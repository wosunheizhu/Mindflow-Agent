'use client';
import { useState, useRef, useEffect } from 'react';
import NextImage from 'next/image';
import { Send, User, Bot, Loader2, Wrench, Check, ChevronDown, ChevronUp, Brain, Upload, Image, FileText, X, Search, UserCircle2, Volume2, Mic, MicOff } from 'lucide-react';
import toast from 'react-hot-toast';
import JsonView from '@/components/JsonView';
import LoginPrompt from '@/components/LoginPrompt';
import LoginModal from '@/components/LoginModal';
import OnboardingGuide from '@/components/OnboardingGuide';
import ResetOnboarding from '@/components/ResetOnboarding';

type ToolCall = {
  tool: string;
  args: any;
  result?: any;
};

type Message = {
  role: 'user' | 'assistant';
  content: string;
  toolCalls?: ToolCall[];
  thinkingSteps?: string[];
  modelThinking?: string; // æ¨¡å‹åŸç”Ÿçš„thinkingå†…å®¹ï¼ˆOllamaç­‰ï¼‰
  reasoningContent?: string; // Agentic AIçš„æ¨ç†è¿‡ç¨‹ï¼ˆGPT-5ç­‰æ¨ç†æ¨¡å‹ï¼‰
  fromAvatar?: boolean; // æ ‡è®°æ¶ˆæ¯æ˜¯å¦æ¥è‡ªæ•°å­—å‘˜å·¥
  avatarName?: string; // æ•°å­—å‘˜å·¥åå­—
  avatarImage?: string; // æ•°å­—å‘˜å·¥å¤´åƒè·¯å¾„
};

// éŸ³è‰²é…ç½®
const voiceConfigs: Record<string, {name: string, rate: number, pitch: number, volume: number}> = {
  'zh_female_sajiaonvyou_moon_bigtts': { name: 'å°å²š', rate: 1.05, pitch: 1.3, volume: 0.9 },
  'zh_male_shaonianzixin_moon_bigtts': { name: 'å°è¿œ', rate: 1.05, pitch: 0.9, volume: 1.0 },
};

function getVoiceName(voiceId: string): string {
  return voiceConfigs[voiceId]?.name || 'æ•°å­—å‘˜å·¥';
}

function getVoiceConfig(voiceId: string) {
  return voiceConfigs[voiceId] || { name: 'æ•°å­—å‘˜å·¥', rate: 1.0, pitch: 1.0, volume: 1.0 };
}

// Base64è½¬Blob
function base64ToBlob(base64: string, mimeType: string): Blob {
  const byteCharacters = atob(base64);
  const byteNumbers = new Array(byteCharacters.length);
  for (let i = 0; i < byteCharacters.length; i++) {
    byteNumbers[i] = byteCharacters.charCodeAt(i);
  }
  const byteArray = new Uint8Array(byteNumbers);
  return new Blob([byteArray], { type: mimeType });
}

export default function ChatPage() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);
  const [deepThinking, setDeepThinking] = useState(false);
  const [browserSearch, setBrowserSearch] = useState(false);
  const [selectedModel, setSelectedModel] = useState<'ollama' | 'openai' | 'gpt4-turbo' | 'gpt5-thinking' | 'gpt5-pro' | 'claude'>('openai');
  const [avatarEnabled, setAvatarEnabled] = useState(true); // æ•°å­—å‘˜å·¥åŠŸèƒ½å¼€å…³ï¼ˆé»˜è®¤å¼€å¯ï¼‰
  const [uploadedFiles, setUploadedFiles] = useState<File[]>([]);
  const [showLoginPrompt, setShowLoginPrompt] = useState(false); // ç™»å½•æç¤ºå¼¹çª—
  const [showLogin, setShowLogin] = useState(false); // ç™»å½•å¼¹çª—
  
  // ä»localStorageè¯»å–æ•°å­—å‘˜å·¥é€‰æ‹©ï¼ˆç”±å·¦ä¾§æ•°å­—å‘˜å·¥æ¡†æ§åˆ¶ï¼‰
  const getSelectedVoice = () => {
    if (typeof window === 'undefined') {
      return 'zh_female_sajiaonvyou_moon_bigtts';
    }
    return localStorage.getItem('selected_avatar_voice') || 'zh_female_sajiaonvyou_moon_bigtts';
  };
  const [expandedTools, setExpandedTools] = useState<Set<string>>(new Set());
  const [thinkingProcess, setThinkingProcess] = useState<string[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const audioCtxRef = useRef<AudioContext | null>(null);

  useEffect(() => {
    audioRef.current = new Audio();
    if (audioRef.current) {
      audioRef.current.preload = 'auto';
    }
    
    // åˆå§‹åŒ–Agentå·¥ä½œçŠ¶æ€
    localStorage.setItem('agent_working', 'false');

    // é˜²é‡å¤ï¼šè®°å½•æœ€åå¤„ç†çš„æç¤ºè¯
    let lastProcessedPrompt = '';
    let lastProcessedTime = 0;

    // ç›‘å¬æ•°å­—å‘˜å·¥å‘é€çš„ä»»åŠ¡
    const handleAvatarTask = (event: CustomEvent) => {
      const { prompt, avatarName, avatarImage } = event.detail;
      const now = Date.now();
      
      // é˜²é‡å¤ï¼šå¦‚æœ1ç§’å†…æ”¶åˆ°ç›¸åŒçš„æç¤ºè¯ï¼Œå¿½ç•¥
      if (prompt === lastProcessedPrompt && (now - lastProcessedTime) < 1000) {
        console.log(`âš ï¸ æ£€æµ‹åˆ°é‡å¤ä»»åŠ¡ï¼Œå¿½ç•¥: ${prompt.substring(0, 50)}...`);
        return;
      }
      
      lastProcessedPrompt = prompt;
      lastProcessedTime = now;
      
      console.log(`ğŸ“¨ æ”¶åˆ°æ•°å­—å‘˜å·¥ä»»åŠ¡: ${avatarName} - ${prompt.substring(0, 50)}...`);
      
      // åˆ›å»ºä¸€ä¸ªæ¥è‡ªæ•°å­—å‘˜å·¥çš„æ¶ˆæ¯
      const avatarMessage: Message = {
        role: 'user',
        content: prompt,
        fromAvatar: true,
        avatarName: avatarName,
        avatarImage: avatarImage
      };
      
      // æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨å¹¶å‘é€ç»™ Agentic AI
      setMessages(prev => {
        const newMessages = [...prev, avatarMessage];
        // è§¦å‘å‘é€
        setTimeout(() => {
          handleSubmitFromAvatar(newMessages);
        }, 100);
        return newMessages;
      });
    };

    window.addEventListener('avatar_agent_task' as any, handleAvatarTask as any);
    
    return () => {
      window.removeEventListener('avatar_agent_task' as any, handleAvatarTask as any);
    };
  }, []);

  const ensureAudioUnlocked = async () => {
    try {
      // è§£é”AudioContextï¼ˆSafari/ç§»åŠ¨ç«¯éœ€è¦ç”¨æˆ·æ‰‹åŠ¿åresumeï¼‰
      const AudioCtx = (window as any).AudioContext || (window as any).webkitAudioContext;
      if (AudioCtx) {
        if (!audioCtxRef.current) audioCtxRef.current = new AudioCtx();
        if (audioCtxRef.current && audioCtxRef.current.state !== 'running') {
          await audioCtxRef.current.resume();
        }
      }
    } catch (e) {}
  };

  const toggleToolExpand = (messageIdx: number, toolIdx: number) => {
    const key = `${messageIdx}-${toolIdx}`;
    setExpandedTools(prev => {
      const next = new Set(prev);
      if (next.has(key)) {
        next.delete(key);
      } else {
        next.add(key);
      }
      return next;
    });
  };

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  // åªåœ¨ç”¨æˆ·å‘é€æ¶ˆæ¯æ—¶è‡ªåŠ¨æ»šåŠ¨ï¼Œç”Ÿæˆè¿‡ç¨‹ä¸­ä¸å¼ºåˆ¶æ»šåŠ¨
  const shouldAutoScroll = useRef(false);

  useEffect(() => {
    if (shouldAutoScroll.current) {
    scrollToBottom();
      shouldAutoScroll.current = false;
    }
  }, [messages]);

  const handleFileSelect = (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = Array.from(e.target.files || []);
    setUploadedFiles([...uploadedFiles, ...files]);
    toast.success(`å·²æ·»åŠ  ${files.length} ä¸ªæ–‡ä»¶`);
  };

  const removeFile = (index: number) => {
    setUploadedFiles(uploadedFiles.filter((_, i) => i !== index));
  };

  // è¯­éŸ³å½•åˆ¶åŠŸèƒ½ - å·²ç¦ç”¨ï¼Œæ”¹ç”¨ç™»å½•æç¤º
  // startRecording å’Œ stopRecording å·²ç§»é™¤

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      toast.success('ğŸ›‘ å½•éŸ³ç»“æŸ', { duration: 1000 });
    }
  };

  // å¤„ç†éº¦å…‹é£æŒ‰é’®ç‚¹å‡» - æ˜¾ç¤ºç™»å½•æç¤º
  const handleMicClick = () => {
    if (isRecording) {
      // å¦‚æœæ­£åœ¨å½•éŸ³ï¼Œåœæ­¢å½•éŸ³
      stopRecording();
    } else {
      // æ˜¾ç¤ºç™»å½•æç¤º
      setShowLoginPrompt(true);
    }
  };

  // å¤„ç†æ¥è‡ªæ•°å­—å‘˜å·¥çš„ä»»åŠ¡æäº¤
  const handleSubmitFromAvatar = async (newMessages: Message[]) => {
    if (loading) {
      toast.error('Agentic AI æ­£åœ¨å¤„ç†ä»»åŠ¡ï¼Œè¯·ç¨å');
      return;
    }

    shouldAutoScroll.current = true; // æ•°å­—å‘˜å·¥å‘é€ä»»åŠ¡æ—¶è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
    setLoading(true);
    localStorage.setItem('agent_working', 'true');
    setThinkingProcess([]);

    try {
      await ensureAudioUnlocked();
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          messages: newMessages,
          deepThinking: deepThinking,
          browserSearch: browserSearch,
          avatarEnabled: avatarEnabled,
          avatarVoice: getSelectedVoice(),
          modelProvider: selectedModel,
          hasFiles: false
        }),
      });

      if (!response.ok) {
        throw new Error('è¯·æ±‚å¤±è´¥');
      }

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let assistantMessage = '';
      let currentToolCalls: ToolCall[] = [];
      let currentThinkingSteps: string[] = [];
      let modelThinkingContent = '';
      let reasoningContent = '';
      let sseBuffer = '';

      if (reader) {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = decoder.decode(value, { stream: true });
          sseBuffer += chunk;
          const events = sseBuffer.split('\n\n');
          sseBuffer = events.pop() || '';

          for (const evt of events) {
            const dataPayload = evt
              .split('\n')
              .filter(l => l.startsWith('data: '))
              .map(l => l.slice(6))
              .join('\n');
            if (!dataPayload) continue;
            if (dataPayload === '[DONE]') break;
            try {
              const parsed = JSON.parse(dataPayload);
                
                if (parsed.type === 'content' && parsed.content) {
                  assistantMessage += parsed.content;
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage,
                    reasoningContent: reasoningContent || undefined,
                    modelThinking: modelThinkingContent || undefined,
                    toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'reasoning_stream' && parsed.content) {
                  reasoningContent += parsed.content;
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'æ­£åœ¨æ¨ç†ä¸­...',
                    reasoningContent: reasoningContent,
                    modelThinking: modelThinkingContent || undefined,
                    toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'reasoning_complete' && parsed.content) {
                  reasoningContent = parsed.content;
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage,
                    reasoningContent: reasoningContent,
                    modelThinking: modelThinkingContent || undefined,
                    toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'thinking' && parsed.content) {
                  currentThinkingSteps.push(parsed.content);
                  setThinkingProcess(prev => [...prev, parsed.content]);
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'æ­£åœ¨æ·±åº¦æ€è€ƒ...',
                    thinkingSteps: currentThinkingSteps
                  }]);
                } else if (parsed.type === 'model_thinking' && parsed.content) {
                  modelThinkingContent += parsed.content;
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'æ¨¡å‹æ­£åœ¨æ€è€ƒ...',
                    modelThinking: modelThinkingContent,
                    toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'tool_call') {
                  currentToolCalls.push({ tool: parsed.tool, args: parsed.args });
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'æ­£åœ¨ä½¿ç”¨å·¥å…·...',
                    toolCalls: currentToolCalls,
                    reasoningContent: reasoningContent || undefined,
                    modelThinking: modelThinkingContent || undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'tool_result') {
                  const idx = currentToolCalls.findIndex(t => t.tool === parsed.tool && !t.result);
                  if (idx !== -1) {
                    currentToolCalls[idx].result = parsed.result;
                    setMessages([...newMessages, { 
                      role: 'assistant', 
                      content: assistantMessage,
                      toolCalls: currentToolCalls,
                      reasoningContent: reasoningContent || undefined,
                      modelThinking: modelThinkingContent || undefined,
                      thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                    }]);
                  }
                } else if (parsed.type === 'avatar_start') {
                  // æ•°å­—å‘˜å·¥å¼€å§‹æ€»ç»“
                  console.log('ğŸ¤ [æ•°å­—å‘˜å·¥ä»»åŠ¡] æ•°å­—å‘˜å·¥å¼€å§‹æ€»ç»“...');
                } else if (parsed.type === 'avatar_audio') {
                  // æ•°å­—å‘˜å·¥æ€»ç»“å®Œæˆ
                  const voiceName = getVoiceName(parsed.voice || getSelectedVoice());
                  const currentVoice = parsed.voice || getSelectedVoice();
                  console.log(`ğŸ¤ [æ•°å­—å‘˜å·¥ä»»åŠ¡] æ•°å­—å‘˜å·¥æ€»ç»“å®Œæˆ [${voiceName}]: ${parsed.audioSize} å­—èŠ‚`);
                  console.log(`ğŸ“ [æ•°å­—å‘˜å·¥ä»»åŠ¡] æ€»ç»“æ–‡æœ¬:`, parsed.summaryText);
                  
                  // âš ï¸ æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œå‘é€ avatar_summary äº‹ä»¶
                  // åŸå› ï¼šavatar_summary åº”è¯¥åªåœ¨ä¸»èŠå¤©æµç¨‹ä¸­å‘é€ä¸€æ¬¡ï¼ˆè§ä¸‹æ–¹ handleSubmit ä¸­çš„å¤„ç†ï¼‰
                  // è¿™é‡Œåªè´Ÿè´£æ’­æ”¾ç¬¬ä¸€æ¬¡ä»»åŠ¡è§„åˆ’æ—¶çš„è¯­éŸ³
                  console.log(`â­ï¸ [æ•°å­—å‘˜å·¥ä»»åŠ¡] è·³è¿‡å‘é€ avatar_summaryï¼ˆä»»åŠ¡è§„åˆ’é˜¶æ®µï¼Œä¸æ˜¯æ€»ç»“ï¼‰`);
                  
                  // æ’­æ”¾è§„åˆ’è¯­éŸ³
                  await ensureAudioUnlocked();
                  const audioBlob = base64ToBlob(parsed.audioBase64, 'audio/wav');
                  const audioUrl = URL.createObjectURL(audioBlob);
                  if (audioRef.current) {
                    audioRef.current.src = audioUrl;
                    audioRef.current.onended = () => {
                      URL.revokeObjectURL(audioUrl);
                    };
                    await audioRef.current.play().catch(e => {
                      console.error('æ’­æ”¾è§„åˆ’éŸ³é¢‘å¤±è´¥:', e);
                    });
                  }
                } else if (parsed.type === 'audio_segment' && parsed.audioBase64) {
                  // å¤„ç†éŸ³é¢‘...
                }
              } catch (e) {
                console.error('è§£æSSEå¤±è´¥:', e);
              }
          }
        }
      }

      setMessages([...newMessages, { 
        role: 'assistant', 
        content: assistantMessage,
        toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
        reasoningContent: reasoningContent || undefined,
        modelThinking: modelThinkingContent || undefined,
        thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
      }]);
    } catch (error) {
      console.error('å¤„ç†æ•°å­—å‘˜å·¥ä»»åŠ¡é”™è¯¯:', error);
      toast.error('å¤„ç†ä»»åŠ¡å¤±è´¥');
      setMessages([...newMessages, { role: 'assistant', content: 'æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºé”™ã€‚' }]);
    } finally {
      setLoading(false);
      localStorage.setItem('agent_working', 'false');
    }
  };

  const handleSend = async () => {
    if ((!input.trim() && uploadedFiles.length === 0) || loading) return;

    let messageContent = input;
    let uploadedFilePaths: string[] = [];

    // å¦‚æœæœ‰ä¸Šä¼ çš„æ–‡ä»¶ï¼Œå…ˆä¸Šä¼ åˆ°æœåŠ¡å™¨
    if (uploadedFiles.length > 0) {
      try {
        const formData = new FormData();
        uploadedFiles.forEach(file => formData.append('files', file));

        const uploadRes = await fetch('/api/upload-chat', {
          method: 'POST',
          body: formData,
        });

        if (uploadRes.ok) {
          const uploadData = await uploadRes.json();
          uploadedFilePaths = uploadData.files.map((f: any) => f.filename);
          const fileInfo = uploadData.files.map((f: any) => `[${f.type.startsWith('image/') ? 'å›¾ç‰‡' : 'æ–‡ä»¶'}: ${f.filename}]`).join(' ');
          messageContent = `${fileInfo}\n\n${input || 'è¯·åˆ†æè¿™äº›æ–‡ä»¶'}`;
          toast.success('æ–‡ä»¶ä¸Šä¼ æˆåŠŸ');
        }
      } catch (err) {
        toast.error('æ–‡ä»¶ä¸Šä¼ å¤±è´¥');
        setLoading(false);
        return;
      }
    }

    const userMessage: Message = { role: 'user', content: messageContent };
    const newMessages = [...messages, userMessage];
    setMessages(newMessages);
    shouldAutoScroll.current = true; // ç”¨æˆ·å‘é€æ¶ˆæ¯æ—¶è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
    setInput('');
    setUploadedFiles([]);
    setLoading(true);
    localStorage.setItem('agent_working', 'true'); // é€šçŸ¥æ•°å­—å‘˜å·¥ï¼šAgentå¼€å§‹å·¥ä½œ
    setThinkingProcess([]); // é‡ç½®æ€è€ƒè¿‡ç¨‹

    try {
      await ensureAudioUnlocked();
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          messages: newMessages,
          deepThinking: deepThinking,
          browserSearch: browserSearch,
          avatarEnabled: avatarEnabled,
          avatarVoice: getSelectedVoice(), // ä»localStorageè¯»å–
          modelProvider: selectedModel,
          hasFiles: uploadedFiles.length > 0
        }),
      });

      if (!response.ok) {
        throw new Error('è¯·æ±‚å¤±è´¥');
      }

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let assistantMessage = '';
      let currentToolCalls: ToolCall[] = [];
      let currentThinkingSteps: string[] = [];
      let modelThinkingContent = '';
      let reasoningContent = '';  // Agentic AIæ¨ç†å†…å®¹
      let sseBuffer = '';

      if (reader) {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = decoder.decode(value, { stream: true });
          sseBuffer += chunk;
          const events = sseBuffer.split('\n\n');
          sseBuffer = events.pop() || '';

          for (const evt of events) {
            const dataPayload = evt
              .split('\n')
              .filter(l => l.startsWith('data: '))
              .map(l => l.slice(6))
              .join('\n');
            if (!dataPayload) continue;
            if (dataPayload === '[DONE]') break;
            try {
              const parsed = JSON.parse(dataPayload);
                
                if (parsed.type === 'content' && parsed.content) {
                  assistantMessage += parsed.content;
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage,
                    reasoningContent: reasoningContent || undefined,
                    modelThinking: modelThinkingContent || undefined,
                    toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'reasoning_stream' && parsed.content) {
                  // å¤„ç†Agentic AIçš„æ¨ç†è¿‡ç¨‹æµå¼è¾“å‡º
                  reasoningContent += parsed.content;
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'æ­£åœ¨æ¨ç†ä¸­...',
                    reasoningContent: reasoningContent,
                    modelThinking: modelThinkingContent || undefined,
                    toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'reasoning_complete' && parsed.content) {
                  // å¤„ç†å®Œæ•´çš„Agentic AIæ¨ç†å†…å®¹
                  reasoningContent = parsed.content;
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage,
                    reasoningContent: reasoningContent,
                    modelThinking: modelThinkingContent || undefined,
                    toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'thinking' && parsed.content) {
                  // å¤„ç†æ€è€ƒè¿‡ç¨‹ - ä¿å­˜åˆ°æ¶ˆæ¯ä¸­
                  currentThinkingSteps.push(parsed.content);
                  setThinkingProcess(prev => [...prev, parsed.content]);
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'æ­£åœ¨æ·±åº¦æ€è€ƒ...',
                    thinkingSteps: currentThinkingSteps
                  }]);
                } else if (parsed.type === 'model_thinking_stream' && parsed.content) {
                  // å®æ—¶æ¥æ”¶æ¨¡å‹thinkingæµï¼ˆOllamaç­‰ï¼‰
                  modelThinkingContent += parsed.content;
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'æ¨¡å‹æ­£åœ¨åˆ†æ...',
                    reasoningContent: reasoningContent || undefined,
                    modelThinking: modelThinkingContent,
                    toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'model_thinking' && parsed.content) {
                  // å¤„ç†å®Œæ•´çš„æ¨¡å‹thinkingå†…å®¹ï¼ˆOllamaç­‰ï¼‰
                  modelThinkingContent = parsed.content;
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'åˆ†æå®Œæˆ...',
                    reasoningContent: reasoningContent || undefined,
                    modelThinking: modelThinkingContent,
                    toolCalls: currentToolCalls.length > 0 ? currentToolCalls : undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'tool_call') {
                  currentToolCalls.push({
                    tool: parsed.tool,
                    args: parsed.args
                  });
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'æ­£åœ¨è°ƒç”¨å·¥å…·...',
                    toolCalls: currentToolCalls,
                    reasoningContent: reasoningContent || undefined,
                    modelThinking: modelThinkingContent || undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'tool_result') {
                  const lastToolCall = currentToolCalls[currentToolCalls.length - 1];
                  if (lastToolCall) {
                    lastToolCall.result = parsed.result;
                  }
                  setMessages([...newMessages, { 
                    role: 'assistant', 
                    content: assistantMessage || 'å·¥å…·æ‰§è¡Œå®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå›å¤...',
                    toolCalls: currentToolCalls,
                    reasoningContent: reasoningContent || undefined,
                    modelThinking: modelThinkingContent || undefined,
                    thinkingSteps: currentThinkingSteps.length > 0 ? currentThinkingSteps : undefined
                  }]);
                } else if (parsed.type === 'avatar_planning') {
                  // æ•°å­—å‘˜å·¥ä»»åŠ¡è®¡åˆ’å·²ç¦ç”¨ï¼ˆä¸åœ¨ä»»åŠ¡å¼€å§‹æ—¶æ‰“æ–­ï¼‰
                  console.log('â­ï¸ è·³è¿‡æ•°å­—å‘˜å·¥è®¡åˆ’å›å¤');
                  
                } else if (parsed.type === 'avatar_start') {
                  // æ•°å­—å‘˜å·¥å¼€å§‹ç¬¬äºŒæ¬¡å›ç­”ï¼ˆé™é»˜å¤„ç†ï¼‰
                  console.log('ğŸ¤ æ•°å­—å‘˜å·¥å¼€å§‹æ€»ç»“...');
                } else if (parsed.type === 'avatar_audio') {
                  // LLM-TTSåŒå‘æµå¼å®Œæˆï¼ˆä»»åŠ¡æ€»ç»“ï¼‰ï¼Œå‘é€ avatar_summary äº‹ä»¶
                  const voiceName = getVoiceName(parsed.voice || getSelectedVoice());
                  const currentVoice = parsed.voice || getSelectedVoice();
                  console.log(`ğŸ¤ æ•°å­—å‘˜å·¥æ€»ç»“å®Œæˆ [${voiceName}]: ${parsed.audioSize} å­—èŠ‚`);
                  console.log(`ğŸ“ æ•°å­—å‘˜å·¥æ€»ç»“æ–‡æœ¬:`, parsed.summaryText);
                  console.log(`ğŸµ å½“å‰éŸ³è‰²: ${currentVoice}`);
                  
                  // å‘é€ avatar_summary äº‹ä»¶åˆ°æ•°å­—å‘˜å·¥ç»„ä»¶ï¼ˆåªåœ¨è¿™é‡Œå‘é€ä¸€æ¬¡ï¼‰
                  if (parsed.summaryText && parsed.summaryText.trim()) {
                    console.log(`ğŸ“¤ å‘é€ avatar_summary äº‹ä»¶åˆ°æ•°å­—å‘˜å·¥ç»„ä»¶`);
                    window.dispatchEvent(new CustomEvent('agent_avatar_message', {
                      detail: {
                        type: 'avatar_summary',
                        text: parsed.summaryText.trim(),
                        voice: currentVoice,
                        duration: parsed.duration || 3000
                      }
                    }));
                  }
                  
                  // æ’­æ”¾è±†åŒ…TTSéŸ³é¢‘
                  await ensureAudioUnlocked();
                  const audioBlob = base64ToBlob(parsed.audioBase64, 'audio/wav');
                  const audioUrl = URL.createObjectURL(audioBlob);
                  if (audioRef.current) {
                    audioRef.current.src = audioUrl;
                    audioRef.current.onended = () => {
                      console.log('âœ… æ•°å­—å‘˜å·¥è¯­éŸ³æ’­æ”¾å®Œæˆ');
                      URL.revokeObjectURL(audioUrl);
                    };
                    audioRef.current.play().then(() => {
                      console.log('ğŸ”Š å¼€å§‹æ’­æ”¾æ•°å­—å‘˜å·¥è¯­éŸ³');
                    }).catch(e => {
                      console.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥:', e);
                      toast.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥');
                    });
                  }
                } else if (parsed.type === 'avatar_error') {
                  // æ•°å­—å‘˜å·¥æœåŠ¡é”™è¯¯
                  toast.error(parsed.content || 'æ•°å­—å‘˜å·¥æœåŠ¡é”™è¯¯', { id: 'avatar-summary' });
                } else if (parsed.type === 'error') {
                  throw new Error(parsed.error);
                }
              } catch (e) {}
            }
          }
        }
    } catch (error) {
      toast.error('å‘é€å¤±è´¥');
      setMessages([...newMessages, { role: 'assistant', content: 'æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºé”™ã€‚' }]);
    } finally {
      setLoading(false);
      localStorage.setItem('agent_working', 'false'); // é€šçŸ¥æ•°å­—å‘˜å·¥ï¼šAgentå®Œæˆå·¥ä½œ
      // ä¸æ¸…ç©ºæ€è€ƒè¿‡ç¨‹ï¼Œä¿ç•™æ˜¾ç¤º
    }
  };

  return (
    <>
    <OnboardingGuide />
    <ResetOnboarding />
    <div id="chat-container" className="flex flex-col h-full">
      <div className="card p-4 mb-4 flex-shrink-0">
        <div className="flex items-center justify-between">
          <div id="chat-header">
            <div className="text-lg font-semibold">AI å¯¹è¯</div>
            <div className="text-xs text-gray-500">ä¸ AI åŠ©æ‰‹è‡ªç”±å¯¹è¯ï¼Œå®ƒä¼šè‡ªåŠ¨è°ƒç”¨å·¥å…·å®Œæˆä»»åŠ¡</div>
          </div>
          <div className="flex items-center gap-2">
            <label className="text-xs text-gray-500 whitespace-nowrap">æ¨¡å‹:</label>
            <select 
              value={selectedModel} 
              onChange={(e) => setSelectedModel(e.target.value as 'ollama' | 'openai' | 'gpt4-turbo' | 'gpt5-thinking' | 'gpt5-pro' | 'claude')}
              className="select text-sm py-1 px-2"
              disabled={loading}
            >
              <option value="gpt5-pro">Mindflow-Y-Proï¼ˆå¼ºæ¨ç†ï¼‰</option>
              <option value="gpt5-thinking">Mindflow-Yï¼ˆå¼ºæ¨ç†ï¼‰</option>
              <option value="openai">Mindflow-Y-Workflowï¼ˆæ¨è-è‡ªåŠ¨å·¥ä½œæµï¼‰</option>
              <option value="gpt4-turbo">Mindflow-Y-Fastï¼ˆå¿«é€Ÿå·¥ä½œæµï¼‰</option>
              <option value="claude">Mindflow-X-Workflowï¼ˆBeta-Testingï¼‰</option>
              <option value="ollama">gpt-oss:20b (æœ¬åœ°)</option>
            </select>
          </div>
        </div>
      </div>

      {/* æ¶ˆæ¯åŒºåŸŸ - å›ºå®šé«˜åº¦ï¼Œå¯æ»šåŠ¨ */}
      <div className="card flex-1 overflow-y-auto p-4 mb-4 min-h-0">
        {messages.length === 0 && (
          <div className="flex items-center justify-center h-full text-gray-500">
            <div className="text-center">
              <div className="h-16 w-16 mx-auto mb-4 rounded-full overflow-hidden bg-white dark:bg-gray-800">
                <NextImage
                  src="/avatars/m.jpg"
                  alt="AI"
                  width={64}
                  height={64}
                  className="object-cover"
                  unoptimized
                />
              </div>
              <div className="text-base font-medium mb-2">å¼€å§‹å¯¹è¯</div>
              <div className="text-sm">AI ä¼šè‡ªåŠ¨è°ƒç”¨å·¥å…·å¸®ä½ å®Œæˆä»»åŠ¡</div>
              <div className="text-xs mt-3 text-gray-400">
                ä¾‹å¦‚ï¼š"å¸®æˆ‘æœç´¢ AI æŠ€æœ¯å¹¶ç”ŸæˆæŠ¥å‘Š"
              </div>
            </div>
          </div>
        )}
        
        {messages.map((msg, msgIdx) => (
          <div key={msgIdx} className={`mb-4 flex gap-3 ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}>
            {msg.role === 'assistant' && (
              <div className="flex-shrink-0 w-8 h-8 rounded-full overflow-hidden bg-white dark:bg-gray-800">
                <NextImage
                  src="/avatars/m.jpg"
                  alt="AI"
                  width={32}
                  height={32}
                  className="object-cover"
                  unoptimized
                />
              </div>
            )}
            <div className={`max-w-[75%] ${msg.role === 'user' ? '' : 'w-full'}`}>
              <div>
                {/* Agentic AIæ¨ç†è¿‡ç¨‹ï¼ˆGPT-5ç­‰æ¨ç†æ¨¡å‹ï¼‰ */}
                {msg.role === 'assistant' && msg.reasoningContent && (
                  <div className="mb-3 bg-gradient-to-r from-blue-50 to-cyan-50 dark:from-blue-950/30 dark:to-cyan-950/30 border-2 border-blue-300 dark:border-blue-700 rounded-lg p-4 shadow-sm">
                    <div className="flex items-center gap-2 mb-3">
                      <Brain size={18} className="text-blue-600 dark:text-blue-400" />
                      <span className="font-bold text-blue-900 dark:text-blue-100 text-sm">ğŸ¤– Agentic AI æ¨ç†è¿‡ç¨‹</span>
                      <span className="ml-auto text-xs px-2 py-1 bg-blue-200 dark:bg-blue-800 text-blue-800 dark:text-blue-200 rounded-full">
                        æ™ºèƒ½æ¨ç†
                      </span>
                    </div>
                    <div className="text-xs text-blue-800 dark:text-blue-200 whitespace-pre-wrap leading-relaxed bg-white/60 dark:bg-black/20 rounded p-3 border border-blue-200 dark:border-blue-800">
                      {msg.reasoningContent}
                    </div>
                  </div>
                )}

                {/* æ·±åº¦æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰ */}
                {msg.role === 'assistant' && msg.thinkingSteps && msg.thinkingSteps.length > 0 && (
                  <div className="mb-3 bg-gradient-to-r from-purple-50 to-blue-50 dark:from-purple-950/30 dark:to-blue-950/30 border border-purple-200 dark:border-purple-800 rounded-lg p-4">
                    <div className="flex items-center gap-2 mb-3">
                      <Brain size={16} className="text-purple-600 dark:text-purple-400" />
                      <span className="font-semibold text-purple-900 dark:text-purple-100 text-sm">æ·±åº¦æ€è€ƒè¿‡ç¨‹</span>
                    </div>
                    <div className="space-y-2">
                      {msg.thinkingSteps.map((step, index) => (
                        <div key={index} className="flex items-center gap-2 text-xs">
                          <div className="w-1.5 h-1.5 bg-purple-500 rounded-full"></div>
                          <span className="text-purple-800 dark:text-purple-200">{step}</span>
                        </div>
                      ))}
                    </div>
                  </div>
                )}

                {/* æ¨¡å‹åŸç”Ÿthinkingï¼ˆOllamaç­‰æœ¬åœ°æ¨¡å‹ï¼‰ */}
                {msg.role === 'assistant' && msg.modelThinking && (
                  <div className="mb-3 bg-gray-50 dark:bg-gray-900/50 border border-gray-200 dark:border-gray-700 rounded-lg p-4">
                    <div className="flex items-center gap-2 mb-2">
                      <Brain size={14} className="text-gray-500 dark:text-gray-400" />
                      <span className="font-medium text-gray-600 dark:text-gray-400 text-xs">æœ¬åœ°æ¨¡å‹åˆ†æè¿‡ç¨‹</span>
                    </div>
                    <div className="text-xs text-gray-500 dark:text-gray-400 whitespace-pre-wrap font-mono leading-relaxed">
                      {msg.modelThinking}
                    </div>
                  </div>
                )}

                {/* æ¶ˆæ¯å†…å®¹ */}
                <div className={`${
                  msg.role === 'user' 
                    ? 'rounded-xl border border-blue-400/70 bg-blue-100/60 dark:bg-blue-900/20 dark:border-blue-500/60 backdrop-blur-sm shadow-sm px-4 py-3 text-blue-900 dark:text-blue-100'
                    : 'bg-transparent text-gray-900 dark:text-gray-100'
                }`}>
                  <div className={`text-xs mb-1 flex items-center gap-1 ${msg.role === 'user' ? 'text-blue-700/80 dark:text-blue-200/80' : 'text-gray-500 dark:text-gray-400 opacity-70'}`}>
                    {msg.role === 'user' ? (
                      <>
                        {msg.fromAvatar ? (
                          <>
                            <UserCircle2 size={12} />
                            <span>{msg.avatarName || 'æ•°å­—å‘˜å·¥'}</span>
                          </>
                        ) : (
                      <>
                        <User size={12} />
                        <span>ä½ </span>
                          </>
                        )}
                      </>
                    ) : (
                      <>
                        <Bot size={12} />
                        <span>AI åŠ©æ‰‹</span>
                      </>
                    )}
                  </div>
                  <div className={`whitespace-pre-wrap text-sm leading-relaxed ${msg.role === 'user' ? 'text-blue-900 dark:text-blue-100' : ''}`}>
                    {msg.content}
                  </div>
                </div>
              </div>
              
              {/* å·¥å…·è°ƒç”¨è¯¦æƒ… */}
              {msg.toolCalls && msg.toolCalls.length > 0 && (
                <div className="mt-2 space-y-2">
                  {msg.toolCalls.map((tc, toolIdx) => {
                    const key = `${msgIdx}-${toolIdx}`;
                    const isExpanded = expandedTools.has(key);
                    return (
                      <div key={toolIdx} className="rounded-lg border-2 border-blue-200 dark:border-blue-800 bg-blue-50 dark:bg-blue-950/30 overflow-hidden">
                        <button
                          onClick={() => toggleToolExpand(msgIdx, toolIdx)}
                          className="w-full px-3 py-2 flex items-center justify-between hover:bg-blue-100 dark:hover:bg-blue-900/40 transition-colors"
                        >
                          <div className="flex items-center gap-2 text-sm">
                            <Wrench size={14} className="text-blue-600 dark:text-blue-400" />
                            <span className="font-medium text-blue-900 dark:text-blue-100">
                              å·¥å…·è°ƒç”¨: {tc.tool}
                            </span>
                            {tc.result && (
                              <Check size={14} className="text-green-600 dark:text-green-400" />
                            )}
                          </div>
                          {isExpanded ? (
                            <ChevronUp size={14} className="text-blue-600 dark:text-blue-400" />
                          ) : (
                            <ChevronDown size={14} className="text-blue-600 dark:text-blue-400" />
                          )}
                        </button>
                        
                        {isExpanded && (
                          <div className="px-3 py-2 border-t border-blue-200 dark:border-blue-800 bg-white dark:bg-[rgb(22,23,24)]">
                            <div className="text-xs font-semibold text-gray-500 mb-2">è¾“å…¥å‚æ•°</div>
                            <div className="bg-gray-50 dark:bg-gray-900 rounded p-2 mb-3">
                              <JsonView src={tc.args} />
                            </div>
                            
                            {tc.result && (
                              <>
                                <div className="text-xs font-semibold text-gray-500 mb-2">æ‰§è¡Œç»“æœ</div>
                                <div className="bg-gray-50 dark:bg-gray-900 rounded p-2">
                                  <JsonView src={tc.result} />
                                </div>
                              </>
                            )}
                          </div>
                        )}
                      </div>
                    );
                  })}
                </div>
              )}
            </div>
            {msg.role === 'user' && (
              <>
                {msg.fromAvatar && msg.avatarImage ? (
                  <div className="flex-shrink-0 w-8 h-8 rounded-full overflow-hidden bg-white dark:bg-white flex items-center justify-center ring-2 ring-lime-400 shadow-sm">
                    <div className="relative w-6 h-6">
                      <img
                        src={`/avatars/${msg.avatarImage}`}
                        alt={msg.avatarName || 'æ•°å­—å‘˜å·¥'}
                        className="object-contain w-full h-full"
                      />
                    </div>
                  </div>
                ) : (
              <div className="flex-shrink-0 w-8 h-8 rounded-full bg-blue-600 flex items-center justify-center">
                <User size={18} className="text-white" />
              </div>
                )}
              </>
            )}
          </div>
        ))}
        
        {loading && (
          <div className="flex justify-start mb-4 gap-3">
            <div className="flex-shrink-0 w-8 h-8 rounded-full bg-blue-100 dark:bg-blue-900/30 flex items-center justify-center">
              <Loader2 size={18} className="text-blue-600 dark:text-blue-400 animate-spin" />
            </div>
            <div className="bg-gray-100 dark:bg-gray-800 rounded-lg px-4 py-3">
              <div className="text-sm text-gray-600 dark:text-gray-400">AI æ­£åœ¨æ€è€ƒ...</div>
            </div>
          </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>

      {/* è¾“å…¥åŒºåŸŸ */}
      <div className="card p-4 flex-shrink-0">
        {/* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */}
        {uploadedFiles.length > 0 && (
          <div className="mb-3 flex flex-wrap gap-2">
            {uploadedFiles.map((file, idx) => (
              <div key={idx} className="flex items-center gap-2 px-3 py-2 bg-blue-50 dark:bg-blue-900/30 border border-blue-200 dark:border-blue-800 rounded-lg text-sm">
                {file.type.startsWith('image/') ? (
                  <Image size={14} className="text-blue-600" />
                ) : (
                  <FileText size={14} className="text-blue-600" />
                )}
                <span className="text-blue-900 dark:text-blue-100">{file.name}</span>
                <button
                  onClick={() => removeFile(idx)}
                  className="text-blue-600 hover:text-blue-800"
                >
                  <X size={14} />
                </button>
              </div>
            ))}
          </div>
        )}

        {/* åŠŸèƒ½é€‰é¡¹æ  */}
        <div className="flex items-center gap-2 mb-3 pb-3 border-b border-gray-200 dark:border-gray-700">
          <button
            onClick={() => fileInputRef.current?.click()}
            className="btn-ghost text-sm"
            title="ä¸Šä¼ æ–‡ä»¶æˆ–å›¾ç‰‡"
          >
            <Upload size={16} />
            ä¸Šä¼ 
          </button>
          <input
            ref={fileInputRef}
            type="file"
            multiple
            accept="image/*,.pdf,.doc,.docx,.txt,.md"
            onChange={handleFileSelect}
            className="hidden"
          />
          
          <div className="h-6 w-px bg-gray-300 dark:bg-gray-600"></div>
          
          <button
            onClick={() => setDeepThinking(!deepThinking)}
            className={`btn-ghost text-sm ${deepThinking ? 'bg-purple-100 dark:bg-purple-900/30 text-purple-600 dark:text-purple-400' : ''}`}
            title="æ·±åº¦æ€è€ƒæ¨¡å¼ï¼ˆä½¿ç”¨æ›´å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼‰"
          >
            <Brain size={16} className={deepThinking ? 'text-purple-600' : ''} />
            æ·±åº¦æ€è€ƒ
            {deepThinking && (
              <span className="ml-1 text-xs px-1.5 py-0.5 rounded bg-purple-200 dark:bg-purple-800 text-purple-800 dark:text-purple-200">
                ON
              </span>
            )}
          </button>

          <div className="h-6 w-px bg-gray-300 dark:bg-gray-600"></div>

          <button
            id="avatar-toggle"
            onClick={() => setAvatarEnabled(!avatarEnabled)}
            className={`btn-ghost text-sm ${avatarEnabled ? 'bg-orange-100 dark:bg-orange-900/30 text-orange-600 dark:text-orange-400' : ''}`}
            title="è¯­éŸ³æ•°å­—å‘˜å·¥ï¼ˆAIè¯­éŸ³æ€»ç»“æ’­æŠ¥ï¼‰"
          >
            <Volume2 size={16} className={avatarEnabled ? 'text-orange-600' : ''} />
            æ•°å­—å‘˜å·¥
            {avatarEnabled && (
              <span className="ml-1 text-xs px-1.5 py-0.5 rounded bg-orange-200 dark:bg-orange-800 text-orange-800 dark:text-orange-200">
                ON
              </span>
            )}
          </button>

          <div className="flex-1"></div>
        </div>

        {/* è¾“å…¥æ¡† */}
        <div className="flex gap-2">
          <textarea
            className="input flex-1 resize-none"
            placeholder="è¾“å…¥æ¶ˆæ¯... (Shift+Enter æ¢è¡Œ)"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyDown={(e) => {
              if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleSend();
              }
            }}
            disabled={loading || isRecording}
            rows={3}
          />
          <div className="flex flex-col gap-2">
            <button
              className={`p-2 rounded transition-colors h-fit ${
                isRecording 
                  ? 'bg-red-100 dark:bg-red-900/30 text-red-600 animate-pulse' 
                  : 'text-gray-600 dark:text-gray-400 hover:text-green-600 dark:hover:text-green-400 hover:bg-gray-100 dark:hover:bg-gray-800'
              } disabled:opacity-50 disabled:cursor-not-allowed`}
              onClick={handleMicClick}
              disabled={loading}
              title={isRecording ? 'ç‚¹å‡»åœæ­¢å½•éŸ³' : 'è¯·å…ˆç™»å½•ä½¿ç”¨è¯­éŸ³åŠŸèƒ½'}
            >
              {isRecording ? <MicOff size={16} className="text-red-600" /> : <Mic size={16} />}
            </button>
            <button
              className="p-2 rounded transition-colors h-fit text-blue-600 dark:text-blue-400 hover:bg-blue-100 dark:hover:bg-blue-900/30 disabled:opacity-50 disabled:cursor-not-allowed"
              onClick={handleSend}
              disabled={loading || (!input.trim() && uploadedFiles.length === 0)}
              title="å‘é€"
            >
              {loading ? <Loader2 size={16} className="animate-spin" /> : <Send size={16} />}
            </button>
          </div>
        </div>
      </div>

      {/* ç™»å½•æç¤º */}
      <LoginPrompt 
        isOpen={showLoginPrompt} 
        onClose={() => setShowLoginPrompt(false)}
        onLogin={() => {
          setShowLoginPrompt(false);
          setShowLogin(true);
        }}
      />

      {/* ç™»å½•å¼¹çª— */}
      <LoginModal isOpen={showLogin} onClose={() => setShowLogin(false)} />
    </div>
    </>
  );
}

