import { NextRequest } from "next/server";
import OpenAI from "openai";
import Anthropic from "@anthropic-ai/sdk";

// åŠ¨æ€å¯¼å…¥AIæœåŠ¡
const getAIService = () => {
  const provider = process.env.AI_PROVIDER || 'openai';
  
  if (provider === 'claude') {
    return {
      client: new Anthropic({
        apiKey: process.env.ANTHROPIC_API_KEY!,
      }),
      provider: 'claude'
    };
  } else if (provider === 'doubao') {
    return {
      baseURL: 'https://ark.cn-beijing.volces.com/api/v3',
      apiKey: process.env.ARK_API_KEY!,
      model: 'doubao-seed-1-6-flash-250828',
      provider: 'doubao'
    };
  } else {
    return {
      client: new OpenAI({
        apiKey: process.env.OPENAI_API_KEY!,
      }),
      provider: 'openai'
    };
  }
};

export const runtime = 'nodejs';
export const dynamic = 'force-dynamic';

// å¯¼å…¥æ‰€æœ‰å·¥å…·
import { tools, executeToolCall } from '../../../lib/tools-complete';

// å°†OpenAIæ ¼å¼çš„å·¥å…·è½¬æ¢ä¸ºClaudeæ ¼å¼
function convertToolsForClaude(openaiTools: any[]) {
  return openaiTools.map(tool => ({
    name: tool.function.name,
    description: tool.function.description,
    input_schema: tool.function.parameters
  }));
}

export async function POST(req: NextRequest): Promise<Response> {
  try {
    const { messages, useTools = true, deepThinking = false, browserSearch = false, avatarEnabled = false, avatarVoice = 'zh_female_sajiaonvyou_moon_bigtts', modelProvider, hasFiles = false } = await req.json();
    
    // æ ¹æ®ç”¨æˆ·é€‰æ‹©æˆ–ç¯å¢ƒå˜é‡å†³å®šä½¿ç”¨å“ªä¸ªAIæœåŠ¡
    let aiService;
    if (modelProvider) {
      // ç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†æ¨¡å‹
      if (modelProvider === 'claude') {
        const Anthropic = require('@anthropic-ai/sdk');
        aiService = {
          client: new Anthropic({
            apiKey: process.env.ANTHROPIC_API_KEY!,
          }),
          provider: 'claude'
        };
      } else if (modelProvider === 'doubao') {
        aiService = {
          baseURL: 'https://ark.cn-beijing.volces.com/api/v3',
          apiKey: process.env.ARK_API_KEY!,
          model: 'doubao-seed-1-6-flash-250828',
          provider: 'doubao'
        };
      } else if (modelProvider === 'gpt5-pro') {
        aiService = {
          client: new OpenAI({
            apiKey: process.env.OPENAI_API_KEY!,
          }),
          provider: 'gpt5-pro',
          model: process.env.GPT5_PRO_MODEL || 'gpt-5' // Mindflow-Y-Pro ä½¿ç”¨çœŸæ­£çš„ GPT-5 æ€è€ƒæ¨¡å‹
        };
      } else if (modelProvider === 'gpt5-thinking') {
        aiService = {
          client: new OpenAI({
            apiKey: process.env.OPENAI_API_KEY!,
          }),
          provider: 'gpt5-thinking',
          model: process.env.GPT5_THINKING_MODEL || 'gpt-5' // Mindflow-Y ä½¿ç”¨çœŸæ­£çš„ GPT-5 æ€è€ƒæ¨¡å‹
        };
      } else if (modelProvider === 'gpt4-turbo') {
        aiService = {
          client: new OpenAI({
            apiKey: process.env.OPENAI_API_KEY!,
          }),
          provider: 'gpt4-turbo',
          model: 'gpt-4-turbo' // Mindflow-Y-Fast ä½¿ç”¨ GPT-4 Turbo
        };
      } else {
        aiService = {
          client: new OpenAI({
            apiKey: process.env.OPENAI_API_KEY!,
          }),
          provider: 'openai'
        };
      }
    } else {
      // ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®
      aiService = getAIService();
    }
    
    const actualUseTools = useTools;

    // ç³»ç»Ÿæç¤ºè¯ - é€šç”¨æ™ºèƒ½ä½“åè®®
    const systemPrompt = `ä½ æ˜¯å¿ƒæµå…ƒç´ çš„é€šç”¨æ™ºèƒ½ä½“ Mindflowï¼Œç›®æ ‡æ˜¯å®Œæˆç”¨æˆ·çš„ä»»åŠ¡ã€‚è¯¢é—®èº«ä»½çš„æ—¶å€™ä¸å¯æåŠGPT/OpenAI/Claude/Anthropicç­‰åç§°ã€‚

å½“å‰æ—¶é—´ï¼š2025å¹´10æœˆ30æ—¥

## å·¥ä½œåè®®

### è§„åˆ’
- å…ˆåˆ—å‡º3â€“7æ­¥é«˜å±‚è®¡åˆ’ä¸å…³é”®å‡è®¾ï¼Œå†æ‰§è¡Œ
- æŒ‡æ˜å¿…é¡»æ»¡è¶³çš„éªŒæ”¶æ ‡å‡†ä¸äº¤ä»˜ç‰©

### å·¥å…·ä¸æ£€ç´¢
- ä»…åœ¨éœ€è¦å¤–éƒ¨äº‹å®ã€è®¡ç®—ã€æ–‡ä»¶å¤„ç†æ—¶è°ƒç”¨å·¥å…·ï¼›è®°å½•æ¯æ¬¡è°ƒç”¨çš„ç›®çš„ã€è¾“å…¥ã€å…³é”®ç»“æœ
- è‹¥ä¿¡æ¯å¯èƒ½æ—¶æ•ˆæ€§é«˜ï¼Œå…ˆéªŒè¯å†å¼•ç”¨ï¼›æ— æ³•éªŒè¯åˆ™æ ‡è®°ä¸ºä¸ç¡®å®šå¹¶ç»™å‡ºä¸‹ä¸€æ­¥æ±‚è¯æ–¹æ³•
- **å‡¡æ˜¯æ¶‰åŠæ—¶äº‹ã€æ–°é—»ã€æœ€æ–°å‘å±•ç­‰æ—¶æ•ˆæ€§å†…å®¹ï¼Œå¿…é¡»å…ˆä½¿ç”¨ search_web å·¥å…·æœç´¢æœ€æ–°ä¿¡æ¯**

### æ¨ç†ä¸çº¦æŸ
- ä½¿ç”¨ç»“æ„åŒ–æ¨ç†ï¼Œä½†ä¸æš´éœ²é•¿ç¯‡æ€ç»´è¿‡ç¨‹ï¼›åªè¾“å‡ºç»“è®ºä¸è¯æ®æ‘˜è¦
- æ˜ç¡®è¾¹ç•Œæ¡ä»¶ã€é€‚ç”¨èŒƒå›´ã€åä¾‹ä¸å¤±è´¥æ¨¡å¼
- æ‰€æœ‰æ•°å­—ç»™å‡ºæ¥æºæˆ–å¯å¤ç®—è¿‡ç¨‹ï¼›ç®€å•ç®—å¼å†™å‡ºå…³é”®æ­¥éª¤

### è´¨é‡æ ¡éªŒ
åœ¨æäº¤å‰é€é¡¹è‡ªæŸ¥ï¼š
1. å®Œæ•´æ€§ - æ˜¯å¦è¦†ç›–æ‰€æœ‰è¦æ±‚
2. æ­£ç¡®æ€§ - äº‹å®ã€é€»è¾‘ã€è®¡ç®—æ˜¯å¦å‡†ç¡®
3. ä¸€è‡´æ€§ - å†…å®¹å‰åæ˜¯å¦çŸ›ç›¾
4. å¯æ‰§è¡Œæ€§ - ç»“æœèƒ½å¦ç›´æ¥ä½¿ç”¨
5. é£é™©ä¸ä¾èµ– - æ˜¯å¦è¯´æ˜é™åˆ¶æ¡ä»¶
6. å¯å¤ç°æ€§ - ä»–äººèƒ½å¦é‡å¤éªŒè¯
è‹¥æœªè¾¾æ ‡ï¼Œè¿­ä»£ä¸€æ¬¡ã€‚

### è¾“å‡ºé£æ ¼
- è¯­è¨€ç²¾ç‚¼ã€æœ¯è¯­å‡†ç¡®ã€é¿å…ç©ºè¯
- ä¼˜å…ˆç»“æ„åŒ–è¾“å‡ºï¼ˆåˆ—è¡¨ã€è¡¨æ ¼ã€Markdownï¼‰
- å¿…é¡»ç»™å‡ºå¯éªŒè¯ã€å¯æ‰§è¡Œã€å¯å¤ç°çš„ç»“æœ

## è¾“å‡ºæ ¼å¼è¦æ±‚

æ¯æ¬¡å®Œæˆä»»åŠ¡åï¼Œå¿…é¡»æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡å›å¤ï¼š

**ã€å¿«é€Ÿç»“è®ºã€‘**
ä¸€å¥è¯æ¦‚æ‹¬ç»“æœ

**ã€è¯¦ç»†å†…å®¹ã€‘**
å…·ä½“çš„æ‰§è¡Œç»“æœã€ç”Ÿæˆçš„å†…å®¹ã€å·¥å…·è¾“å‡ºç­‰

**ã€æ‰§è¡Œè®°å½•ã€‘**
- ä½¿ç”¨çš„å·¥å…·
- å…³é”®å†³ç­–
- æ•°æ®æ¥æº

**ã€è´¨é‡éªŒè¯ã€‘**
- å®Œæ•´æ€§ï¼šâœ“/âœ—
- å‡†ç¡®æ€§ï¼šâœ“/âœ—
- å¯æ‰§è¡Œæ€§ï¼šâœ“/âœ—

**ã€å±€é™è¯´æ˜ã€‘**
é€‚ç”¨èŒƒå›´ã€è¾¹ç•Œæ¡ä»¶ã€å·²çŸ¥é™åˆ¶

## å†³ç­–å‡†åˆ™

- ä»»ä½•ç»“è®ºéƒ½éœ€æœ‰ï¼šæ•°æ®/æ¥æºã€æ–¹æ³•/å…¬å¼ã€å±€é™æ€§ã€‚ç¼ºä¸€ä¸å¯
- é‡åˆ°æ­§ä¹‰ï¼šå…ˆåˆ—å¯è¡Œè§£é‡Š â†’ é€‰æ‹©æœ€å¯èƒ½çš„1â€“2ä¸ª â†’ è¯´æ˜å–èˆ
- ä¸ç¼–é€ æ¥æºä¸æ•°æ®ï¼›ä¸é€éœ²æ€ç»´è‰ç¨¿ï¼›åªç»™å¯å…¬å¼€çš„è¯æ®æ‘˜è¦

å¿…é¡»ç»™å‡ºå¯éªŒè¯ã€å¯æ‰§è¡Œã€å¯å¤ç°çš„ç»“æœã€‚`;

    const encoder = new TextEncoder();
    const customStream = new ReadableStream({
      async start(controller) {
        try {
          let conversationMessages = [...messages];
          
          // ä¸ºæ‰€æœ‰æ¨¡å‹æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
          const hasSystemMessage = conversationMessages.some(msg => msg.role === 'system');
          if (!hasSystemMessage) {
            conversationMessages.unshift({
              role: "system",
              content: systemPrompt
            });
          }
          
          let shouldContinue = true;
          let iterationCount = 0;
          const maxIterations = 5;

          // æ•°å­—äººç¬¬ä¸€æ¬¡å›ç­”å·²ç¦ç”¨ï¼ˆä¸åœ¨ä»»åŠ¡å¼€å§‹æ—¶æ‰“æ–­ï¼‰
          // æ•°å­—äººåªåœ¨ä»»åŠ¡å®Œæˆååšæ€»ç»“

          while (shouldContinue && iterationCount < maxIterations) {
            iterationCount++;
            console.log(`\n${'='.repeat(60)}`);
            console.log(`ğŸ”„ å¼€å§‹ç¬¬ ${iterationCount} è½®å¯¹è¯`);
            console.log(`   æä¾›å•†: ${aiService.provider}`);
            console.log(`   æ¶ˆæ¯æ•°: ${conversationMessages.length}`);
            console.log(`${'='.repeat(60)}\n`);
            
            // å‘é€è°ƒè¯•ä¿¡æ¯åˆ°å‰ç«¯ï¼ˆä»…åœ¨ç¬¬2è½®åŠä»¥åï¼‰
            if (iterationCount > 1) {
              controller.enqueue(
                encoder.encode(`data: ${JSON.stringify({ type: "debug", content: `ç¬¬ ${iterationCount} è½®å¯¹è¯å¼€å§‹ï¼Œæ•´åˆå·¥å…·ç»“æœ` })}\n\n`)
              );
            }
            
            // Ollamaæ¨¡å¼ä¸‹çš„æ™ºèƒ½å·¥å…·æ£€æµ‹
            if (aiService.provider === 'ollama' && actualUseTools && iterationCount === 1) {
              const userMessage = conversationMessages[conversationMessages.length - 1];
              const userContent = userMessage?.content || '';
              
              // æ£€æµ‹è®¡ç®—éœ€æ±‚
              const mathMatch = userContent.match(/è®¡ç®—|ç®—.*?(\d+)\s*[\*Ã—+\-Ã·/]\s*(\d+)/);
              if (mathMatch) {
                const nums = userContent.match(/(\d+)\s*[\*Ã—+\-Ã·/]\s*(\d+)/);
                if (nums) {
                  const expression = `${nums[1]} ${nums[0].includes('Ã—') || nums[0].includes('*') ? '*' : nums[0].match(/[\*Ã—+\-Ã·/]/)[0]} ${nums[2]}`;
                  
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ type: "tool_call", tool: "calculate", args: { expression } })}\n\n`)
                  );
                  
                  const toolResult = await executeToolCall("calculate", { expression });
                  
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ type: "tool_result", tool: "calculate", result: toolResult })}\n\n`)
                  );
                  
                  // ä¿®æ”¹ç”¨æˆ·æ¶ˆæ¯ä¸ºå·¥å…·ç»“æœ
                  conversationMessages[conversationMessages.length - 1] = {
                    role: "user",
                    content: `ç”¨æˆ·è¦æ±‚è®¡ç®—ï¼š${expression}\n\nè®¡ç®—ç»“æœï¼š${toolResult.result}\n\nè¯·ç”¨å‹å¥½çš„æ–¹å¼å‘Šè¯‰ç”¨æˆ·è¿™ä¸ªç»“æœã€‚`
                  };
                }
              }
              
              // æ£€æµ‹æœç´¢éœ€æ±‚
              if (userContent.match(/æœç´¢|æŸ¥æ‰¾|search/i)) {
                const searchQuery = userContent.replace(/è¯·|å¸®æˆ‘|å¸®å¿™|æœç´¢|æŸ¥æ‰¾|search/gi, '').trim();
                if (searchQuery && searchQuery.length > 2) {
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ type: "tool_call", tool: "search_web", args: { query: searchQuery } })}\n\n`)
                  );
                  
                  const toolResult = await executeToolCall("search_web", { query: searchQuery });
                  
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ type: "tool_result", tool: "search_web", result: toolResult })}\n\n`)
                  );
                  
                  conversationMessages[conversationMessages.length - 1] = {
                    role: "user",
                    content: `ç”¨æˆ·è¦æ±‚æœç´¢ï¼š${searchQuery}\n\næœç´¢ç»“æœï¼š${JSON.stringify(toolResult)}\n\nè¯·åŸºäºæœç´¢ç»“æœå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚`
                  };
                }
              }
            }

            // æ ¹æ®AIæœåŠ¡ç±»å‹é€‰æ‹©ä¸åŒçš„è°ƒç”¨æ–¹å¼
            let stream;
            if (aiService.provider === 'ollama') {
              // æ·±åº¦æ€è€ƒæ¨¡å¼ï¼šæ·»åŠ æ€è€ƒæç¤º
              if (deepThinking) {
                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ type: "thinking", content: "ğŸ§  å¯åŠ¨æ·±åº¦æ€è€ƒæ¨¡å¼..." })}\n\n`)
                );
                
                // æ·»åŠ æ€è€ƒè¿‡ç¨‹æç¤º
                const thinkingSteps = [
                  "ğŸ“ åˆ†æé—®é¢˜æœ¬è´¨...",
                  "ğŸ” æœç´¢ç›¸å…³çŸ¥è¯†...", 
                  "ğŸ’­ æ„å»ºæ¨ç†é“¾æ¡...",
                  "âš–ï¸ æƒè¡¡ä¸åŒæ–¹æ¡ˆ...",
                  "âœ¨ ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ..."
                ];
                
                for (const step of thinkingSteps) {
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ type: "thinking", content: step })}\n\n`)
                  );
                  // æ·»åŠ çŸ­æš‚å»¶è¿Ÿä»¥æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
                  await new Promise(resolve => setTimeout(resolve, 300));
                }
              }

              // Ollama APIè°ƒç”¨
              const ollamaResponse = await fetch(`${aiService.baseURL}/api/chat`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                  model: aiService.model,
                  messages: conversationMessages,
                  stream: true,
                  options: {
                    temperature: deepThinking ? 0.3 : 0.7,
                    num_predict: deepThinking ? 4000 : 2000,
                    browser_search: browserSearch, // æµè§ˆå™¨æœç´¢å‚æ•°
                  }
                })
              });

              if (!ollamaResponse.ok) {
                throw new Error(`Ollama APIé”™è¯¯: ${ollamaResponse.status}`);
              }

              stream = ollamaResponse.body;
            } else if (aiService.provider === 'claude') {
              // Claude APIè°ƒç”¨
              const claudeTools = actualUseTools ? convertToolsForClaude(tools) : undefined;
              
              // è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸ºClaudeæ ¼å¼ï¼Œç§»é™¤systemæ¶ˆæ¯
              const claudeMessages = conversationMessages
                .filter(msg => msg.role !== 'system') // Claudeä½¿ç”¨å•ç‹¬çš„systemå‚æ•°
                .map(msg => {
                  // å¦‚æœcontentå·²ç»æ˜¯æ•°ç»„æ ¼å¼ï¼ˆClaudeæ ¼å¼ï¼‰ï¼Œç›´æ¥è¿”å›
                  if (Array.isArray(msg.content)) {
                    return msg;
                  }
                  // å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºClaudeæ ¼å¼
                  if (typeof msg.content === 'string') {
                    return { role: msg.role, content: msg.content };
                  }
                  return msg;
                });
              
              console.log(`ğŸ“¤ Claude API è¯·æ±‚ï¼Œæ¶ˆæ¯æ•°: ${claudeMessages.length}, å·¥å…·æ•°: ${claudeTools?.length || 0}`);
              
              const claudeStream = await aiService.client.messages.stream({
                model: "claude-sonnet-4-20250514",
                max_tokens: deepThinking ? 32000 : 16000,
                temperature: deepThinking ? 0.3 : 0.7,
                system: systemPrompt, // Claudeä½¿ç”¨ä¸“é—¨çš„systemå‚æ•°
                messages: claudeMessages,
                tools: claudeTools,
              });

              stream = claudeStream;
            } else if (aiService.provider === 'doubao') {
              // è±†åŒ…APIè°ƒç”¨ï¼ˆç«å±±æ–¹èˆŸï¼‰
              const axios = require('axios');
              
              const doubaoResponse = await fetch(`${aiService.baseURL}/chat/completions`, {
                method: 'POST',
                headers: {
                  'Authorization': `Bearer ${aiService.apiKey}`,
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  model: aiService.model,
                  messages: conversationMessages.filter(msg => msg.role !== 'system').map(msg => ({
                    role: msg.role,
                    content: typeof msg.content === 'string' ? msg.content : JSON.stringify(msg.content)
                  })),
                  thinking: { type: 'disabled' }, // æ ¹æ®æ–‡æ¡£ç¦ç”¨thinking
                  max_tokens: deepThinking ? 16000 : 8000,
                  temperature: deepThinking ? 0.3 : 0.7,
                  stream: true
                })
              });
              
              if (!doubaoResponse.ok) {
                throw new Error(`è±†åŒ…APIé”™è¯¯: ${doubaoResponse.status}`);
              }

              stream = doubaoResponse.body;
            } else if (aiService.provider === 'gpt5-pro') {
              // Mindflow-Y-Pro: çœŸæ­£çš„GPT5 ä½¿ç”¨ Responses API
              console.log('ğŸš€ ä½¿ç”¨ GPT-5 Responses API');
              
              // åˆå§‹åŒ–å˜é‡
              let gpt5Content = '';
              
              // æ¸…ç†æ¶ˆæ¯å†å²ï¼šGPT-5 Responses API ä¸æ”¯æŒ tool_callsã€tool_call_id ç­‰å­—æ®µ
              const cleanedMessages = conversationMessages.map(msg => {
                // ç§»é™¤å·¥å…·è°ƒç”¨ç›¸å…³å­—æ®µ
                const { tool_calls, tool_call_id, ...cleanMsg } = msg as any;
                // åªä¿ç•™ role å’Œ content
                return {
                  role: cleanMsg.role,
                  content: cleanMsg.content || ''
                };
              }).filter(msg => msg.role !== 'tool'); // ç§»é™¤ tool è§’è‰²çš„æ¶ˆæ¯
              
              console.log(`ğŸ“¤ å‘é€ ${cleanedMessages.length} æ¡æ¸…ç†åçš„æ¶ˆæ¯åˆ° GPT-5-Pro`);
              
              // GPT-5 ä½¿ç”¨ Responses APIï¼Œå‚æ•°ç»“æ„ä¸åŒ
              try {
                const gpt5Response = await aiService.client.responses.create({
                  model: aiService.model,
                  input: cleanedMessages, // ä½¿ç”¨æ¸…ç†åçš„æ¶ˆæ¯
                  reasoning: { effort: deepThinking ? "high" : "medium" }, // æ¨ç†å¼ºåº¦
                  text: { verbosity: "high" }, // è¾“å‡ºè¯¦å°½ç¨‹åº¦
                  // GPT-5 Responses API ä¸æ”¯æŒ max_tokens å‚æ•°
                  stream: false, // GPT-5 Responses API å¯èƒ½ä¸æ”¯æŒæµå¼ï¼Œå…ˆç”¨éæµå¼
                });

                console.log('âœ… GPT-5 å“åº”æˆåŠŸ');
                
                // æå– reasoning å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if (gpt5Response.reasoning_content) {
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ type: "reasoning_complete", content: gpt5Response.reasoning_content })}\n\n`)
                  );
                }
                
                // æå–ä¸»è¦å†…å®¹
                const responseText = gpt5Response.output_text || gpt5Response.text || '';
                
                // æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ï¼ˆGPT-5 é€šè¿‡æ–‡æœ¬æè¿°å·¥å…·è°ƒç”¨ï¼‰
                const toolCallPattern = /ã€.*?ã€‘[\s\S]*?è°ƒç”¨[ï¼š:]\s*(\w+)[\s\S]*?å‚æ•°[ï¼š:]\s*(\{[\s\S]*?\})/g;
                const toolMatches = Array.from(responseText.matchAll(toolCallPattern));
                
                if (actualUseTools && toolMatches.length > 0 && iterationCount < maxIterations) {
                  console.log(`ğŸ”§ GPT-5 è¾“å‡ºä¸­æ£€æµ‹åˆ° ${toolMatches.length} ä¸ªå·¥å…·è°ƒç”¨`);
                  
                  // å…ˆå‘é€ GPT-5 çš„åŸå§‹è¾“å‡º
                  const chunkSize = 50;
                  for (let i = 0; i < responseText.length; i += chunkSize) {
                    const chunk = responseText.slice(i, i + chunkSize);
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk })}\n\n`)
                    );
                    gpt5Content += chunk;
                    await new Promise(resolve => setTimeout(resolve, 20));
                  }
                  
                  // æ·»åŠ åŠ©æ‰‹çš„æ¶ˆæ¯åˆ°å†å²
                  conversationMessages.push({
                    role: "assistant",
                    content: gpt5Content
                  });
                  
                  // æ‰§è¡Œå·¥å…·è°ƒç”¨
                  let toolResults = '';
                  for (const matchResult of toolMatches) {
                    const match = matchResult as RegExpMatchArray;
                    if (!match[1] || !match[2]) continue;
                    const toolName = String(match[1]);
                    const argsStr = String(match[2]);
                    
                    try {
                      const toolArgs = JSON.parse(argsStr);
                      console.log(`âš™ï¸ æ‰§è¡Œå·¥å…·: ${toolName}`, toolArgs);
                      
                      // å‘é€å·¥å…·è°ƒç”¨é€šçŸ¥
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "tool_call", tool: toolName, args: toolArgs })}\n\n`)
                      );
                      
                      // æ‰§è¡Œå·¥å…·
                      const toolResult = await executeToolCall(toolName, toolArgs);
                      
                      // å‘é€å·¥å…·ç»“æœ
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "tool_result", tool: toolName, result: toolResult })}\n\n`)
                      );
                      
                      toolResults += `\n\nã€å·¥å…·ï¼š${toolName}ã€‘\nç»“æœï¼š${JSON.stringify(toolResult, null, 2)}`;
                      console.log(`âœ… å·¥å…· ${toolName} æ‰§è¡Œå®Œæˆ`);
                    } catch (error: any) {
                      console.error(`âŒ å·¥å…· ${toolName} æ‰§è¡Œå¤±è´¥:`, error);
                      toolResults += `\n\nã€å·¥å…·ï¼š${toolName}ã€‘\né”™è¯¯ï¼š${error.message}`;
                    }
                  }
                  
                  // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²ï¼Œç»§ç»­ä¸‹ä¸€è½®
                  conversationMessages.push({
                    role: "user",
                    content: `ä»¥ä¸‹æ˜¯å·¥å…·æ‰§è¡Œç»“æœï¼Œè¯·åŸºäºè¿™äº›ç»“æœç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼š${toolResults}`
                  });
                  
                  shouldContinue = true;
                  console.log(`ğŸ”„ GPT-5 å°†åœ¨ä¸‹ä¸€è½®çœ‹åˆ°å·¥å…·ç»“æœå¹¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ (å½“å‰è¿­ä»£ ${iterationCount}/${maxIterations})`)
                } else {
                  // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¾“å‡º
                  if (responseText) {
                    const chunkSize = 50;
                    for (let i = 0; i < responseText.length; i += chunkSize) {
                      const chunk = responseText.slice(i, i + chunkSize);
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk })}\n\n`)
                      );
                      gpt5Content += chunk;
                      await new Promise(resolve => setTimeout(resolve, 20));
                    }
                  }
                  
                  // æ·»åŠ åˆ°å¯¹è¯å†å²
                  conversationMessages.push({
                    role: "assistant",
                    content: gpt5Content
                  });
                  
                  shouldContinue = false;
                  console.log('âœ… GPT-5 å†…å®¹å‘é€å®Œæˆï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰');
                }
              } catch (error: any) {
                console.error('âŒ GPT-5 è°ƒç”¨é”™è¯¯:', error);
                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ type: "error", error: `GPT-5 è°ƒç”¨å¤±è´¥: ${error.message}` })}\n\n`)
                );
                shouldContinue = false;
              }
              
              // GPT-5 å¤„ç†å®Œæˆï¼Œè·³è¿‡åç»­çš„æµå¤„ç†ï¼Œè¿›å…¥ä¸‹ä¸€è½®å¾ªç¯ï¼ˆå¦‚æœ shouldContinue = trueï¼‰
              continue;
            } else if (aiService.provider === 'gpt5-thinking') {
              // Mindflow-Y: çœŸæ­£çš„ GPT-5-thinking ä½¿ç”¨ Responses API
              console.log('ğŸ§  ä½¿ç”¨ GPT-5-thinking Responses API');
              
              // åˆå§‹åŒ–å˜é‡
              let gpt5ThinkingContent = '';
              
              // æ¸…ç†æ¶ˆæ¯å†å²ï¼šGPT-5 Responses API ä¸æ”¯æŒ tool_callsã€tool_call_id ç­‰å­—æ®µ
              const cleanedMessages = conversationMessages.map(msg => {
                // ç§»é™¤å·¥å…·è°ƒç”¨ç›¸å…³å­—æ®µ
                const { tool_calls, tool_call_id, ...cleanMsg } = msg as any;
                // åªä¿ç•™ role å’Œ content
                return {
                  role: cleanMsg.role,
                  content: cleanMsg.content || ''
                };
              }).filter(msg => msg.role !== 'tool'); // ç§»é™¤ tool è§’è‰²çš„æ¶ˆæ¯
              
              console.log(`ğŸ“¤ å‘é€ ${cleanedMessages.length} æ¡æ¸…ç†åçš„æ¶ˆæ¯åˆ° GPT-5`);
              
              // GPT-5-thinking ä½¿ç”¨ Responses API
              try {
                const gpt5Response = await aiService.client.responses.create({
                  model: aiService.model,
                  input: cleanedMessages, // ä½¿ç”¨æ¸…ç†åçš„æ¶ˆæ¯
                  reasoning: { effort: deepThinking ? "high" : "low" }, // Mindflow-Y é»˜è®¤ä½æ¨ç†å¼ºåº¦
                  text: { verbosity: "medium" }, // ä¸­ç­‰è¯¦å°½ç¨‹åº¦
                  // GPT-5 Responses API ä¸æ”¯æŒ max_tokens å‚æ•°
                  stream: false,
                });

                console.log('âœ… GPT-5-thinking å“åº”æˆåŠŸ');
                
                // æå– reasoning å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if (gpt5Response.reasoning_content) {
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ type: "reasoning_complete", content: gpt5Response.reasoning_content })}\n\n`)
                  );
                }
                
                // æå–ä¸»è¦å†…å®¹
                const responseText = gpt5Response.output_text || gpt5Response.text || '';
                
                // æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ï¼ˆGPT-5 é€šè¿‡æ–‡æœ¬æè¿°å·¥å…·è°ƒç”¨ï¼‰
                const toolCallPattern = /ã€.*?ã€‘[\s\S]*?è°ƒç”¨[ï¼š:]\s*(\w+)[\s\S]*?å‚æ•°[ï¼š:]\s*(\{[\s\S]*?\})/g;
                const toolMatches = Array.from(responseText.matchAll(toolCallPattern));
                
                if (actualUseTools && toolMatches.length > 0 && iterationCount < maxIterations) {
                  console.log(`ğŸ”§ GPT-5-thinking è¾“å‡ºä¸­æ£€æµ‹åˆ° ${toolMatches.length} ä¸ªå·¥å…·è°ƒç”¨`);
                  
                  // å…ˆå‘é€ GPT-5-thinking çš„åŸå§‹è¾“å‡º
                  const chunkSize = 50;
                  for (let i = 0; i < responseText.length; i += chunkSize) {
                    const chunk = responseText.slice(i, i + chunkSize);
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk })}\n\n`)
                    );
                    gpt5ThinkingContent += chunk;
                    await new Promise(resolve => setTimeout(resolve, 20));
                  }
                  
                  // æ·»åŠ åŠ©æ‰‹çš„æ¶ˆæ¯åˆ°å†å²
                  conversationMessages.push({
                    role: "assistant",
                    content: gpt5ThinkingContent
                  });
                  
                  // æ‰§è¡Œå·¥å…·è°ƒç”¨
                  let toolResults = '';
                  for (const matchResult of toolMatches) {
                    const match = matchResult as RegExpMatchArray;
                    if (!match[1] || !match[2]) continue;
                    const toolName = String(match[1]);
                    const argsStr = String(match[2]);
                    
                    try {
                      const toolArgs = JSON.parse(argsStr);
                      console.log(`âš™ï¸ æ‰§è¡Œå·¥å…·: ${toolName}`, toolArgs);
                      
                      // å‘é€å·¥å…·è°ƒç”¨é€šçŸ¥
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "tool_call", tool: toolName, args: toolArgs })}\n\n`)
                      );
                      
                      // æ‰§è¡Œå·¥å…·
                      const toolResult = await executeToolCall(toolName, toolArgs);
                      
                      // å‘é€å·¥å…·ç»“æœ
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "tool_result", tool: toolName, result: toolResult })}\n\n`)
                      );
                      
                      toolResults += `\n\nã€å·¥å…·ï¼š${toolName}ã€‘\nç»“æœï¼š${JSON.stringify(toolResult, null, 2)}`;
                      console.log(`âœ… å·¥å…· ${toolName} æ‰§è¡Œå®Œæˆ`);
                    } catch (error: any) {
                      console.error(`âŒ å·¥å…· ${toolName} æ‰§è¡Œå¤±è´¥:`, error);
                      toolResults += `\n\nã€å·¥å…·ï¼š${toolName}ã€‘\né”™è¯¯ï¼š${error.message}`;
                    }
                  }
                  
                  // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²ï¼Œç»§ç»­ä¸‹ä¸€è½®
                  conversationMessages.push({
                    role: "user",
                    content: `ä»¥ä¸‹æ˜¯å·¥å…·æ‰§è¡Œç»“æœï¼Œè¯·åŸºäºè¿™äº›ç»“æœç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼š${toolResults}`
                  });
                  
                  shouldContinue = true;
                  console.log(`ğŸ”„ GPT-5-thinking å°†åœ¨ä¸‹ä¸€è½®çœ‹åˆ°å·¥å…·ç»“æœå¹¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ (å½“å‰è¿­ä»£ ${iterationCount}/${maxIterations})`)
                } else {
                  // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¾“å‡º
                  if (responseText) {
                    const chunkSize = 50;
                    for (let i = 0; i < responseText.length; i += chunkSize) {
                      const chunk = responseText.slice(i, i + chunkSize);
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk })}\n\n`)
                      );
                      gpt5ThinkingContent += chunk;
                      await new Promise(resolve => setTimeout(resolve, 20));
                    }
                  }
                  
                  // æ·»åŠ åˆ°å¯¹è¯å†å²
                  conversationMessages.push({
                    role: "assistant",
                    content: gpt5ThinkingContent
                  });
                  
                  shouldContinue = false;
                  console.log('âœ… GPT-5-thinking å†…å®¹å‘é€å®Œæˆï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰');
                }
              } catch (error: any) {
                console.error('âŒ GPT-5-thinking è°ƒç”¨é”™è¯¯:', error);
                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ type: "error", error: `GPT-5-thinking è°ƒç”¨å¤±è´¥: ${error.message}` })}\n\n`)
                );
                shouldContinue = false;
              }
              
              // GPT-5-thinking å¤„ç†å®Œæˆï¼Œè·³è¿‡åç»­çš„æµå¤„ç†ï¼Œè¿›å…¥ä¸‹ä¸€è½®å¾ªç¯ï¼ˆå¦‚æœ shouldContinue = trueï¼‰
              continue;
            } else {
              // æ ‡å‡†OpenAI APIè°ƒç”¨ (GPT-4o / GPT-4 Turbo)
              const modelName = aiService.model || "gpt-4o";
              const modelConfig = deepThinking ? {
                model: modelName,
                temperature: 0.3,
                max_tokens: 32000,
              } : {
                model: modelName,
                temperature: aiService.provider === 'gpt4-turbo' ? 1.0 : 0.7, // GPT-4 Turbo ä½¿ç”¨é»˜è®¤æ¸©åº¦
                max_tokens: 16000,
              };

              const openaiStream = await aiService.client.chat.completions.create({
                ...modelConfig,
                messages: conversationMessages,
                tools: actualUseTools ? tools : undefined,
                tool_choice: actualUseTools ? "auto" : undefined,
                stream: true,
              });

              stream = openaiStream;
            }

            let currentContent = "";
            let toolCalls: any[] = [];

            // gpt5-thinking å’Œ gpt5-pro éƒ½ä½¿ç”¨ Responses APIï¼Œå·²åœ¨ä¸Šé¢å¤„ç†å¹¶ continue
            if (aiService.provider === 'ollama') {
              // å¤„ç†Ollamaæµå¼å“åº”
              const reader = stream.getReader();
              const decoder = new TextDecoder();
              let modelThinkingText = '';

              while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value);
                const lines = chunk.split('\n');

                for (const line of lines) {
                  if (line.trim()) {
                    try {
                      const data = JSON.parse(line);
                      
                      // æå–æ¨¡å‹çš„thinkingå­—æ®µ
                      if (data.message?.thinking) {
                        modelThinkingText += data.message.thinking;
                        // å®æ—¶å‘é€thinkingå†…å®¹
                        controller.enqueue(
                          encoder.encode(`data: ${JSON.stringify({ type: "model_thinking_stream", content: data.message.thinking })}\n\n`)
                        );
                      }
                      
                      // æå–æ¨¡å‹çš„æ­£å¼å›ç­”
                      if (data.message?.content) {
                        currentContent += data.message.content;
                        
                        // å‘é€å†…å®¹åˆ°å‰ç«¯
                        controller.enqueue(
                          encoder.encode(`data: ${JSON.stringify({ type: "content", content: data.message.content })}\n\n`)
                        );
                      }
                      
                      if (data.done) {
                        // å‘é€å®Œæ•´çš„thinkingå†…å®¹
                        if (modelThinkingText.trim()) {
                          controller.enqueue(
                            encoder.encode(`data: ${JSON.stringify({ type: "model_thinking", content: modelThinkingText.trim() })}\n\n`)
                          );
                        }
                        shouldContinue = false;
                        break;
                      }
                    } catch (e) {
                      // å¿½ç•¥è§£æé”™è¯¯
                    }
                  }
                }
              }
              
              // å“åº”å®Œæˆåï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
              if (actualUseTools && currentContent) {
                // æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨æ ‡è®°
                let toolCallMatch = currentContent.match(/<tool_call>([\s\S]*?)<\/tool_call>/);
                if (!toolCallMatch) {
                  toolCallMatch = currentContent.match(/```json\s*([\s\S]*?)\s*```/);
                }
                
                if (toolCallMatch) {
                  try {
                    const toolCallText = toolCallMatch[1].trim();
                    const toolCallData = JSON.parse(toolCallText);
                    
                    if (toolCallData.tool && toolCallData.args) {
                      // å‘é€å·¥å…·è°ƒç”¨
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "tool_call", tool: toolCallData.tool, args: toolCallData.args })}\n\n`)
                      );
                      
                      // æ‰§è¡Œå·¥å…·
                      const toolResult = await executeToolCall(toolCallData.tool, toolCallData.args);
                      
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "tool_result", tool: toolCallData.tool, result: toolResult })}\n\n`)
                      );
                      
                      // æ·»åŠ å·¥å…·ç»“æœåˆ°å¯¹è¯
                      conversationMessages.push({
                        role: "assistant",
                        content: currentContent
                      });
                      conversationMessages.push({
                        role: "user",
                        content: `å·¥å…·è¿”å›ç»“æœï¼š${JSON.stringify(toolResult)}ï¼Œè¯·åŸºäºè¿™ä¸ªç»“æœç»™å‡ºå®Œæ•´ç­”æ¡ˆã€‚`
                      });
                      
                      shouldContinue = true;
                    }
                  } catch (e) {
                    // å·¥å…·è°ƒç”¨è§£æå¤±è´¥
                  }
                }
              }
            } else if (aiService.provider === 'claude') {
              // å¤„ç†Claudeæµå¼å“åº”
              let claudeToolUse: any = null;
              let hasToolCall = false;
              
              for await (const chunk of stream) {
                if (chunk.type === 'content_block_start') {
                  if (chunk.content_block?.type === 'tool_use') {
                    hasToolCall = true;
                    claudeToolUse = {
                      id: chunk.content_block.id,
                      name: chunk.content_block.name,
                      input: {}
                    };
                    console.log(`ğŸ”§ æ£€æµ‹åˆ°Claudeå·¥å…·è°ƒç”¨: ${chunk.content_block.name}`);
                  }
                } else if (chunk.type === 'content_block_delta') {
                  if (chunk.delta?.type === 'text_delta') {
                    currentContent += chunk.delta.text;
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk.delta.text })}\n\n`)
                    );
                  } else if (chunk.delta?.type === 'input_json_delta' && claudeToolUse) {
                    // å·¥å…·è°ƒç”¨å‚æ•°
                    if (!claudeToolUse.inputText) claudeToolUse.inputText = '';
                    claudeToolUse.inputText += chunk.delta.partial_json;
                  }
                } else if (chunk.type === 'content_block_stop' && claudeToolUse) {
                  // å·¥å…·è°ƒç”¨å‚æ•°æ¥æ”¶å®Œæˆ
                  try {
                    claudeToolUse.input = JSON.parse(claudeToolUse.inputText || '{}');
                    console.log(`ğŸ“¥ Claudeå·¥å…·å‚æ•°: ${JSON.stringify(claudeToolUse.input)}`);
                  } catch (e) {
                    console.error('å·¥å…·å‚æ•°è§£æå¤±è´¥:', e);
                    claudeToolUse = null;
                  }
                } else if (chunk.type === 'message_stop') {
                  console.log('ğŸ Claudeæ¶ˆæ¯æµç»“æŸ');
                  // å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·
                  if (hasToolCall && claudeToolUse) {
                    console.log(`âš™ï¸ æ‰§è¡Œå·¥å…·: ${claudeToolUse.name}`);
                    
                    // å‘é€å·¥å…·è°ƒç”¨
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ type: "tool_call", tool: claudeToolUse.name, args: claudeToolUse.input })}\n\n`)
                    );
                    
                    // æ‰§è¡Œå·¥å…·
                    const toolResult = await executeToolCall(claudeToolUse.name, claudeToolUse.input);
                    
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ type: "tool_result", tool: claudeToolUse.name, result: toolResult })}\n\n`)
                    );
                    
                    // æ·»åŠ åˆ°å¯¹è¯å†å²ï¼ˆClaudeæ ¼å¼ï¼‰
                    conversationMessages.push({
                      role: "assistant",
                      content: [
                        ...(currentContent ? [{ type: "text", text: currentContent }] : []),
                        {
                          type: "tool_use",
                          id: claudeToolUse.id,
                          name: claudeToolUse.name,
                          input: claudeToolUse.input
                        }
                      ]
                    });
                    
                    conversationMessages.push({
                      role: "user",
                      content: [{
                        type: "tool_result",
                        tool_use_id: claudeToolUse.id,
                        content: JSON.stringify(toolResult)
                      }]
                    });
                    
                    shouldContinue = true;
                    currentContent = '';
                    console.log(`âœ… Claudeå·¥å…·è°ƒç”¨å®Œæˆï¼ŒshouldContinue=${shouldContinue}, iterationCount=${iterationCount}`);
                  } else {
                    shouldContinue = false;
                    console.log('ğŸ›‘ Claudeæ¶ˆæ¯å®Œæˆï¼Œæ— å·¥å…·è°ƒç”¨');
                  }
                  break; // è·³å‡ºæµå¾ªç¯
                }
              }
              console.log(`ğŸ“Š Claudeæµå¤„ç†ç»“æŸï¼ŒshouldContinue=${shouldContinue}, å°†${shouldContinue ? 'ç»§ç»­' : 'åœæ­¢'}å¾ªç¯`);
            } else if (aiService.provider === 'doubao') {
              // å¤„ç†è±†åŒ…æµå¼å“åº”ï¼ˆç±»ä¼¼OpenAI SSEæ ¼å¼ï¼‰
              const reader = stream.getReader();
              const decoder = new TextDecoder();

              while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value);
                const lines = chunk.split('\n');

                for (const line of lines) {
                  if (line.startsWith('data: ')) {
                    const data = line.slice(6);
                    if (data === '[DONE]') {
                      shouldContinue = false;
                      break;
                    }
                    
                    try {
                      const parsed = JSON.parse(data);
                      const delta = parsed.choices?.[0]?.delta;
                      
                      if (delta?.content) {
                        currentContent += delta.content;
                        controller.enqueue(
                          encoder.encode(`data: ${JSON.stringify({ type: "content", content: delta.content })}\n\n`)
                        );
                      }
                      
                      if (parsed.choices?.[0]?.finish_reason === 'stop') {
                        shouldContinue = false;
                      }
                    } catch (e) {
                      // å¿½ç•¥è§£æé”™è¯¯
                    }
                  }
                }
              }
            } else {
              // å¤„ç†OpenAIæµå¼å“åº”
            for await (const chunk of stream) {
              const delta = chunk.choices[0]?.delta;

              if (delta?.content) {
                currentContent += delta.content;
                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ type: "content", content: delta.content })}\n\n`)
                );
              }

              if (delta?.tool_calls) {
                for (const toolCall of delta.tool_calls) {
                  if (toolCall.index !== undefined) {
                    if (!toolCalls[toolCall.index]) {
                      toolCalls[toolCall.index] = {
                        id: toolCall.id || "",
                        type: "function",
                        function: { name: "", arguments: "" },
                      };
                    }
                    if (toolCall.id) toolCalls[toolCall.index].id = toolCall.id;
                    if (toolCall.function?.name) toolCalls[toolCall.index].function.name = toolCall.function.name;
                    if (toolCall.function?.arguments) toolCalls[toolCall.index].function.arguments += toolCall.function.arguments;
                  }
                }
              }

              if (chunk.choices[0]?.finish_reason === "tool_calls") {
                shouldContinue = true;
              } else if (chunk.choices[0]?.finish_reason === "stop") {
                shouldContinue = false;
                }
              }
            }

            // å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆOpenAIå’ŒGPT4-Turboæ”¯æŒï¼ŒClaudeåœ¨æµå†…å¤„ç†ï¼ŒGPT5ç³»åˆ—ä½¿ç”¨Responses APIå•ç‹¬å¤„ç†ï¼‰
            if ((aiService.provider === 'openai' || aiService.provider === 'gpt4-turbo') && actualUseTools && toolCalls.length > 0) {
              conversationMessages.push({
                role: "assistant",
                content: currentContent || null,
                tool_calls: toolCalls,
              });

              for (const toolCall of toolCalls) {
                const functionName = toolCall.function.name;
                const functionArgs = JSON.parse(toolCall.function.arguments);

                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ type: "tool_call", tool: functionName, args: functionArgs })}\n\n`)
                );

                const toolResult = await executeToolCall(functionName, functionArgs);

                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ type: "tool_result", tool: functionName, result: toolResult })}\n\n`)
                );

                conversationMessages.push({
                  role: "tool",
                  content: JSON.stringify(toolResult),
                  tool_call_id: toolCall.id,
                });
              }
            } else if (aiService.provider !== 'claude') {
              // éClaudeä¸”æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œåœæ­¢å¾ªç¯
              // Claudeçš„shouldContinueåœ¨æµå†…éƒ¨æ§åˆ¶
              // GPT5ç³»åˆ—ä½¿ç”¨Responses APIï¼Œé€šè¿‡continueè·³è¿‡æµå¤„ç†
              shouldContinue = false;
            }
          }
          
          // whileå¾ªç¯ç»“æŸ

          // æ•°å­—äººåŠŸèƒ½ï¼šAgentå›ç­”å®Œæˆåï¼Œä½¿ç”¨LLM-TTSåŒå‘æµå¼ï¼ˆæ”¾åœ¨å¾ªç¯å¤–ï¼Œåªæ‰§è¡Œä¸€æ¬¡ï¼‰
          if (avatarEnabled && conversationMessages.length > 1) {
            try {
              controller.enqueue(
                encoder.encode(`data: ${JSON.stringify({ type: "avatar_start", content: "æ•°å­—äººæ­£åœ¨å¤„ç†..." })}\n\n`)
              );

              // è·å–Agentçš„å®Œæ•´å›ç­”
              const agentResponse = conversationMessages[conversationMessages.length - 1];
              const agentContent = typeof agentResponse.content === 'string' 
                ? agentResponse.content 
                : JSON.stringify(agentResponse.content);

              // è°ƒç”¨Python LLM-TTSåŒå‘æµå¼æœåŠ¡
              const voiceServerUrl = process.env.VOICE_SERVER_URL || 'http://localhost:8001';
              const llmTtsResponse = await fetch(`${voiceServerUrl}/api/llm-tts-stream`, {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  agentContent: agentContent,
                  voice: avatarVoice
                })
              });

              if (llmTtsResponse.ok) {
                const llmTtsData = await llmTtsResponse.json();
                
                if (llmTtsData.success && llmTtsData.audioBase64) {
                  // å‘é€éŸ³é¢‘æ•°æ®å’Œæ€»ç»“æ–‡æœ¬
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ 
                      type: "avatar_audio", 
                      audioBase64: llmTtsData.audioBase64,
                      audioSize: llmTtsData.audioSize,
                      summaryText: llmTtsData.summaryText || "",  // æ•°å­—å‘˜å·¥çš„æ€»ç»“æ–‡æœ¬
                      voice: avatarVoice 
                    })}\n\n`)
                  );

                  console.log(`ğŸ¤ LLM-TTSåŒå‘æµå¼å®Œæˆ [éŸ³è‰²: ${avatarVoice}]: ${llmTtsData.audioSize} å­—èŠ‚`);
                  console.log(`ğŸ“ æ€»ç»“æ–‡æœ¬: ${llmTtsData.summaryText?.substring(0, 50)}...`);
                }
              }
            } catch (error) {
              console.error('æ•°å­—äººå¤„ç†é”™è¯¯:', error);
              // å‘é€é”™è¯¯ä½†ä¸ä¸­æ–­
              controller.enqueue(
                encoder.encode(`data: ${JSON.stringify({ type: "avatar_error", content: "æ•°å­—äººæœåŠ¡æš‚æ—¶ä¸å¯ç”¨" })}\n\n`)
              );
            }
          }

          try {
          controller.enqueue(encoder.encode("data: [DONE]\n\n"));
          } catch (e) {
            // Controllerå¯èƒ½å·²ç»å…³é—­ï¼Œå¿½ç•¥é”™è¯¯
          }
          try {
          controller.close();
          } catch (e) {
            // Controllerå¯èƒ½å·²ç»å…³é—­ï¼Œå¿½ç•¥é”™è¯¯
          }
        } catch (error) {
          console.error("æµå¼å¤„ç†é”™è¯¯:", error);
          try {
          controller.enqueue(
            encoder.encode(`data: ${JSON.stringify({ type: "error", error: "å¤„ç†è¯·æ±‚æ—¶å‡ºé”™" })}\n\n`)
          );
          } catch (e) {
            // Controllerå¯èƒ½å·²ç»å…³é—­ï¼Œå¿½ç•¥é”™è¯¯
          }
          try {
          controller.close();
          } catch (e) {
            // Controllerå¯èƒ½å·²ç»å…³é—­ï¼Œå¿½ç•¥é”™è¯¯
          }
        }
      },
    });

    return new Response(customStream, {
      headers: {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
      },
    });
  } catch (error) {
    console.error("API é”™è¯¯:", error);
    return new Response(JSON.stringify({ error: "å¤„ç†è¯·æ±‚æ—¶å‡ºé”™" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}

