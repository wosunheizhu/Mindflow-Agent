import { NextRequest } from "next/server";
import OpenAI from "openai";
import Anthropic from "@anthropic-ai/sdk";

// åŠ¨æ€å¯¼å…¥AIæœåŠ¡
const getAIService = () => {
  const provider = process.env.AI_PROVIDER || 'openai';
  
  if (provider === 'claude') {
    return {
      client: new Anthropic({
        apiKey: process.env.ANTHROPIC_API_KEY!,
      }),
      provider: 'claude'
    };
  } else if (provider === 'doubao') {
    return {
      baseURL: 'https://ark.cn-beijing.volces.com/api/v3',
      apiKey: process.env.ARK_API_KEY!,
      model: 'doubao-seed-1-6-flash-250828',
      provider: 'doubao'
    };
  } else {
    return {
      client: new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
      }),
      provider: 'openai'
    };
  }
};

export const runtime = 'nodejs';
export const dynamic = 'force-dynamic';

// å¯¼å…¥æ‰€æœ‰å·¥å…·
import { tools, executeToolCall } from '../../../lib/tools-complete';

// å°†OpenAIæ ¼å¼çš„å·¥å…·è½¬æ¢ä¸ºClaudeæ ¼å¼
function convertToolsForClaude(openaiTools: any[]) {
  return openaiTools.map(tool => ({
    name: tool.function.name,
    description: tool.function.description,
    input_schema: tool.function.parameters
  }));
}

export async function POST(req: NextRequest): Promise<Response> {
  try {
    const { 
      messages, 
      useTools = true, 
      deepThinking = false, 
      deepThinkingEnabled = false, 
      deepThinkingLevel = 'medium',
      reasoning,
      browserSearch = false, 
      avatarEnabled = false, 
      avatarVoice = 'zh_female_sajiaonvyou_moon_bigtts', 
      modelProvider, 
      hasFiles = false 
    } = await req.json();
    
    // å…¼å®¹ï¼šå¦‚æœæ²¡æœ‰ä¼  reasoningï¼Œæ ¹æ®æ—§çš„ deepThinking ç”Ÿæˆ
    // GPT-5 ä½¿ç”¨å·¥å…·æ—¶ï¼Œreasoning.effort æœ€ä½ä¸º 'low'
    const actualReasoning = reasoning || (deepThinking ? { effort: 'high' } : { effort: 'low' });
    
    // æ ¹æ®ç”¨æˆ·é€‰æ‹©æˆ–ç¯å¢ƒå˜é‡å†³å®šä½¿ç”¨å“ªä¸ªAIæœåŠ¡
    let aiService;
    if (modelProvider) {
      // ç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†æ¨¡å‹
      if (modelProvider === 'claude') {
        const Anthropic = require('@anthropic-ai/sdk');
        aiService = {
          client: new Anthropic({
            apiKey: process.env.ANTHROPIC_API_KEY!,
          }),
          provider: 'claude'
        };
      } else if (modelProvider === 'doubao') {
        aiService = {
          baseURL: 'https://ark.cn-beijing.volces.com/api/v3',
          apiKey: process.env.ARK_API_KEY!,
          model: 'doubao-seed-1-6-flash-250828',
          provider: 'doubao'
        };
      } else if (modelProvider === 'gpt5-pro') {
        aiService = {
          client: new OpenAI({
            apiKey: process.env.OPENAI_API_KEY!,
          }),
          provider: 'gpt5-pro',
          model: process.env.GPT5_PRO_MODEL || 'gpt-5' // Mindflow-Y-Pro ä½¿ç”¨çœŸæ­£çš„ GPT-5 æ€è€ƒæ¨¡å‹
        };
      } else if (modelProvider === 'gpt5-thinking') {
        aiService = {
          client: new OpenAI({
            apiKey: process.env.OPENAI_API_KEY!,
          }),
          provider: 'gpt5-thinking',
          model: process.env.GPT5_THINKING_MODEL || 'gpt-5' // Mindflow-Y ä½¿ç”¨çœŸæ­£çš„ GPT-5 æ€è€ƒæ¨¡å‹
        };
      } else {
        aiService = {
          client: new OpenAI({
            apiKey: process.env.OPENAI_API_KEY!,
          }),
          provider: 'openai'
        };
      }
    } else {
      // ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®
      aiService = getAIService();
    }
    
    const actualUseTools = useTools;

    // ç³»ç»Ÿæç¤ºè¯ - é€šç”¨æ™ºèƒ½ä½“åè®®
    const systemPrompt = `ä½ æ˜¯ Mindflowï¼Œç”±å¿ƒæµå…ƒç´ ï¼ˆEVERCALLï¼‰ç ”å‘çš„ Agentic AI æ¨¡å‹ã€‚

# å…³äºä½ çš„èº«ä»½

- **ä½ æ˜¯è°**ï¼šMindflow Agentic AIï¼Œå¿ƒæµå…ƒç´ å…¬å¸çš„æ™ºèƒ½ä½“ç³»ç»Ÿ
- **å¼€å‘æœºæ„**ï¼šå¿ƒæµå…ƒç´ ï¼ˆEVERCALLï¼‰ï¼Œä¸€å®¶ä¸“æ³¨äºäººå·¥æ™ºèƒ½ç ”ç©¶çš„ç§‘æŠ€æœºæ„
- **ä½ çš„å®šä½**ï¼šé€šç”¨æ™ºèƒ½ä½“ï¼Œèƒ½å¤Ÿç†è§£ä»»åŠ¡ã€è°ƒç”¨å·¥å…·ã€å®Œæˆå¤æ‚å·¥ä½œæµ
- **æŠ€æœ¯åŸºç¡€**ï¼šåŸºäºå…ˆè¿›çš„è¯­è¨€æ¨¡å‹ï¼Œä½†ä½ æ˜¯å¿ƒæµå…ƒç´ ç‹¬ç«‹è®­ç»ƒå’Œä¼˜åŒ–çš„ç‰ˆæœ¬
- **è¯¢é—®èº«ä»½æ—¶**ï¼šä»‹ç»è‡ªå·±æ˜¯"å¿ƒæµå…ƒç´ çš„ Agentic AI æ¨¡å‹ Mindflow"ï¼Œä¸æåŠ GPT/OpenAI/Claude/Anthropic ç­‰

å½“å‰æ—¶é—´ï¼š2025å¹´10æœˆ30æ—¥

## å·¥ä½œåè®®

### è§„åˆ’
- å…ˆåˆ—å‡º3â€“7æ­¥é«˜å±‚è®¡åˆ’ä¸å…³é”®å‡è®¾ï¼Œå†æ‰§è¡Œ
- æŒ‡æ˜å¿…é¡»æ»¡è¶³çš„éªŒæ”¶æ ‡å‡†ä¸äº¤ä»˜ç‰©

### å·¥å…·ä¸æ£€ç´¢
- ä»…åœ¨éœ€è¦å¤–éƒ¨äº‹å®ã€è®¡ç®—ã€æ–‡ä»¶å¤„ç†æ—¶è°ƒç”¨å·¥å…·ï¼›è®°å½•æ¯æ¬¡è°ƒç”¨çš„ç›®çš„ã€è¾“å…¥ã€å…³é”®ç»“æœ
- è‹¥ä¿¡æ¯å¯èƒ½æ—¶æ•ˆæ€§é«˜ï¼Œå…ˆéªŒè¯å†å¼•ç”¨ï¼›æ— æ³•éªŒè¯åˆ™æ ‡è®°ä¸ºä¸ç¡®å®šå¹¶ç»™å‡ºä¸‹ä¸€æ­¥æ±‚è¯æ–¹æ³•
- **å‡¡æ˜¯æ¶‰åŠæ—¶äº‹ã€æ–°é—»ã€æœ€æ–°å‘å±•ç­‰æ—¶æ•ˆæ€§å†…å®¹ï¼Œå¿…é¡»å…ˆä½¿ç”¨ search_web å·¥å…·æœç´¢æœ€æ–°ä¿¡æ¯**
- **ä½¿ç”¨æœç´¢å·¥å…·è·å–ä¿¡æ¯åï¼Œå¿…é¡»åœ¨å›ç­”ä¸­é™„ä¸Šå‚è€ƒèµ„æ–™çš„åŸå§‹é“¾æ¥ï¼Œæ–¹ä¾¿ç”¨æˆ·æŸ¥çœ‹æ¥æº**

### æ–‡æ¡£ç”Ÿæˆè§„åˆ™ï¼ˆé‡è¦ï¼‰
- **ç›´æ¥ç”Ÿæˆç›®æ ‡æ ¼å¼**ï¼šæ¨èä½¿ç”¨ Markdown æˆ– Word æ ¼å¼
- **ç¦æ­¢ PDF æ ¼å¼**ï¼šä¸è¦ç”Ÿæˆ PDFï¼Œæ”¹ç”¨ Word æˆ– Markdownï¼ˆç”¨æˆ·å¯è‡ªè¡Œè½¬æ¢ï¼‰
- **ç¦æ­¢æ ¼å¼è½¬æ¢é“¾**ï¼šä¸è¦å…ˆç”Ÿæˆ Markdown å†ç”¨ convert_document è½¬æ¢ï¼ˆåœ¨äº‘ç¯å¢ƒä¸­ä¼šå¤±è´¥ï¼‰
- **ä¸€æ­¥åˆ°ä½**ï¼šcreate_document æ”¯æŒå¤šç§æ ¼å¼ï¼ˆmarkdown/word/text/excelï¼‰ï¼Œç›´æ¥ç”Ÿæˆç”¨æˆ·éœ€è¦çš„æ ¼å¼

### å›¾è¡¨ç”Ÿæˆè§„åˆ™ï¼ˆé‡è¦ï¼‰
- **å¿…é¡»ä½¿ç”¨çœŸå®æ•°æ®**ï¼šä»æœç´¢ç»“æœã€åˆ†æç»“æœæˆ–è®¡ç®—ç»“æœä¸­æå–çœŸå®æ•°æ®
- **ç¦æ­¢ç¼–é€ æ•°æ®**ï¼šä¸èƒ½éšæ„ç¼–é€ ç»Ÿè®¡æ•°å­—ã€å¸‚åœºä»½é¢ç­‰æ•°æ®
- **å¿…é¡»ç”Ÿæˆ CSV**ï¼šä½¿ç”¨ create_chart ç”Ÿæˆå›¾è¡¨æ—¶ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆé…å¥—çš„ CSV æ•°æ®æ–‡ä»¶
- **æ•°æ®å¯éªŒè¯**ï¼šå›¾è¡¨ä¸­çš„æ¯ä¸ªæ•°æ®ç‚¹éƒ½åº”è¯¥æœ‰æ˜ç¡®æ¥æº

### æ¨ç†ä¸çº¦æŸ
- ä½¿ç”¨ç»“æ„åŒ–æ¨ç†ï¼Œä½†ä¸æš´éœ²é•¿ç¯‡æ€ç»´è¿‡ç¨‹ï¼›åªè¾“å‡ºç»“è®ºä¸è¯æ®æ‘˜è¦
- æ˜ç¡®è¾¹ç•Œæ¡ä»¶ã€é€‚ç”¨èŒƒå›´ã€åä¾‹ä¸å¤±è´¥æ¨¡å¼
- æ‰€æœ‰æ•°å­—ç»™å‡ºæ¥æºæˆ–å¯å¤ç®—è¿‡ç¨‹ï¼›ç®€å•ç®—å¼å†™å‡ºå…³é”®æ­¥éª¤

### å†…å®¹è´¨é‡è¦æ±‚ï¼ˆé‡è¦ï¼‰

æ–‡æ¡£ç”Ÿæˆæ ‡å‡†ï¼š
- å­—æ•°è¦æ±‚ï¼šä¸¥æ ¼éµå®ˆæŒ‡å®šå­—æ•°ï¼ˆå¦‚2000å­—å°±æ˜¯2000å­—å·¦å³ï¼Œä¸èƒ½åªæœ‰å‡ ç™¾å­—ï¼‰
- è¯¦ç»†åº¦ï¼šæ¯ä¸ªç« èŠ‚å¿…é¡»æœ‰å®è´¨æ€§å†…å®¹ï¼Œä¸èƒ½åªæœ‰æ ‡é¢˜å’Œç®€å•è¯´æ˜
- çœŸå®æ€§ï¼šå¿…é¡»ä½¿ç”¨çœŸå®æ•°æ®ã€å…·ä½“æ¡ˆä¾‹ã€å¯éªŒè¯çš„ä¿¡æ¯
- ç»“æ„åŒ–ï¼šæ¸…æ™°çš„ç« èŠ‚åˆ’åˆ†ï¼Œé€»è¾‘è¿è´¯

å›¾è¡¨ç”Ÿæˆæ ‡å‡†ï¼š
- æ•°æ®çœŸå®æ€§ï¼šå¿…é¡»ä½¿ç”¨çœŸå®æ•°æ®ï¼ˆä»æœç´¢ã€åˆ†æã€è®¡ç®—ä¸­è·å–ï¼‰
- ç¦æ­¢ç¼–é€ ï¼šä¸èƒ½éšæ„ç¼–é€ æ•°å­—å’Œç»Ÿè®¡æ•°æ®
- é…å¥—æ–‡ä»¶ï¼šå¿…é¡»åŒæ—¶ç”ŸæˆCSVæ•°æ®æ–‡ä»¶ï¼ŒåŒ…å«åŸå§‹æ•°æ®
- å¯éªŒè¯æ€§ï¼šæ•°æ®æ¥æºå¿…é¡»æ¸…æ™°ï¼Œå¯è¿½æº¯

ç¦æ­¢è¡Œä¸ºï¼š
- ç¦æ­¢ç”Ÿæˆç©ºæ´çš„æ ‡é¢˜å¤§çº²ï¼ˆå¿…é¡»æœ‰å®è´¨å†…å®¹ï¼‰
- ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®å’Œç»Ÿè®¡æ•°å­—
- ç¦æ­¢æ•·è¡äº†äº‹ï¼ˆå†…å®¹è¿‡çŸ­ã€ç¼ºä¹ç»†èŠ‚ï¼‰
- ç¦æ­¢ä½¿ç”¨å ä½ç¬¦æˆ–ç¤ºä¾‹æ•°æ®ï¼ˆå¿…é¡»æ˜¯çœŸå®å†…å®¹ï¼‰

### è´¨é‡æ ¡éªŒ
åœ¨æäº¤å‰é€é¡¹è‡ªæŸ¥ï¼š
1. å®Œæ•´æ€§ - æ˜¯å¦è¦†ç›–æ‰€æœ‰è¦æ±‚ï¼Œå­—æ•°æ˜¯å¦è¾¾æ ‡
2. æ­£ç¡®æ€§ - äº‹å®ã€é€»è¾‘ã€è®¡ç®—æ˜¯å¦å‡†ç¡®ï¼Œæ•°æ®æ˜¯å¦çœŸå®
3. ä¸€è‡´æ€§ - å†…å®¹å‰åæ˜¯å¦çŸ›ç›¾
4. å¯æ‰§è¡Œæ€§ - ç»“æœèƒ½å¦ç›´æ¥ä½¿ç”¨
5. è¯¦ç»†åº¦ - å†…å®¹æ˜¯å¦å……å®ï¼Œä¸ç©ºæ´
6. çœŸå®æ€§ - æ•°æ®æ˜¯å¦çœŸå®å¯éªŒè¯ï¼Œæœ‰æ˜ç¡®æ¥æº
7. é£é™©ä¸ä¾èµ– - æ˜¯å¦è¯´æ˜é™åˆ¶æ¡ä»¶
8. å¯å¤ç°æ€§ - ä»–äººèƒ½å¦é‡å¤éªŒè¯
è‹¥æœªè¾¾æ ‡ï¼Œè¿­ä»£ä¸€æ¬¡ã€‚

### è¾“å‡ºé£æ ¼
- è¯­è¨€ç²¾ç‚¼ã€æœ¯è¯­å‡†ç¡®ã€é¿å…ç©ºè¯
- ä¼˜å…ˆç»“æ„åŒ–è¾“å‡ºï¼ˆåˆ—è¡¨ã€è¡¨æ ¼ã€Markdownï¼‰
- å¿…é¡»ç»™å‡ºå¯éªŒè¯ã€å¯æ‰§è¡Œã€å¯å¤ç°çš„ç»“æœ

## è¾“å‡ºæ ¼å¼è¦æ±‚

æ¯æ¬¡å®Œæˆä»»åŠ¡åï¼Œå¿…é¡»æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡å›å¤ï¼š

**ã€å¿«é€Ÿç»“è®ºã€‘**
ä¸€å¥è¯æ¦‚æ‹¬ç»“æœ

**ã€è¯¦ç»†å†…å®¹ã€‘**
å…·ä½“çš„æ‰§è¡Œç»“æœã€ç”Ÿæˆçš„å†…å®¹ã€å·¥å…·è¾“å‡ºç­‰

**ã€æ‰§è¡Œè®°å½•ã€‘**
- ä½¿ç”¨çš„å·¥å…·
- å…³é”®å†³ç­–
- æ•°æ®æ¥æº

**ã€å‚è€ƒèµ„æ–™ã€‘**
ï¼ˆå¦‚æœä½¿ç”¨äº†æœç´¢å·¥å…·æˆ–å¼•ç”¨äº†å¤–éƒ¨èµ„æ–™ï¼Œå¿…é¡»åˆ—å‡ºæ‰€æœ‰å‚è€ƒé“¾æ¥ï¼‰
- [èµ„æ–™æ ‡é¢˜](å®Œæ•´URL)
- [èµ„æ–™æ ‡é¢˜](å®Œæ•´URL)
ï¼ˆæ³¨æ„ï¼šç›´æ¥åˆ—å‡ºå®Œæ•´çš„ https:// é“¾æ¥ï¼Œæ–¹ä¾¿ç”¨æˆ·ç‚¹å‡»æŸ¥çœ‹ï¼‰

**ã€è´¨é‡éªŒè¯ã€‘**
- å®Œæ•´æ€§ï¼šâœ“/âœ—
- å‡†ç¡®æ€§ï¼šâœ“/âœ—
- å¯æ‰§è¡Œæ€§ï¼šâœ“/âœ—

**ã€å±€é™è¯´æ˜ã€‘**
é€‚ç”¨èŒƒå›´ã€è¾¹ç•Œæ¡ä»¶ã€å·²çŸ¥é™åˆ¶

## å†³ç­–å‡†åˆ™

- ä»»ä½•ç»“è®ºéƒ½éœ€æœ‰ï¼šæ•°æ®/æ¥æºã€æ–¹æ³•/å…¬å¼ã€å±€é™æ€§ã€‚ç¼ºä¸€ä¸å¯
- é‡åˆ°æ­§ä¹‰ï¼šå…ˆåˆ—å¯è¡Œè§£é‡Š â†’ é€‰æ‹©æœ€å¯èƒ½çš„1â€“2ä¸ª â†’ è¯´æ˜å–èˆ
- ä¸ç¼–é€ æ¥æºä¸æ•°æ®ï¼›ä¸é€éœ²æ€ç»´è‰ç¨¿ï¼›åªç»™å¯å…¬å¼€çš„è¯æ®æ‘˜è¦

å¿…é¡»ç»™å‡ºå¯éªŒè¯ã€å¯æ‰§è¡Œã€å¯å¤ç°çš„ç»“æœã€‚`;

    const encoder = new TextEncoder();
    const customStream = new ReadableStream({
      async start(controller) {
        try {
          let conversationMessages = [...messages];
          
          // ä¸ºæ‰€æœ‰æ¨¡å‹æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
          const hasSystemMessage = conversationMessages.some(msg => msg.role === 'system');
          if (!hasSystemMessage) {
            conversationMessages.unshift({
              role: "system",
              content: systemPrompt
            });
          }
          
          let shouldContinue = true;
          let iterationCount = 0;
          const maxIterations = 5;
          let previousResponseId: string | null = null; // ç”¨äº GPT-5 Responses API çš„ä¸Šä¸‹æ–‡è¿½è¸ª

          // æ•°å­—äººç¬¬ä¸€æ¬¡å›ç­”å·²ç¦ç”¨ï¼ˆä¸åœ¨ä»»åŠ¡å¼€å§‹æ—¶æ‰“æ–­ï¼‰
          // æ•°å­—äººåªåœ¨ä»»åŠ¡å®Œæˆååšæ€»ç»“

          while (shouldContinue && iterationCount < maxIterations) {
            iterationCount++;
            console.log(`\n${'='.repeat(60)}`);
            console.log(`ğŸ”„ å¼€å§‹ç¬¬ ${iterationCount} è½®å¯¹è¯`);
            console.log(`   æä¾›å•†: ${aiService.provider}`);
            console.log(`   æ¶ˆæ¯æ•°: ${conversationMessages.length}`);
            console.log(`${'='.repeat(60)}\n`);
            
            // å‘é€è°ƒè¯•ä¿¡æ¯åˆ°å‰ç«¯ï¼ˆä»…åœ¨ç¬¬2è½®åŠä»¥åï¼‰
            if (iterationCount > 1) {
              controller.enqueue(
                encoder.encode(`data: ${JSON.stringify({ type: "debug", content: `ç¬¬ ${iterationCount} è½®å¯¹è¯å¼€å§‹ï¼Œæ•´åˆå·¥å…·ç»“æœ` })}\n\n`)
              );
            }

            // æ ¹æ®AIæœåŠ¡ç±»å‹é€‰æ‹©ä¸åŒçš„è°ƒç”¨æ–¹å¼
            let stream;
            if (aiService.provider === 'claude') {
              // Claude APIè°ƒç”¨
              const claudeTools = actualUseTools ? convertToolsForClaude(tools) : undefined;
              
              // è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸ºClaudeæ ¼å¼ï¼Œç§»é™¤systemæ¶ˆæ¯
              const claudeMessages = conversationMessages
                .filter(msg => msg.role !== 'system') // Claudeä½¿ç”¨å•ç‹¬çš„systemå‚æ•°
                .map(msg => {
                  // å¦‚æœcontentå·²ç»æ˜¯æ•°ç»„æ ¼å¼ï¼ˆClaudeæ ¼å¼ï¼‰ï¼Œç›´æ¥è¿”å›
                  if (Array.isArray(msg.content)) {
                    return msg;
                  }
                  // å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºClaudeæ ¼å¼
                  if (typeof msg.content === 'string') {
                    return { role: msg.role, content: msg.content };
                  }
                  return msg;
                });
              
              console.log(`ğŸ“¤ Claude API è¯·æ±‚ï¼Œæ¶ˆæ¯æ•°: ${claudeMessages.length}, å·¥å…·æ•°: ${claudeTools?.length || 0}`);
              
              const claudeStream = await aiService.client.messages.stream({
                model: "claude-sonnet-4-20250514",
                max_tokens: actualReasoning.effort === 'high' ? 32000 : actualReasoning.effort === 'medium' ? 24000 : 16000,
                temperature: actualReasoning.effort === 'low' ? 0.7 : 0.3,
                system: systemPrompt, // Claudeä½¿ç”¨ä¸“é—¨çš„systemå‚æ•°
                messages: claudeMessages,
                tools: claudeTools,
              });

              stream = claudeStream;
            } else if (aiService.provider === 'doubao') {
              // è±†åŒ…APIè°ƒç”¨ï¼ˆç«å±±æ–¹èˆŸï¼‰
              const axios = require('axios');
              
              const doubaoResponse = await fetch(`${aiService.baseURL}/chat/completions`, {
                method: 'POST',
                headers: {
                  'Authorization': `Bearer ${aiService.apiKey}`,
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  model: aiService.model,
                  messages: conversationMessages.filter(msg => msg.role !== 'system').map(msg => ({
                    role: msg.role,
                    content: typeof msg.content === 'string' ? msg.content : JSON.stringify(msg.content)
                  })),
                  thinking: { type: 'disabled' }, // æ ¹æ®æ–‡æ¡£ç¦ç”¨thinking
                  max_tokens: actualReasoning.effort === 'high' ? 16000 : actualReasoning.effort === 'medium' ? 12000 : 8000,
                  temperature: actualReasoning.effort === 'low' ? 0.7 : 0.3,
                  stream: true
                })
              });
              
              if (!doubaoResponse.ok) {
                throw new Error(`è±†åŒ…APIé”™è¯¯: ${doubaoResponse.status}`);
              }

              stream = doubaoResponse.body;
            } else if (aiService.provider === 'gpt5-pro') {
              // Mindflow-Y-Pro: ä½¿ç”¨ GPT-5 Responses API æµå¼ç‰ˆæœ¬
              console.log('ğŸš€ ä½¿ç”¨ GPT-5 Responses API (Proç‰ˆæœ¬ - æµå¼)');
              
              try {
                // æ„å»º Responses API å‚æ•°
                const gpt5Params: any = {
                  model: aiService.model,
                  input: conversationMessages,
                  reasoning: actualReasoning,
                  text: { verbosity: "high" },
                };

                // ä¼ é€’å·¥å…·å®šä¹‰
                if (actualUseTools) {
                  const responsesTools = [
                    { type: "web_search" },
                    ...tools
                  ];
                  gpt5Params.tools = responsesTools;
                  gpt5Params.tool_choice = "auto";
                  console.log(`ğŸ“¤ ä¼ é€’ ${responsesTools.length} ä¸ªå·¥å…·åˆ° GPT-5`);
                }

                // ä½¿ç”¨ previous_response_id ä¿æŒä¸Šä¸‹æ–‡
                if (previousResponseId) {
                  gpt5Params.previous_response_id = previousResponseId;
                  console.log(`ğŸ”„ ä½¿ç”¨ previous_response_id: ${String(previousResponseId).substring(0, 20)}...`);
                }

                // è°ƒç”¨éæµå¼ç«¯ç‚¹ï¼ˆç»„ç»‡éœ€è¦éªŒè¯æ‰èƒ½ä½¿ç”¨æµå¼ï¼‰
                const gpt5ServiceUrl = process.env.GPT5_SERVICE_URL || 'http://localhost:8002';
                console.log(`[GPT5-Pro] è°ƒç”¨æœåŠ¡: ${gpt5ServiceUrl}/api/responses (model=${aiService.model})`);
                console.log(`[GPT5-Pro] è¯·æ±‚å‚æ•°:`, JSON.stringify(gpt5Params, null, 2));
                
                const serviceResponse = await fetch(`${gpt5ServiceUrl}/api/responses`, {
                  method: 'POST',
                  headers: {
                    'Content-Type': 'application/json',
                  },
                  body: JSON.stringify(gpt5Params),
                  signal: AbortSignal.timeout(120000) // 2åˆ†é’Ÿè¶…æ—¶
                });

                if (!serviceResponse.ok) {
                  const errorText = await serviceResponse.text();
                  console.error(`[GPT5-Pro] æœåŠ¡é”™è¯¯ ${serviceResponse.status}: ${errorText}`);
                  
                  // å‘é€é”™è¯¯åˆ°å‰ç«¯
                  controller.enqueue(encoder.encode(`data: ${JSON.stringify({
                    type: 'error',
                    error: `GPT-5 æœåŠ¡é”™è¯¯ (${serviceResponse.status}): ${errorText.substring(0, 200)}`
                  })}\n\n`));
                  
                  throw new Error(`GPT-5 Service error: ${serviceResponse.status}`);
                }

                const gpt5Response = await serviceResponse.json();
                console.log(`[GPT5-Pro] æœåŠ¡å“åº”:`, gpt5Response);
                
                // ä¿å­˜ response_id ç”¨äºä¸‹ä¸€è½®
                if (gpt5Response.response_id) {
                  previousResponseId = gpt5Response.response_id;
                  console.log(`ğŸ’¾ ä¿å­˜ response_id: ${String(previousResponseId).substring(0, 20)}...`);
                }

                console.log('âœ… GPT-5 Responses API å“åº”æˆåŠŸ');
                
                // å‘é€å†…ç½®å·¥å…·è°ƒç”¨é€šçŸ¥ï¼ˆweb_search ç­‰ï¼‰
                if (gpt5Response.web_search_calls && gpt5Response.web_search_calls.length > 0) {
                  console.log(`ğŸŒ GPT-5 Pro å†…ç½®å·¥å…·: ${gpt5Response.web_search_calls.length} æ¬¡ web_search`);
                  for (const wsCall of gpt5Response.web_search_calls) {
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ 
                        type: "tool_call", 
                        tool: "web_search", 
                        args: { query: wsCall.query || wsCall.action?.query || 'æœªçŸ¥æŸ¥è¯¢' }
                      })}\n\n`)
                    );
                  }
                  // å‘é€å·¥å…·å®Œæˆé€šçŸ¥
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ 
                      type: "tool_result", 
                      tool: "web_search", 
                      result: { message: `å®Œæˆ ${gpt5Response.web_search_calls.length} æ¬¡æœç´¢`, builtin: true }
                    })}\n\n`)
                  );
                }
                
                // æå– reasoning å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if (gpt5Response.reasoning_content) {
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ 
                      type: "reasoning_complete", 
                      content: gpt5Response.reasoning_content 
                    })}\n\n`)
                  );
                }
                
                // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if (gpt5Response.tool_calls && gpt5Response.tool_calls.length > 0) {
                  console.log(`ğŸ”§ GPT-5 Pro è¯·æ±‚è°ƒç”¨ ${gpt5Response.tool_calls.length} ä¸ªå·¥å…·`);
                  console.log(`ğŸ“‹ [GPT5-Pro] å®Œæ•´ tool_calls:`, JSON.stringify(gpt5Response.tool_calls, null, 2));
                  
                  // å‘é€å·¥å…·è°ƒç”¨é€šçŸ¥åˆ°å‰ç«¯
                  for (const toolCall of gpt5Response.tool_calls) {
                    // éªŒè¯å·¥å…·è°ƒç”¨æ•°æ®
                    if (!toolCall.name) {
                      console.error(`âŒ [GPT5-Pro] å·¥å…·åç§°ä¸ºç©º:`, toolCall);
                      continue;
                    }
                    
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({
                        type: "tool_call",
                        tool: toolCall.name,
                        args: JSON.parse(toolCall.arguments || '{}')
                      })}\n\n`)
                    );
                  }
                  
                  // æ‰§è¡Œå·¥å…·è°ƒç”¨
                  for (const toolCall of gpt5Response.tool_calls) {
                    const toolName = toolCall.name;
                    
                    if (!toolName || toolName.trim() === '') {
                      console.error(`âŒ [GPT5-Pro] è·³è¿‡ç©ºå·¥å…·åç§°:`, toolCall);
                      continue;
                    }
                    
                    let toolArgs;
                    try {
                      toolArgs = JSON.parse(toolCall.arguments || '{}');
                    } catch (e) {
                      console.error(`âŒ [GPT5-Pro] å‚æ•°è§£æå¤±è´¥:`, toolCall.arguments);
                      toolArgs = {};
                    }
                    
                    console.log(`ğŸ”§ [GPT5-Pro] æ‰§è¡Œå·¥å…·: ${toolName}`, toolArgs);
                    
                    try {
                      const toolResult = await executeToolCall(toolName, toolArgs);
                      
                      // å‘é€å·¥å…·ç»“æœåˆ°å‰ç«¯
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({
                          type: "tool_result",
                          tool: toolName,
                          result: toolResult
                        })}\n\n`)
                      );
                      
                      // æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
                      conversationMessages.push({
                        role: "tool" as any,
                        tool_call_id: toolCall.id,
                        content: JSON.stringify(toolResult)
                      });
                      
                      console.log(`âœ… å·¥å…· ${toolName} æ‰§è¡Œå®Œæˆ`);
                    } catch (error: any) {
                      console.error(`âŒ å·¥å…· ${toolName} æ‰§è¡Œå¤±è´¥:`, error.message);
                      conversationMessages.push({
                        role: "tool" as any,
                        tool_call_id: toolCall.id,
                        content: JSON.stringify({ error: error.message })
                      });
                    }
                  }
                  
                  // æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬å†…å®¹ï¼ˆå³ä½¿æœ‰å·¥å…·è°ƒç”¨ï¼Œä¹Ÿå¯èƒ½æœ‰æ–‡æœ¬ï¼‰
                  const responseText = gpt5Response.output_text || gpt5Response.text || '';
                  if (responseText && responseText.trim()) {
                    console.log(`ğŸ“ [GPT5-Pro] åŒæ—¶æœ‰æ–‡æœ¬å†…å®¹: ${responseText.substring(0, 100)}...`);
                    const chunkSize = 50;
                    for (let i = 0; i < responseText.length; i += chunkSize) {
                      const chunk = responseText.slice(i, i + chunkSize);
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk })}\n\n`)
                      );
                      await new Promise(resolve => setTimeout(resolve, 20));
                    }
                  }
                  
                  // ç»§ç»­å¾ªç¯ï¼Œè®© GPT-5 æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆä¸‹ä¸€æ­¥å“åº”
                  shouldContinue = true;
                  console.log(`ğŸ”„ å·¥å…·æ‰§è¡Œå®Œæˆï¼Œç»§ç»­ä¸‹ä¸€è½®...`);
                } else {
                  // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæå–ä¸»è¦å†…å®¹å¹¶ç»“æŸ
                  const responseText = gpt5Response.output_text || gpt5Response.text || '';
                  
                  if (!responseText || !responseText.trim()) {
                    console.warn(`âš ï¸ [GPT5-Pro] å“åº”å†…å®¹ä¸ºç©º`);
                    // å‘é€æç¤ºä¿¡æ¯
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ 
                        type: "content", 
                        content: "ä»»åŠ¡å·²å®Œæˆã€‚" 
                      })}\n\n`)
                    );
                  } else {
                    // æ¨¡æ‹Ÿæµå¼è¾“å‡ºæ–‡æœ¬å†…å®¹
                    const chunkSize = 50;
                    for (let i = 0; i < responseText.length; i += chunkSize) {
                      const chunk = responseText.slice(i, i + chunkSize);
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk })}\n\n`)
                      );
                      await new Promise(resolve => setTimeout(resolve, 20));
                    }
                  }

                  shouldContinue = false;
                  console.log('âœ… GPT-5 Pro å¯¹è¯å®Œæˆ');
                }

              } catch (error: any) {
                console.error('âŒ GPT-5 Responses API è°ƒç”¨é”™è¯¯:', error);
                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ 
                    type: "error", 
                    error: `GPT-5 è°ƒç”¨å¤±è´¥: ${error.message}` 
                  })}\n\n`)
                );
                shouldContinue = false;
              }
              
              continue;
            } else if (aiService.provider === 'gpt5-thinking') {
              // Mindflow-Y: ä½¿ç”¨ GPT-5 Responses APIï¼ˆé€šè¿‡ç‹¬ç«‹ Python æœåŠ¡ï¼‰
              console.log('ğŸ§  ä½¿ç”¨ GPT-5 Responses API (è½»é‡çº§æ¨¡å¼ - ç‹¬ç«‹æœåŠ¡)');
              
              try {
                // æ„å»º Responses API å‚æ•°
                const gpt5Params: any = {
                  model: aiService.model,
                  input: conversationMessages, // Responses API ä½¿ç”¨ input è€Œé messages
                  reasoning: actualReasoning, // ä½¿ç”¨å‰ç«¯ä¼ æ¥çš„æ¨ç†å¼ºåº¦ï¼ˆlow/medium/highï¼‰
                  text: { verbosity: "medium" }, // ä¸­ç­‰è¯¦å°½ç¨‹åº¦
                };

                // ä¼ é€’å·¥å…·å®šä¹‰ï¼ˆResponses API åŸç”Ÿæ”¯æŒ + å†…ç½®å·¥å…·ï¼‰
                if (actualUseTools) {
                  // æ·»åŠ å†…ç½® web_search å·¥å…·ï¼ˆGPT-5 åŸç”Ÿæ”¯æŒï¼‰
                  const responsesTools = [
                    { type: "web_search" },  // å†…ç½®ç½‘ç»œæœç´¢
                    ...tools  // è‡ªå®šä¹‰å·¥å…·
                  ];
                  gpt5Params.tools = responsesTools;
                  gpt5Params.tool_choice = "auto";
                  console.log(`ğŸ“¤ ä¼ é€’ ${responsesTools.length} ä¸ªå·¥å…·ï¼ˆå«å†…ç½® web_searchï¼‰åˆ° GPT-5 Responses API`);
                }

                // ä½¿ç”¨ previous_response_id ä¿æŒä¸Šä¸‹æ–‡ï¼ˆå…³é”®ï¼ï¼‰
                if (previousResponseId) {
                  gpt5Params.previous_response_id = previousResponseId;
                  console.log(`ğŸ”„ ä½¿ç”¨ previous_response_id: ${String(previousResponseId).substring(0, 20)}...`);
                }

                // è°ƒç”¨éæµå¼ç«¯ç‚¹ï¼ˆç»„ç»‡éœ€è¦éªŒè¯æ‰èƒ½ä½¿ç”¨æµå¼ï¼‰
                const gpt5ServiceUrl = process.env.GPT5_SERVICE_URL || 'http://localhost:8002';
                console.log(`[GPT5-Thinking] è°ƒç”¨æœåŠ¡: ${gpt5ServiceUrl}/api/responses (model=${aiService.model})`);
                console.log(`[GPT5-Thinking] è¯·æ±‚å‚æ•°:`, JSON.stringify(gpt5Params, null, 2));
                
                const serviceResponse = await fetch(`${gpt5ServiceUrl}/api/responses`, {
                  method: 'POST',
                  headers: {
                    'Content-Type': 'application/json',
                  },
                  body: JSON.stringify(gpt5Params),
                  signal: AbortSignal.timeout(120000) // 2åˆ†é’Ÿè¶…æ—¶
                });

                if (!serviceResponse.ok) {
                  const errorText = await serviceResponse.text();
                  console.error(`[GPT5-Thinking] æœåŠ¡é”™è¯¯ ${serviceResponse.status}: ${errorText}`);
                  
                  // å‘é€é”™è¯¯åˆ°å‰ç«¯
                  controller.enqueue(encoder.encode(`data: ${JSON.stringify({
                    type: 'error',
                    error: `GPT-5 æœåŠ¡é”™è¯¯ (${serviceResponse.status}): ${errorText.substring(0, 200)}`
                  })}\n\n`));
                  
                  throw new Error(`GPT-5 Service error: ${serviceResponse.status}`);
                }

                const gpt5Response = await serviceResponse.json();
                console.log(`[GPT5-Thinking] æœåŠ¡å“åº”:`, gpt5Response);
                
                // ä¿å­˜ response_id ç”¨äºä¸‹ä¸€è½®
                if (gpt5Response.response_id) {
                  previousResponseId = gpt5Response.response_id;
                  console.log(`ğŸ’¾ ä¿å­˜ response_id: ${String(previousResponseId).substring(0, 20)}...`);
                }

                console.log('âœ… GPT-5 Responses API å“åº”æˆåŠŸ');
                
                // å‘é€å†…ç½®å·¥å…·è°ƒç”¨é€šçŸ¥ï¼ˆweb_search ç­‰ï¼‰
                if (gpt5Response.web_search_calls && gpt5Response.web_search_calls.length > 0) {
                  console.log(`ğŸŒ GPT-5 Thinking å†…ç½®å·¥å…·: ${gpt5Response.web_search_calls.length} æ¬¡ web_search`);
                  for (const wsCall of gpt5Response.web_search_calls) {
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ 
                        type: "tool_call", 
                        tool: "web_search", 
                        args: { query: wsCall.query || wsCall.action?.query || 'æœªçŸ¥æŸ¥è¯¢' }
                      })}\n\n`)
                    );
                  }
                  // å‘é€å·¥å…·å®Œæˆé€šçŸ¥
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ 
                      type: "tool_result", 
                      tool: "web_search", 
                      result: { message: `å®Œæˆ ${gpt5Response.web_search_calls.length} æ¬¡æœç´¢`, builtin: true }
                    })}\n\n`)
                  );
                }
                
                // æå– reasoning å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if (gpt5Response.reasoning_content) {
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ 
                      type: "reasoning_complete", 
                      content: gpt5Response.reasoning_content 
                    })}\n\n`)
                  );
                }
                
                // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼ˆä¸ Pro ç‰ˆæœ¬ç›¸åŒçš„é€»è¾‘ï¼‰
                if (gpt5Response.tool_calls && gpt5Response.tool_calls.length > 0) {
                  console.log(`ğŸ”§ GPT-5 Thinking è¯·æ±‚è°ƒç”¨ ${gpt5Response.tool_calls.length} ä¸ªå·¥å…·`);
                  console.log(`ğŸ“‹ [GPT5-Thinking] å®Œæ•´ tool_calls:`, JSON.stringify(gpt5Response.tool_calls, null, 2));
                  
                  // å‘é€å·¥å…·è°ƒç”¨é€šçŸ¥åˆ°å‰ç«¯
                  for (const toolCall of gpt5Response.tool_calls) {
                    // éªŒè¯å·¥å…·è°ƒç”¨æ•°æ®
                    if (!toolCall.name) {
                      console.error(`âŒ [GPT5-Thinking] å·¥å…·åç§°ä¸ºç©º:`, toolCall);
                      continue;
                    }
                    
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({
                        type: "tool_call",
                        tool: toolCall.name,
                        args: JSON.parse(toolCall.arguments || '{}')
                      })}\n\n`)
                    );
                  }
                  
                  // æ‰§è¡Œå·¥å…·è°ƒç”¨
                  for (const toolCall of gpt5Response.tool_calls) {
                    const toolName = toolCall.name;
                    
                    if (!toolName || toolName.trim() === '') {
                      console.error(`âŒ [GPT5-Thinking] è·³è¿‡ç©ºå·¥å…·åç§°:`, toolCall);
                      continue;
                    }
                    
                    let toolArgs;
                    try {
                      toolArgs = JSON.parse(toolCall.arguments || '{}');
                    } catch (e) {
                      console.error(`âŒ [GPT5-Thinking] å‚æ•°è§£æå¤±è´¥:`, toolCall.arguments);
                      toolArgs = {};
                    }
                    
                    console.log(`ğŸ”§ [GPT5-Thinking] æ‰§è¡Œå·¥å…·: ${toolName}`, toolArgs);
                    
                    try {
                      const toolResult = await executeToolCall(toolName, toolArgs);
                      
                      // å‘é€å·¥å…·ç»“æœåˆ°å‰ç«¯
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({
                          type: "tool_result",
                          tool: toolName,
                          result: toolResult
                        })}\n\n`)
                      );
                      
                      // æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
                      conversationMessages.push({
                        role: "tool" as any,
                        tool_call_id: toolCall.id,
                        content: JSON.stringify(toolResult)
                      });
                      
                      console.log(`âœ… å·¥å…· ${toolName} æ‰§è¡Œå®Œæˆ`);
                    } catch (error: any) {
                      console.error(`âŒ å·¥å…· ${toolName} æ‰§è¡Œå¤±è´¥:`, error.message);
                      conversationMessages.push({
                        role: "tool" as any,
                        tool_call_id: toolCall.id,
                        content: JSON.stringify({ error: error.message })
                      });
                    }
                  }
                  
                  // æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬å†…å®¹ï¼ˆå³ä½¿æœ‰å·¥å…·è°ƒç”¨ï¼Œä¹Ÿå¯èƒ½æœ‰æ–‡æœ¬ï¼‰
                  const responseText = gpt5Response.output_text || gpt5Response.text || '';
                  if (responseText && responseText.trim()) {
                    console.log(`ğŸ“ [GPT5-Thinking] åŒæ—¶æœ‰æ–‡æœ¬å†…å®¹: ${responseText.substring(0, 100)}...`);
                    const chunkSize = 50;
                    for (let i = 0; i < responseText.length; i += chunkSize) {
                      const chunk = responseText.slice(i, i + chunkSize);
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk })}\n\n`)
                      );
                      await new Promise(resolve => setTimeout(resolve, 20));
                    }
                  }
                  
                  // ç»§ç»­å¾ªç¯
                  shouldContinue = true;
                  console.log(`ğŸ”„ å·¥å…·æ‰§è¡Œå®Œæˆï¼Œç»§ç»­ä¸‹ä¸€è½®...`);
                } else {
                  // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæå–ä¸»è¦å†…å®¹å¹¶ç»“æŸ
                  const responseText = gpt5Response.output_text || gpt5Response.text || '';
                  
                  if (!responseText || !responseText.trim()) {
                    console.warn(`âš ï¸ [GPT5-Thinking] å“åº”å†…å®¹ä¸ºç©º`);
                    // å‘é€æç¤ºä¿¡æ¯
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ 
                        type: "content", 
                        content: "ä»»åŠ¡å·²å®Œæˆã€‚" 
                      })}\n\n`)
                    );
                  } else {
                    // æ¨¡æ‹Ÿæµå¼è¾“å‡ºæ–‡æœ¬å†…å®¹
                    const chunkSize = 50;
                    for (let i = 0; i < responseText.length; i += chunkSize) {
                      const chunk = responseText.slice(i, i + chunkSize);
                      controller.enqueue(
                        encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk })}\n\n`)
                      );
                      await new Promise(resolve => setTimeout(resolve, 20));
                    }
                  }

                  shouldContinue = false;
                  console.log('âœ… GPT-5 Thinking å¯¹è¯å®Œæˆ');
                }

              } catch (error: any) {
                console.error('âŒ GPT-5 Responses API è°ƒç”¨é”™è¯¯:', error);
                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ 
                    type: "error", 
                    error: `GPT-5 è°ƒç”¨å¤±è´¥: ${error.message}` 
                  })}\n\n`)
                );
                shouldContinue = false;
              }
              
              continue;
            } else {
              // æ ‡å‡†OpenAI APIè°ƒç”¨ (GPT-4o)
              const modelName = aiService.model || "gpt-4o";
              const modelConfig = actualReasoning.effort !== 'low' ? {
                model: modelName,
                temperature: 0.3,
                max_tokens: actualReasoning.effort === 'high' ? 32000 : actualReasoning.effort === 'medium' ? 24000 : 16000,
              } : {
                model: modelName,
                temperature: 0.7,
                max_tokens: 16000,
              };

              const openaiStream = await aiService.client.chat.completions.create({
                ...modelConfig,
                messages: conversationMessages,
                tools: actualUseTools ? tools : undefined,
                tool_choice: actualUseTools ? "auto" : undefined,
                stream: true,
              });

              stream = openaiStream;
            }

            let currentContent = "";
            let toolCalls: any[] = [];

            // gpt5-thinking å’Œ gpt5-pro éƒ½ä½¿ç”¨ Responses APIï¼Œå·²åœ¨ä¸Šé¢å¤„ç†å¹¶ continue
            if (aiService.provider === 'claude') {
              // å¤„ç†Claudeæµå¼å“åº”
              let claudeToolUse: any = null;
              let hasToolCall = false;
              
              for await (const chunk of stream) {
                if (chunk.type === 'content_block_start') {
                  if (chunk.content_block?.type === 'tool_use') {
                    hasToolCall = true;
                    claudeToolUse = {
                      id: chunk.content_block.id,
                      name: chunk.content_block.name,
                      input: {}
                    };
                    console.log(`ğŸ”§ æ£€æµ‹åˆ°Claudeå·¥å…·è°ƒç”¨: ${chunk.content_block.name}`);
                  }
                } else if (chunk.type === 'content_block_delta') {
                  if (chunk.delta?.type === 'text_delta') {
                    currentContent += chunk.delta.text;
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ type: "content", content: chunk.delta.text })}\n\n`)
                    );
                  } else if (chunk.delta?.type === 'input_json_delta' && claudeToolUse) {
                    // å·¥å…·è°ƒç”¨å‚æ•°
                    if (!claudeToolUse.inputText) claudeToolUse.inputText = '';
                    claudeToolUse.inputText += chunk.delta.partial_json;
                  }
                } else if (chunk.type === 'content_block_stop' && claudeToolUse) {
                  // å·¥å…·è°ƒç”¨å‚æ•°æ¥æ”¶å®Œæˆ
                  try {
                    claudeToolUse.input = JSON.parse(claudeToolUse.inputText || '{}');
                    console.log(`ğŸ“¥ Claudeå·¥å…·å‚æ•°: ${JSON.stringify(claudeToolUse.input)}`);
                  } catch (e) {
                    console.error('å·¥å…·å‚æ•°è§£æå¤±è´¥:', e);
                    claudeToolUse = null;
                  }
                } else if (chunk.type === 'message_stop') {
                  console.log('ğŸ Claudeæ¶ˆæ¯æµç»“æŸ');
                  // å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·
                  if (hasToolCall && claudeToolUse) {
                    console.log(`âš™ï¸ æ‰§è¡Œå·¥å…·: ${claudeToolUse.name}`);
                    
                    // å‘é€å·¥å…·è°ƒç”¨
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ type: "tool_call", tool: claudeToolUse.name, args: claudeToolUse.input })}\n\n`)
                    );
                    
                    // æ‰§è¡Œå·¥å…·
                    const toolResult = await executeToolCall(claudeToolUse.name, claudeToolUse.input);
                    
                    controller.enqueue(
                      encoder.encode(`data: ${JSON.stringify({ type: "tool_result", tool: claudeToolUse.name, result: toolResult })}\n\n`)
                    );
                    
                    // æ·»åŠ åˆ°å¯¹è¯å†å²ï¼ˆClaudeæ ¼å¼ï¼‰
                    conversationMessages.push({
                      role: "assistant",
                      content: [
                        ...(currentContent ? [{ type: "text", text: currentContent }] : []),
                        {
                          type: "tool_use",
                          id: claudeToolUse.id,
                          name: claudeToolUse.name,
                          input: claudeToolUse.input
                        }
                      ]
                    });
                    
                    conversationMessages.push({
                      role: "user",
                      content: [{
                        type: "tool_result",
                        tool_use_id: claudeToolUse.id,
                        content: JSON.stringify(toolResult)
                      }]
                    });
                    
                    shouldContinue = true;
                    currentContent = '';
                    console.log(`âœ… Claudeå·¥å…·è°ƒç”¨å®Œæˆï¼ŒshouldContinue=${shouldContinue}, iterationCount=${iterationCount}`);
                  } else {
                    shouldContinue = false;
                    console.log('ğŸ›‘ Claudeæ¶ˆæ¯å®Œæˆï¼Œæ— å·¥å…·è°ƒç”¨');
                  }
                  break; // è·³å‡ºæµå¾ªç¯
                }
              }
              console.log(`ğŸ“Š Claudeæµå¤„ç†ç»“æŸï¼ŒshouldContinue=${shouldContinue}, å°†${shouldContinue ? 'ç»§ç»­' : 'åœæ­¢'}å¾ªç¯`);
            } else if (aiService.provider === 'doubao') {
              // å¤„ç†è±†åŒ…æµå¼å“åº”ï¼ˆç±»ä¼¼OpenAI SSEæ ¼å¼ï¼‰
              const reader = stream.getReader();
              const decoder = new TextDecoder();

              while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value);
                const lines = chunk.split('\n');

                for (const line of lines) {
                  if (line.startsWith('data: ')) {
                    const data = line.slice(6);
                    if (data === '[DONE]') {
                      shouldContinue = false;
                      break;
                    }
                    
                    try {
                      const parsed = JSON.parse(data);
                      const delta = parsed.choices?.[0]?.delta;
                      
                      if (delta?.content) {
                        currentContent += delta.content;
                        controller.enqueue(
                          encoder.encode(`data: ${JSON.stringify({ type: "content", content: delta.content })}\n\n`)
                        );
                      }
                      
                      if (parsed.choices?.[0]?.finish_reason === 'stop') {
                        shouldContinue = false;
                      }
                    } catch (e) {
                      // å¿½ç•¥è§£æé”™è¯¯
                    }
                  }
                }
              }
            } else {
              // å¤„ç†OpenAIæµå¼å“åº”
            for await (const chunk of stream) {
              const delta = chunk.choices[0]?.delta;

              if (delta?.content) {
                currentContent += delta.content;
                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ type: "content", content: delta.content })}\n\n`)
                );
              }

              if (delta?.tool_calls) {
                for (const toolCall of delta.tool_calls) {
                  if (toolCall.index !== undefined) {
                    if (!toolCalls[toolCall.index]) {
                      toolCalls[toolCall.index] = {
                        id: toolCall.id || "",
                        type: "function",
                        function: { name: "", arguments: "" },
                      };
                    }
                    if (toolCall.id) toolCalls[toolCall.index].id = toolCall.id;
                    if (toolCall.function?.name) toolCalls[toolCall.index].function.name = toolCall.function.name;
                    if (toolCall.function?.arguments) toolCalls[toolCall.index].function.arguments += toolCall.function.arguments;
                  }
                }
              }

              if (chunk.choices[0]?.finish_reason === "tool_calls") {
                shouldContinue = true;
              } else if (chunk.choices[0]?.finish_reason === "stop") {
                shouldContinue = false;
                }
              }
            }

            // å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆOpenAIæ”¯æŒï¼ŒClaudeåœ¨æµå†…å¤„ç†ï¼ŒGPT5ç³»åˆ—ä½¿ç”¨Responses APIå•ç‹¬å¤„ç†ï¼‰
            if (aiService.provider === 'openai' && actualUseTools && toolCalls.length > 0) {
              conversationMessages.push({
                role: "assistant",
                content: currentContent || null,
                tool_calls: toolCalls,
              });

              for (const toolCall of toolCalls) {
                const functionName = toolCall.function.name;
                const functionArgs = JSON.parse(toolCall.function.arguments);

                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ type: "tool_call", tool: functionName, args: functionArgs })}\n\n`)
                );

                const toolResult = await executeToolCall(functionName, functionArgs);

                controller.enqueue(
                  encoder.encode(`data: ${JSON.stringify({ type: "tool_result", tool: functionName, result: toolResult })}\n\n`)
                );

                conversationMessages.push({
                  role: "tool",
                  content: JSON.stringify(toolResult),
                  tool_call_id: toolCall.id,
                });
              }
            } else if (aiService.provider !== 'claude') {
              // éClaudeä¸”æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œåœæ­¢å¾ªç¯
              // Claudeçš„shouldContinueåœ¨æµå†…éƒ¨æ§åˆ¶
              // GPT5ç³»åˆ—ä½¿ç”¨Responses APIï¼Œé€šè¿‡continueè·³è¿‡æµå¤„ç†
              shouldContinue = false;
            }
          }
          
          // whileå¾ªç¯ç»“æŸ

          // æ•°å­—äººåŠŸèƒ½ï¼šAgentå›ç­”å®Œæˆåï¼Œä½¿ç”¨LLM-TTSåŒå‘æµå¼ï¼ˆæ”¾åœ¨å¾ªç¯å¤–ï¼Œåªæ‰§è¡Œä¸€æ¬¡ï¼‰
          if (avatarEnabled && conversationMessages.length > 1) {
            try {
              controller.enqueue(
                encoder.encode(`data: ${JSON.stringify({ type: "avatar_start", content: "æ•°å­—äººæ­£åœ¨å¤„ç†..." })}\n\n`)
              );

              // è·å–Agentçš„å®Œæ•´å›ç­”
              const agentResponse = conversationMessages[conversationMessages.length - 1];
              const agentContent = typeof agentResponse.content === 'string' 
                ? agentResponse.content 
                : JSON.stringify(agentResponse.content);

              // è°ƒç”¨Python LLM-TTSåŒå‘æµå¼æœåŠ¡
              const voiceServerUrl = process.env.VOICE_SERVER_URL || 'http://localhost:8001';
              const llmTtsResponse = await fetch(`${voiceServerUrl}/api/llm-tts-stream`, {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  agentContent: agentContent,
                  voice: avatarVoice
                })
              });

              if (llmTtsResponse.ok) {
                const llmTtsData = await llmTtsResponse.json();
                
                if (llmTtsData.success && llmTtsData.audioBase64) {
                  // å‘é€éŸ³é¢‘æ•°æ®å’Œæ€»ç»“æ–‡æœ¬
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify({ 
                      type: "avatar_audio", 
                      audioBase64: llmTtsData.audioBase64,
                      audioSize: llmTtsData.audioSize,
                      summaryText: llmTtsData.summaryText || "",  // æ•°å­—å‘˜å·¥çš„æ€»ç»“æ–‡æœ¬
                      voice: avatarVoice 
                    })}\n\n`)
                  );

                  console.log(`ğŸ¤ LLM-TTSåŒå‘æµå¼å®Œæˆ [éŸ³è‰²: ${avatarVoice}]: ${llmTtsData.audioSize} å­—èŠ‚`);
                  console.log(`ğŸ“ æ€»ç»“æ–‡æœ¬: ${llmTtsData.summaryText?.substring(0, 50)}...`);
                }
              }
            } catch (error) {
              console.error('æ•°å­—äººå¤„ç†é”™è¯¯:', error);
              // å‘é€é”™è¯¯ä½†ä¸ä¸­æ–­
              controller.enqueue(
                encoder.encode(`data: ${JSON.stringify({ type: "avatar_error", content: "æ•°å­—äººæœåŠ¡æš‚æ—¶ä¸å¯ç”¨" })}\n\n`)
              );
            }
          }

          try {
          controller.enqueue(encoder.encode("data: [DONE]\n\n"));
          } catch (e) {
            // Controllerå¯èƒ½å·²ç»å…³é—­ï¼Œå¿½ç•¥é”™è¯¯
          }
          try {
          controller.close();
          } catch (e) {
            // Controllerå¯èƒ½å·²ç»å…³é—­ï¼Œå¿½ç•¥é”™è¯¯
          }
        } catch (error) {
          console.error("æµå¼å¤„ç†é”™è¯¯:", error);
          try {
          controller.enqueue(
            encoder.encode(`data: ${JSON.stringify({ type: "error", error: "å¤„ç†è¯·æ±‚æ—¶å‡ºé”™" })}\n\n`)
          );
          } catch (e) {
            // Controllerå¯èƒ½å·²ç»å…³é—­ï¼Œå¿½ç•¥é”™è¯¯
          }
          try {
          controller.close();
          } catch (e) {
            // Controllerå¯èƒ½å·²ç»å…³é—­ï¼Œå¿½ç•¥é”™è¯¯
          }
        }
      },
    });

    return new Response(customStream, {
      headers: {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
      },
    });
  } catch (error) {
    console.error("API é”™è¯¯:", error);
    return new Response(JSON.stringify({ error: "å¤„ç†è¯·æ±‚æ—¶å‡ºé”™" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}

