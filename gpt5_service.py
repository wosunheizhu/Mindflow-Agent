"""
GPT-5 Responses API æœåŠ¡
ä¸“é—¨å¤„ç† GPT-5 çš„ Responses API è°ƒç”¨ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨å’Œ agentic å·¥ä½œæµ
"""

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional, Callable
import httpx
import os
from dotenv import load_dotenv
import json
import requests

load_dotenv()

app = FastAPI(title="GPT-5 Responses API Service")

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI API é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = "https://api.openai.com/v1"


class Message(BaseModel):
    role: str
    content: Optional[str] = None  # content å¯ä»¥ä¸º nullï¼ˆæ¯”å¦‚å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼‰
    tool_calls: Optional[List[Dict[str, Any]]] = None
    tool_call_id: Optional[str] = None
    
    class Config:
        extra = "allow"  # å…è®¸é¢å¤–å­—æ®µ


class Tool(BaseModel):
    type: str
    function: Optional[Dict[str, Any]] = None  # è‡ªå®šä¹‰å·¥å…·æœ‰ function å­—æ®µ
    name: Optional[str] = None  # å†…ç½®å·¥å…·å’Œ Responses API æ ¼å¼çš„å·¥å…·æœ‰ name
    description: Optional[str] = None
    parameters: Optional[Dict[str, Any]] = None
    
    class Config:
        extra = "allow"  # å…è®¸é¢å¤–å­—æ®µ


class GPT5Request(BaseModel):
    model: str = "gpt-5"
    input: List[Message]
    reasoning: Optional[Dict[str, str]] = {"effort": "medium"}
    text: Optional[Dict[str, str]] = {"verbosity": "medium"}
    tools: Optional[List[Tool]] = None
    tool_choice: Optional[str] = "auto"
    previous_response_id: Optional[str] = None


class GPT5Response(BaseModel):
    output_text: Optional[str] = None
    reasoning_content: Optional[str] = None
    tool_calls: Optional[List[Dict[str, Any]]] = None
    web_search_calls: Optional[List[Dict[str, Any]]] = None  # å†…ç½®å·¥å…·è°ƒç”¨
    response_id: Optional[str] = None
    usage: Optional[Dict[str, Any]] = None


# ---- ä» Responses API çš„ output ä¸­æå– function_call ----
def extract_function_calls(response_json: Dict[str, Any]) -> List[Dict[str, Any]]:
    """æå– output æ•°ç»„ä¸­çš„ function_call é¡¹"""
    calls: List[Dict[str, Any]] = []
    try:
        for item in response_json.get("output", []) or []:
            if item.get("type") == "function_call":
                calls.append({
                    "id": item.get("id"),
                    "name": item.get("name"),
                    "arguments": item.get("arguments", "{}"),
                    "status": item.get("status"),
                })
    except Exception as e:
        print(f"  âš ï¸ æå– function_call æ—¶å‡ºé”™: {e}")
    
    valid_calls = [c for c in calls if c.get("id") and c.get("name")]
    if valid_calls:
        print(f"  ğŸ”§ æå–åˆ° {len(valid_calls)} ä¸ªæœ‰æ•ˆçš„ function_call")
    return valid_calls


def safe_json_string(obj: Any, max_len: int = 400_000) -> str:
    """å®‰å…¨åœ°åºåˆ—åŒ–å¯¹è±¡ä¸º JSON å­—ç¬¦ä¸²ï¼Œå¹¶æ§åˆ¶é•¿åº¦"""
    try:
        s = json.dumps(obj, ensure_ascii=False)
    except Exception:
        s = str(obj)
    
    # æ§åˆ¶é•¿åº¦ï¼ˆResponses API é™åˆ¶ï¼‰
    if len(s) > max_len:
        s = s[:max_len] + f"...[truncated {len(s)-max_len} chars]"
    return s


@app.get("/")
async def root():
    return {
        "service": "GPT-5 Responses API Service",
        "status": "running",
        "endpoints": {
            "responses": "/api/responses",
            "health": "/health"
        }
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "api_configured": bool(OPENAI_API_KEY)}


@app.post("/api/responses", response_model=GPT5Response)
async def create_response(request: GPT5Request):
    """
    è°ƒç”¨ GPT-5 Responses API
    
    è¿™æ˜¯ OpenAI GPT-5 æ¨èçš„ API ç«¯ç‚¹ï¼Œæ”¯æŒï¼š
    - reasoning.effort æ§åˆ¶æ¨ç†æ·±åº¦
    - text.verbosity æ§åˆ¶è¾“å‡ºè¯¦ç•¥
    - previous_response_id ä¿æŒä¸Šä¸‹æ–‡
    - åŸç”Ÿå·¥å…·è°ƒç”¨æ”¯æŒ
    """
    
    if not OPENAI_API_KEY:
        raise HTTPException(status_code=500, detail="OPENAI_API_KEY not configured")
    
    # æ„å»ºè¯·æ±‚æ•°æ®å¹¶æ¸…ç†æ¶ˆæ¯æ ¼å¼
    # Responses API ä¸¥æ ¼è¦æ±‚ï¼š
    # 1. ä¸æ¥å— role:"tool"ï¼ˆåªå…è®¸ assistant/system/developer/userï¼‰
    # 2. ä¸æ¥å— tool_calls/function_call ç­‰æ¨¡å‹äº§å‡ºå­—æ®µ
    # 3. content åº”è¯¥æ˜¯æ•°ç»„æ ¼å¼ [{"type":"text","text":"..."}]
    
    ALLOWED_ROLES = {"assistant", "system", "developer", "user"}
    
    cleaned_input = []
    skipped_count = 0
    
    for i, msg in enumerate(request.input):
        msg_dict = msg.model_dump(exclude_none=True)
        role = msg_dict.get("role")
        
        # ç§»é™¤å‰ç«¯ç‰¹æœ‰å­—æ®µï¼ˆOpenAI API ä¸æ”¯æŒï¼‰
        frontend_only_fields = ["fromAvatar", "avatarName", "avatarImage", "toolCalls", "thinkingSteps", "modelThinking", "reasoningContent"]
        for field in frontend_only_fields:
            msg_dict.pop(field, None)
        
        # æå–æ–‡æœ¬å†…å®¹
        raw_content = msg_dict.get("content", "")
        if isinstance(raw_content, dict):
            text = raw_content.get("text") or raw_content.get("content") or ""
        elif isinstance(raw_content, list):
            # å¯èƒ½æ˜¯ [{"type":"text","text":"..."}] æ ¼å¼
            texts = []
            for item in raw_content:
                if isinstance(item, dict):
                    texts.append(str(item.get("text") or item.get("content") or ""))
                else:
                    texts.append(str(item))
            text = "\n".join(texts).strip()
        else:
            text = str(raw_content).strip()
        
        # æ£€æŸ¥å¹¶è­¦å‘Šï¼šå¦‚æœæ¶ˆæ¯åŒ…å«ç¦æ­¢å­—æ®µ
        if "tool_calls" in msg_dict or "toolCalls" in msg_dict or "function_call" in msg_dict:
            print(f"  âš ï¸ æ¶ˆæ¯ [{i}] role={role} åŒ…å« tool_callsï¼Œå°†è¢«ç§»é™¤")
        
        # å…³é”®ä¿®å¤ï¼šå°† role:"tool" è½¬æ¢ä¸º role:"assistant"
        if role == "tool":
            # å·¥å…·ç»“æœæ”¹å†™ä¸º assistant çš„ output_text
            if text:
                print(f"  ğŸ”„ æ¶ˆæ¯ [{i}] role=tool è½¬æ¢ä¸º role=assistant (output_text)")
                cleaned_input.append({
                    "role": "assistant",
                    "content": [{"type": "output_text", "text": text}]
                })
            else:
                print(f"  âš ï¸ æ¶ˆæ¯ [{i}] role=tool æ— å†…å®¹ï¼Œè·³è¿‡")
                skipped_count += 1
            continue
        
        # å…¶ä»–éæ³•è§’è‰²è½¬æ¢ä¸º user
        if role not in ALLOWED_ROLES:
            print(f"  âš ï¸ æ¶ˆæ¯ [{i}] role={role} ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­ï¼Œè½¬æ¢ä¸º user")
            role = "user"
        
        # æŒ‰è§’è‰²æ˜ å°„åˆ°æ­£ç¡®çš„ content type
        # user/system/developer â†’ input_text
        # assistant â†’ output_text
        if text:
            if role in ("user", "system", "developer"):
                cleaned_input.append({
                    "role": role,
                    "content": [{"type": "input_text", "text": text}]
                })
            else:  # assistant
                cleaned_input.append({
                    "role": role,
                    "content": [{"type": "output_text", "text": text}]
                })
        else:
            # æ²¡æœ‰ contentï¼ˆå¯èƒ½åªæœ‰ tool_callsï¼‰ï¼Œè·³è¿‡
            print(f"  âš ï¸ æ¶ˆæ¯ [{i}] role={role} æ²¡æœ‰ contentï¼Œè·³è¿‡")
            skipped_count += 1
    
    print(f"ğŸ“ æ¸…ç†åçš„æ¶ˆæ¯: {len(cleaned_input)} æ¡ï¼ˆè·³è¿‡ {skipped_count} æ¡ï¼‰")
    
    # éªŒè¯ï¼šç¡®ä¿æ²¡æœ‰ç¦æ­¢å­—æ®µå’Œè§’è‰²
    input_json = json.dumps(cleaned_input)
    
    # æ£€æŸ¥ content.type æ˜¯å¦æ­£ç¡®
    try:
        if cleaned_input:
            first_type = cleaned_input[0]["content"][0]["type"] if cleaned_input[0].get("content") else None
            print(f"  ğŸ“‹ é¦–æ¡æ¶ˆæ¯ content.type: {first_type}")
    except Exception:
        pass
    
    if "tool_calls" in input_json or "toolCalls" in input_json:
        print(f"  âš ï¸âš ï¸âš ï¸ è­¦å‘Šï¼šinput ä»åŒ…å« tool_callsï¼")
    if '"role":"tool"' in input_json or '"role": "tool"' in input_json:
        print(f"  âš ï¸âš ï¸âš ï¸ è­¦å‘Šï¼šinput ä»åŒ…å« role:toolï¼")
    if '"type":"text"' in input_json or '"type": "text"' in input_json:
        print(f"  âš ï¸âš ï¸âš ï¸ è­¦å‘Šï¼šinput ä½¿ç”¨äº† type:textï¼ˆåº”è¯¥æ˜¯ input_text/output_textï¼‰ï¼")
    else:
        print(f"  âœ… ç¡®è®¤ï¼šæ—  tool_callsã€æ—  role:toolã€æ­£ç¡®ä½¿ç”¨ input_text/output_text")
    
    payload = {
        "model": request.model,
        "input": cleaned_input,
    }
    
    # æ·»åŠ  GPT-5 ç‰¹æœ‰å‚æ•°
    if request.reasoning:
        payload["reasoning"] = request.reasoning
    
    if request.text:
        payload["text"] = request.text
    
    # æ·»åŠ å·¥å…·å®šä¹‰ï¼ˆè½¬æ¢ä¸º Responses API æ ¼å¼ï¼‰
    if request.tools:
        # è½¬æ¢å·¥å…·æ ¼å¼ï¼šChat Completions æ ¼å¼ -> Responses API æ ¼å¼
        # Chat Completions: {"type": "function", "function": {"name": "...", "description": "...", "parameters": {...}}}
        # Responses API: {"type": "function", "name": "...", "description": "...", "parameters": {...}}
        # å†…ç½®å·¥å…·: {"type": "web_search"}
        converted_tools = []
        for tool in request.tools:
            tool_dict = tool.model_dump(exclude_none=True)
            
            # å†…ç½®å·¥å…·ï¼ˆåªæœ‰ type å­—æ®µï¼‰
            if tool_dict.get("type") in ["web_search", "file_search", "code_interpreter", "image_generation"]:
                converted_tool = {"type": tool_dict["type"]}
                print(f"  âœ… æ·»åŠ å†…ç½®å·¥å…·: {tool_dict['type']}")
            
            # Chat Completions æ ¼å¼ï¼ˆåµŒå¥—åœ¨ function ä¸‹ï¼‰
            elif "function" in tool_dict and isinstance(tool_dict["function"], dict):
                converted_tool = {
                    "type": tool_dict.get("type", "function"),
                    "name": tool_dict["function"].get("name"),
                    "description": tool_dict["function"].get("description"),
                    "parameters": tool_dict["function"].get("parameters", {})
                }
                print(f"  âœ… è½¬æ¢è‡ªå®šä¹‰å·¥å…·: {converted_tool['name']}")
            
            # å·²ç»æ˜¯ Responses API æ ¼å¼ï¼ˆé¡¶å±‚æœ‰ nameï¼‰
            elif "name" in tool_dict:
                converted_tool = tool_dict
                print(f"  âœ… ä¿ç•™ Responses API æ ¼å¼å·¥å…·: {tool_dict['name']}")
            
            else:
                print(f"  âš ï¸ æœªçŸ¥å·¥å…·æ ¼å¼ï¼Œè·³è¿‡: {tool_dict}")
                continue
            
            converted_tools.append(converted_tool)
        
        payload["tools"] = converted_tools
        if request.tool_choice:
            payload["tool_choice"] = request.tool_choice
        
        print(f"âœ… æ€»è®¡ {len(converted_tools)} ä¸ªå·¥å…·ï¼ˆå«å†…ç½®å’Œè‡ªå®šä¹‰ï¼‰")
    
    # æ·»åŠ ä¸Šä¸‹æ–‡ IDï¼ˆå¦‚æœæœ‰ï¼‰
    if request.previous_response_id:
        payload["previous_response_id"] = request.previous_response_id
    
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }
    
    # æ‰“å°è¯·æ±‚è¯¦æƒ…ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    print(f"\nğŸ“¤ å‘é€åˆ° OpenAI Responses API:")
    print(f"æ¨¡å‹: {payload['model']}")
    print(f"æ¶ˆæ¯æ•°: {len(payload['input'])}")
    print(f"å·¥å…·æ•°: {len(payload.get('tools', []))}")
    if payload.get('tools'):
        # æ¸…ç†å·¥å…·åˆ—è¡¨ä¸­çš„å ä½ç¬¦å’Œéæ³•é¡¹
        tool_names = []
        for t in payload['tools']:
            name = t.get('function', {}).get('name') or t.get('name', '')
            if name and name != '?':
                tool_names.append(name)
        print(f"å·¥å…·åˆ—è¡¨: {tool_names[:5]}")
    print(f"Reasoning: {payload.get('reasoning')}")
    print(f"Text: {payload.get('text')}\n")
    
    try:
        # å¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆGPT-5 web_search å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰
        async with httpx.AsyncClient(timeout=300.0) as client:
            # è°ƒç”¨ OpenAI Responses API
            response = await client.post(
                f"{OPENAI_BASE_URL}/responses",
                headers=headers,
                json=payload
            )
            
            if response.status_code != 200:
                error_detail = response.text
                print(f"âŒ OpenAI API é”™è¯¯: {response.status_code}")
                print(f"å“åº”å†…å®¹: {error_detail}")
                raise HTTPException(
                    status_code=response.status_code,
                    detail=f"OpenAI API error: {error_detail}"
                )
            
            result = response.json()
            
            # æ‰“å°å“åº”è¯¦æƒ…ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            print(f"\nğŸ“¥ æ”¶åˆ° OpenAI Responses API å“åº”:")
            print(f"å“åº”é”®: {list(result.keys())}")
            
            # æ‰“å°å®Œæ•´çš„ output æ•°ç»„
            if result.get("output"):
                print(f"output æ•°ç»„é•¿åº¦: {len(result['output'])}")
                for i, item in enumerate(result["output"]):
                    item_type = item.get('type')  # â† å®šä¹‰å˜é‡
                    print(f"  [{i}] type={item_type}, keys={list(item.keys())[:10]}")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    if item.get('tool_calls'):
                        print(f"      ğŸ”§ å‘ç°å·¥å…·è°ƒç”¨: {len(item['tool_calls'])} ä¸ª")
                        for tc in item.get('tool_calls', [])[:2]:
                            print(f"         - {tc.get('function', {}).get('name', tc.get('name', '?'))}")
                    
                    # æ£€æŸ¥å†…ç½®å·¥å…·è°ƒç”¨ï¼ˆweb_search_call, file_search_call ç­‰ï¼‰
                    if item_type == "web_search_call":
                        action = item.get('action', {})
                        query = action.get('query', '')
                        print(f"      ğŸŒ å†…ç½® web_search: {query[:50]}...")
                    
                    if item_type == 'text':
                        content = item.get('content', item.get('text', ''))
                        print(f"      æ–‡æœ¬å†…å®¹: {content[:100]}...")
                    elif item_type == 'message':
                        print(f"      message content é•¿åº¦: {len(item.get('content', []))}")
                    elif item_type == 'reasoning':
                        summary = item.get('summary', item.get('content', ''))
                        print(f"      æ¨ç†å†…å®¹: {summary[:100]}...")
            
            print(f"å®Œæ•´ JSON (å‰ 1000 å­—ç¬¦): {json.dumps(result, indent=2, ensure_ascii=False)[:1000]}...\n")
            
            # è§£æ Responses API çš„å“åº”æ ¼å¼
            output_text = None
            reasoning_content = None
            tool_calls = None
            web_search_calls = []  # æ”¶é›†å†…ç½®å·¥å…·è°ƒç”¨ä¿¡æ¯
            
            # Responses API è¿”å›çš„ output æ˜¯ä¸€ä¸ªæ•°ç»„
            if result.get("output") and isinstance(result["output"], list):
                for item in result["output"]:
                    item_type = item.get("type")
                    
                    # æå–æ–‡æœ¬å†…å®¹ - å¤„ç† message ç±»å‹
                    if item_type == "message":
                        # content æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œéœ€è¦éå†
                        content_list = item.get("content", [])
                        if isinstance(content_list, list):
                            for content_item in content_list:
                                # æŸ¥æ‰¾ output_text ç±»å‹
                                if content_item.get("type") == "output_text":
                                    output_text = content_item.get("text", "")
                                    break
                        elif isinstance(content_list, str):
                            # å¦‚æœ content æ˜¯å­—ç¬¦ä¸²
                            output_text = content_list
                    
                    # å¤‡ç”¨ï¼šæå–æ–‡æœ¬å†…å®¹ - text ç±»å‹
                    elif item_type == "text":
                        if item.get("content"):
                            output_text = item["content"]
                        elif item.get("text"):
                            output_text = item["text"]
                    
                    # æå– reasoning å†…å®¹
                    elif item_type == "reasoning":
                        summary = item.get("summary")
                        # summary å¯èƒ½æ˜¯æ•°ç»„æˆ–å­—ç¬¦ä¸²
                        if isinstance(summary, str):
                            reasoning_content = summary
                        elif isinstance(summary, list) and len(summary) > 0:
                            reasoning_content = str(summary)
                        elif item.get("content"):
                            reasoning_content = item["content"]
                    
                    # æå–å†…ç½® web_search è°ƒç”¨ä¿¡æ¯
                    elif item_type == "web_search_call":
                        action = item.get("action", {})
                        web_search_calls.append({
                            "id": item.get("id"),
                            "type": "web_search",
                            "query": action.get("query", ""),
                            "status": item.get("status", "completed")
                        })
                    
                    # æå–å·¥å…·è°ƒç”¨ - å…³é”®ä¿®å¤ï¼
                    # 1. æ•°ç»„å½¢å¼çš„å·¥å…·è°ƒç”¨
                    if item.get("tool_calls") and isinstance(item["tool_calls"], list):
                        if not tool_calls:
                            tool_calls = []
                        tool_calls.extend(item["tool_calls"])
                        print(f"      ğŸ”§ å‘ç°å·¥å…·è°ƒç”¨æ•°ç»„: {len(item['tool_calls'])} ä¸ª")
                    
                    # 2. å•ä¸ªå·¥å…·è°ƒç”¨ï¼ˆtype == "function_call"ï¼‰
                    elif item_type == "function_call":
                        if not tool_calls:
                            tool_calls = []
                        
                        # æ„å»ºæ ‡å‡†æ ¼å¼çš„å·¥å…·è°ƒç”¨
                        tool_call = {
                            "id": item.get("id"),
                            "type": "function",
                            "function": {
                                "name": item.get("name"),  # å·¥å…·åç§°
                                "arguments": item.get("arguments", "{}")  # å‚æ•°
                            }
                        }
                        tool_calls.append(tool_call)
                        print(f"      ğŸ”§ å‘ç°å•ä¸ªå·¥å…·è°ƒç”¨: {item.get('name')}")
                    
                    # 3. message ç±»å‹ä¸­å¯èƒ½ä¹Ÿæœ‰å·¥å…·è°ƒç”¨
                    elif item_type == "message" and item.get("tool_calls"):
                        if not tool_calls:
                            tool_calls = []
                        tool_calls.extend(item["tool_calls"])
                        print(f"      ğŸ”§ message ä¸­æœ‰å·¥å…·è°ƒç”¨: {len(item['tool_calls'])} ä¸ª")
            
            # å¤‡ç”¨ï¼šå°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
            if not output_text:
                if isinstance(result.get("output_text"), str):
                    output_text = result["output_text"]
                elif isinstance(result.get("text"), str):
                    output_text = result["text"]
                elif result.get("choices"):
                    output_text = result["choices"][0].get("message", {}).get("content")
            
            if not reasoning_content and result.get("reasoning"):
                if isinstance(result["reasoning"], dict):
                    reasoning_content = result["reasoning"].get("summary") or result["reasoning"].get("content")
            
            print(f"âœ… è§£æç»“æœ: æ–‡æœ¬é•¿åº¦={len(output_text) if output_text else 0}, reasoning={bool(reasoning_content)}, è‡ªå®šä¹‰å·¥å…·={len(tool_calls) if tool_calls else 0}, web_search={len(web_search_calls)}")
            
            # === æ£€æŸ¥æ˜¯å¦æœ‰ function_callï¼Œå¦‚æœæœ‰åˆ™æ‰§è¡ŒäºŒæ®µå¼å›è·¯ ===
            function_calls = extract_function_calls(result)
            
            if function_calls:
                print(f"\nğŸ”§ æ£€æµ‹åˆ° {len(function_calls)} ä¸ª function_callï¼Œå¼€å§‹äºŒæ®µå¼å·¥å…·å›è·¯")
                
                # æ„å»º tool_outputs
                tool_outputs = []
                for call in function_calls:
                    call_id = call["id"]
                    name = call["name"]
                    args_str = call.get("arguments", "{}")
                    
                    print(f"  âš™ï¸ å·¥å…·è°ƒç”¨: {name} (id={call_id[:20]}...)")
                    
                    try:
                        # è§£æå‚æ•°
                        if isinstance(args_str, str):
                            args = json.loads(args_str) if args_str else {}
                        else:
                            args = args_str
                        
                        # æ³¨æ„ï¼šè¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„å·¥å…·æ‰§è¡Œå‡½æ•°
                        # ç›®å‰è¿”å›å ä½ç»“æœï¼Œå®é™…éƒ¨ç½²æ—¶éœ€è¦é›†æˆå·¥å…·æ‰§è¡Œé€»è¾‘
                        result_text = f"å·¥å…· {name} å·²ç”±åç«¯å¤„ç†ï¼ˆå ä½å“åº”ï¼‰"
                        
                        # æ„å»º tool_outputï¼ˆResponses API æ ¼å¼ï¼‰
                        tool_outputs.append({
                            "tool_call_id": call_id,
                            "output": result_text  # æ³¨æ„ï¼šå¯èƒ½éœ€è¦ç‰¹å®šæ ¼å¼
                        })
                        
                        print(f"    âœ… å·¥å…· {name} æ‰§è¡Œå®Œæˆ")
                    except Exception as e:
                        print(f"    âŒ å·¥å…· {name} æ‰§è¡Œå¤±è´¥: {e}")
                        tool_outputs.append({
                            "tool_call_id": call_id,
                            "output": f"é”™è¯¯: {str(e)}"
                        })
                
                # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼šä½¿ç”¨ previous_response_id + tool_outputs ç»­å†™
                follow_up_payload = {
                    "model": request.model,
                    "previous_response_id": result.get("id"),
                    "tool_outputs": tool_outputs,
                }
                
                # ä¿æŒç›¸åŒçš„å‚æ•°
                if request.reasoning:
                    follow_up_payload["reasoning"] = request.reasoning
                if request.text:
                    follow_up_payload["text"] = request.text
                if request.tools:
                    follow_up_payload["tools"] = payload["tools"]  # ä½¿ç”¨å·²è½¬æ¢çš„å·¥å…·
                
                print(f"\nğŸ” ç»­å†™è¯·æ±‚: previous_response_id={result.get('id')[:20]}..., tool_outputs={len(tool_outputs)} ä¸ª")
                
                # å‘é€ç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆç»­å†™ä¹Ÿéœ€è¦è¶³å¤Ÿæ—¶é—´ï¼‰
                async with httpx.AsyncClient(timeout=300.0) as client:
                    follow_response = await client.post(
                        f"{OPENAI_BASE_URL}/responses",
                        headers=headers,
                        json=follow_up_payload
                    )
                    
                    if follow_response.status_code != 200:
                        error_detail = follow_response.text
                        print(f"âŒ OpenAI API é”™è¯¯ï¼ˆç»­å†™ï¼‰: {follow_response.status_code}")
                        print(f"å“åº”å†…å®¹: {error_detail}")
                        # å¦‚æœç»­å†™å¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€æ¬¡çš„ç»“æœ
                        print(f"âš ï¸ ç»­å†™å¤±è´¥ï¼Œè¿”å›ç¬¬ä¸€æ¬¡å“åº”")
                    else:
                        result = follow_response.json()
                        print(f"âœ… äºŒæ®µå¼å·¥å…·å›è·¯å®Œæˆ")
                        
                        # é‡æ–°è§£æç¬¬äºŒæ¬¡çš„å“åº”
                        output_text = None
                        reasoning_content = None
                        tool_calls = None
                        
                        if result.get("output") and isinstance(result["output"], list):
                            for item in result["output"]:
                                item_type = item.get("type")
                                
                                if item_type == "message":
                                    content_list = item.get("content", [])
                                    if isinstance(content_list, list):
                                        for content_item in content_list:
                                            if content_item.get("type") == "output_text":
                                                output_text = content_item.get("text", "")
                                                break
                                
                                elif item_type == "reasoning":
                                    summary = item.get("summary")
                                    if isinstance(summary, str):
                                        reasoning_content = summary
                                    elif isinstance(summary, list) and len(summary) > 0:
                                        reasoning_content = str(summary)
                        
                        print(f"âœ… äºŒæ®µå¼è§£æ: æ–‡æœ¬é•¿åº¦={len(output_text) if output_text else 0}")
            
            # è¿”å›å“åº”ï¼ˆåŒ…å«å†…ç½®å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼‰
            gpt5_response = GPT5Response(
                output_text=output_text,
                reasoning_content=reasoning_content,
                tool_calls=tool_calls,
                web_search_calls=web_search_calls if web_search_calls else None,
                response_id=result.get("id") or result.get("response_id"),
                usage=result.get("usage")
            )
            
            print(f"âœ… GPT-5 Responses API è°ƒç”¨æˆåŠŸï¼ˆæœ€ç»ˆï¼‰")
            
            return gpt5_response
            
    except httpx.TimeoutException:
        raise HTTPException(status_code=504, detail="Request timeout")
    except httpx.RequestError as e:
        raise HTTPException(status_code=500, detail=f"Request error: {str(e)}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/responses/stream")
async def create_response_stream(request: GPT5Request):
    """
    æµå¼è°ƒç”¨ GPT-5 Responses API
    - å®æ—¶æ¨é€ reasoning å’Œ content
    - SSE æ ¼å¼è¾“å‡º
    """
    print("ğŸ“¡ [GPT-5 Stream] æ”¶åˆ°æµå¼è¯·æ±‚", flush=True)
    print(f"ğŸ“¨ [GPT-5 Stream] è¯·æ±‚å‚æ•°: model={request.model}, inputæ¶ˆæ¯æ•°={len(request.input)}", flush=True)
    
    def sse_event(data: dict) -> str:
        """ç”Ÿæˆ SSE äº‹ä»¶"""
        return f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
    
    async def generate_stream():
        print("ğŸ”„ [GPT-5 Stream] generate_stream() å¼€å§‹æ‰§è¡Œ", flush=True)
        yield sse_event({"type": "debug", "content": "æµå¼ç”Ÿæˆå™¨å·²å¯åŠ¨"})
        print("âœ… [GPT-5 Stream] ç¬¬ä¸€ä¸ªäº‹ä»¶å·²yield", flush=True)
        try:
            print("ğŸ”§ [GPT-5 Stream] å¼€å§‹æ„å»ºè¯·æ±‚å‚æ•°", flush=True)
            # æ„å»ºè¯·æ±‚
            headers = {
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "Content-Type": "application/json",
            }
            
            # è§„èŒƒåŒ–æ¶ˆæ¯
            print(f"ğŸ“ [GPT-5 Stream] è§„èŒƒåŒ– {len(request.input)} æ¡æ¶ˆæ¯", flush=True)
            normalized_messages = []
            for msg in request.input:
                if isinstance(msg.content, str):
                    normalized_messages.append({
                        "role": msg.role,
                        "content": msg.content
                    })
                else:
                    normalized_messages.append(msg.model_dump(exclude_none=True))
            
            # è§„èŒƒåŒ–å·¥å…·ï¼ˆä¸éæµå¼ç«¯ç‚¹é€»è¾‘ä¸€è‡´ï¼‰
            print(f"ğŸ”§ [GPT-5 Stream] è§„èŒƒåŒ– {len(request.tools) if request.tools else 0} ä¸ªå·¥å…·", flush=True)
            normalized_tools = []
            if request.tools:
                for tool in request.tools:
                    tool_dict = tool.model_dump(exclude_none=True)
                    
                    # å†…ç½®å·¥å…·ï¼ˆåªæœ‰ type å­—æ®µï¼‰
                    if tool_dict.get("type") in ["web_search", "file_search", "code_interpreter", "image_generation"]:
                        normalized_tools.append({"type": tool_dict["type"]})
                        print(f"  âœ… æ·»åŠ å†…ç½®å·¥å…·: {tool_dict['type']}")
                    
                    # Chat Completions æ ¼å¼ï¼ˆåµŒå¥—åœ¨ function ä¸‹ï¼‰
                    elif "function" in tool_dict and isinstance(tool_dict["function"], dict):
                        tool_name = tool_dict["function"].get("name")
                        if tool_name and tool_name != "?":
                            normalized_tools.append({
                                "type": tool_dict.get("type", "function"),
                                "name": tool_name,
                                "description": tool_dict["function"].get("description", ""),
                                "parameters": tool_dict["function"].get("parameters", {})
                            })
                            print(f"  âœ… è½¬æ¢è‡ªå®šä¹‰å·¥å…·: {tool_name}")
                    
                    # å·²ç»æ˜¯ Responses API æ ¼å¼ï¼ˆé¡¶å±‚æœ‰ nameï¼‰
                    elif "name" in tool_dict:
                        if tool_dict["name"] != "?":
                            normalized_tools.append(tool_dict)
                            print(f"  âœ… ä¿ç•™ Responses API æ ¼å¼å·¥å…·: {tool_dict['name']}")
                
                print(f"âœ… æ€»è®¡ {len(normalized_tools)} ä¸ªå·¥å…·ï¼ˆå«å†…ç½®å’Œè‡ªå®šä¹‰ï¼‰")
            
            payload = {
                "model": request.model,
                "input": normalized_messages,
                "reasoning": request.reasoning or {"effort": "medium"},
                "text": request.text or {"verbosity": "medium"},
                "stream": True  # å…³é”®ï¼šå¼€å¯æµå¼
            }
            
            if normalized_tools:
                payload["tools"] = normalized_tools
                payload["tool_choice"] = request.tool_choice or "auto"
            
            if request.previous_response_id:
                payload["previous_response_id"] = request.previous_response_id
            
            print(f"ğŸ“¤ [GPT-5 Stream] å‘é€æµå¼è¯·æ±‚: model={request.model}, tools={len(normalized_tools)}, reasoning={payload['reasoning']}", flush=True)
            print(f"ğŸ“‹ [GPT-5 Stream] Payload keys: {list(payload.keys())}", flush=True)
            
            # ä½¿ç”¨ httpx å¼‚æ­¥å®¢æˆ·ç«¯è¿›è¡Œæµå¼è¯·æ±‚
            print("ğŸŒ [GPT-5 Stream] åˆ›å»º httpx å®¢æˆ·ç«¯...", flush=True)
            async with httpx.AsyncClient(timeout=600.0) as client:
                print("ğŸ“¡ [GPT-5 Stream] å¼€å§‹å‘é€ POST è¯·æ±‚...", flush=True)
                async with client.stream(
                    "POST",
                    f"{OPENAI_BASE_URL}/responses",
                    headers=headers,
                    json=payload
                ) as response:
                    if response.status_code != 200:
                        error_text = await response.aread()
                        error_str = error_text.decode('utf-8')
                        print(f"âŒ [GPT-5 Stream] é”™è¯¯: {response.status_code}", flush=True)
                        print(f"âŒ [GPT-5 Stream] é”™è¯¯è¯¦æƒ…: {error_str}", flush=True)
                        yield sse_event({"type": "error", "error": f"OpenAI API é”™è¯¯: {response.status_code}", "details": error_str})
                        yield "data: [DONE]\n\n"
                        return
                    
                    print("âœ… [GPT-5 Stream] å¼€å§‹æ¥æ”¶æµå¼å“åº”")
                    
                    # é€è¡Œè¯»å– SSE
                    reasoning_buffer = ""
                    content_buffer = ""
                    line_count = 0
                    
                    async for line in response.aiter_lines():
                        line_count += 1
                        if line_count % 10 == 0:
                            print(f"ğŸ“Š [GPT-5 Stream] å·²è¯»å– {line_count} è¡Œ")
                        if not line:
                            continue
                        if not line.startswith("data:"):
                            continue
                        
                        data = line[5:].strip()
                        if data == "[DONE]":
                            print("ğŸ [GPT-5 Stream] æµå¼å“åº”ç»“æŸ")
                            yield "data: [DONE]\n\n"
                            break
                        
                        try:
                            event = json.loads(data)
                            event_type = event.get("type", "")
                            
                            # å¤„ç† reasoning å¢é‡
                            if "reasoning" in event_type and "delta" in event:
                                delta_text = event.get("delta", "")
                                if delta_text:
                                    reasoning_buffer += delta_text
                                    yield sse_event({"type": "reasoning_stream", "content": delta_text})
                            
                            # å¤„ç† reasoning å®Œæˆ
                            elif "reasoning" in event_type and event.get("status") == "completed":
                                if reasoning_buffer:
                                    yield sse_event({"type": "reasoning_complete", "content": reasoning_buffer})
                            
                            # å¤„ç† content å¢é‡
                            elif "output" in event_type or "message" in event_type:
                                delta_text = event.get("delta") or event.get("text") or ""
                                if delta_text:
                                    content_buffer += delta_text
                                    yield sse_event({"type": "content", "content": delta_text})
                            
                            # å¤„ç†å·¥å…·è°ƒç”¨
                            elif "function_call" in event_type or "tool_call" in event_type:
                                yield sse_event({
                                    "type": "tool_call",
                                    "name": event.get("name"),
                                    "arguments": event.get("arguments", "")
                                })
                        
                        except json.JSONDecodeError:
                            continue
                        except Exception as e:
                            print(f"âš ï¸ [GPT-5 Stream] è§£æäº‹ä»¶å¤±è´¥: {e}")
                            continue
        
        except Exception as e:
            print(f"âŒ [GPT-5 Stream] æµå¼å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            yield sse_event({"type": "error", "error": str(e)})
            yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


if __name__ == "__main__":
    import uvicorn
    
    # Railway ä½¿ç”¨ PORT ç¯å¢ƒå˜é‡ï¼Œæœ¬åœ°å¼€å‘ä½¿ç”¨ 8002
    port = int(os.getenv("PORT", 8002))
    
    print(f"""
    ğŸš€ GPT-5 Responses API Service å¯åŠ¨ä¸­...
    
    ğŸ“ ç«¯ç‚¹: http://localhost:{port}
    ğŸ“– API æ–‡æ¡£: http://localhost:{port}/docs
    
    âœ… åŠŸèƒ½:
    - GPT-5 Responses API è°ƒç”¨
    - åŸç”Ÿå·¥å…·è°ƒç”¨æ”¯æŒ
    - reasoning.effort æ§åˆ¶
    - text.verbosity æ§åˆ¶
    - previous_response_id ä¸Šä¸‹æ–‡ç®¡ç†
    
    âš ï¸  æ³¨æ„: ç«¯å£ 8001 å·²è¢«è¯­éŸ³æœåŠ¡ä½¿ç”¨
    """)
    
    uvicorn.run(app, host="0.0.0.0", port=port)

