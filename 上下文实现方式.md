å¦‚æœä½ åœ¨ä½¿ç”¨ â€œè±†åŒ… APIâ€ ï¼ˆå‡å®šæ˜¯ä½ ä»¬å›¢é˜Ÿæˆ–ç¬¬ä¸‰æ–¹çš„æŸä¸ª LLM æ¥å£ï¼‰è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶ï¼Œéœ€è¦ **æºå¸¦å¯¹è¯ï¼ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰**ï¼Œä»¥ä¸‹æ˜¯ä¸€ä¸ªè¾ƒä¸ºè¯¦ç»†ã€ç»“æ„åŒ–çš„åšæ³•è¯´æ˜ï¼Œå…¼å…·ç†è®ºèƒŒæ™¯ï¼‹å®æ“å»ºè®®ã€‚ä½ å¯ä»¥ä¾æ®è‡ªå·±é¡¹ç›®æŠ€æœ¯æ ˆï¼ˆä½ æåˆ°ä½¿ç”¨ Python + FastAPIï¼‰ç¨ä½œè°ƒæ•´ã€‚

---

## âœ… ä¸ºä»€ä¹ˆè¦æºå¸¦ä¸Šä¸‹æ–‡

* LLM çš„ â€œä¸Šä¸‹æ–‡çª—å£â€ï¼ˆcontext windowï¼‰å†³å®šäº†æ¨¡å‹åœ¨ä¸€æ¬¡è°ƒç”¨é‡Œèƒ½çœ‹åˆ°å¤šå°‘ä»¥å‰çš„ä¿¡æ¯ï¼ˆtoken æ•°ï¼‰â€”â€”å¦‚æœä¸ä¼ ä¸Šä¸‹æ–‡ï¼Œæ¨¡å‹å°±â€œçœ‹ä¸åˆ°â€å…ˆå‰ç”¨æˆ·è¯´çš„è¯ï¼ç³»ç»Ÿè¯´çš„è¯ï¼Œå¾ˆéš¾åšè¿ç»­å¯¹è¯ã€ç»´æŒçŠ¶æ€ã€‚ ([Pieces][1])
* åœ¨å¯¹è¯ç³»ç»Ÿæˆ–å¤šè½®äº¤äº’ä¸­ï¼Œæºå¸¦å‰æ–‡æœ‰åŠ©äºæ¨¡å‹ç†è§£ç”¨æˆ·çš„æ„å›¾ã€å†å²ã€çº¦å®šï¼Œä»è€Œè¾“å‡ºæ›´è¿è´¯ã€åˆé€‚çš„å›åº”ã€‚
* ä½†åŒæ—¶ï¼Œä¸Šä¸‹æ–‡è¶Šå¤šï¼Œtoken æ¶ˆè€—è¶Šé«˜ã€æˆæœ¬è¶Šå¤§ã€å¤„ç†è¶Šæ…¢ï¼Œè¿˜å¯èƒ½è¶…å‡ºæ¨¡å‹çª—å£é™åˆ¶ã€‚ ([agenta.ai][2])

---

## ğŸ›  å¦‚ä½•åœ¨è°ƒç”¨ API æ—¶æºå¸¦ä¸Šä¸‹æ–‡

å‡å®šä½ ç”¨ Python/HTTP è°ƒç”¨ä¸€ä¸ª LLM æ¥å£ã€‚ä¸‹é¢æ˜¯æµç¨‹ä¸ç»“æ„å»ºè®®ï¼š

### 1. å®šä¹‰ä¸Šä¸‹æ–‡å­˜å‚¨ç»“æ„

* ä¸ºæ¯ä¸ªä¼šè¯ï¼ˆæˆ–ç”¨æˆ·ï¼‰ç»´æŠ¤ä¸€ä¸ªä¸Šä¸‹æ–‡å†å²ï¼Œæ¯”å¦‚ä¸€ä¸ªåˆ—è¡¨ `messages`ã€‚æ¯æ¡è®°å½•ä¸ºï¼šè§’è‰²ï¼ˆuser/system/assistantï¼‰ã€å†…å®¹ã€æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰ã€‚
* åœ¨ä½ çš„åç«¯ï¼ˆFastAPIï¼‰ä¸­ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªç”¨æˆ·æˆ–æ¯ä¸ªå¯¹è¯ session ä½¿ç”¨ä¸€ä¸ª `session_id`ï¼Œå¹¶å°†å…¶ `messages` å­˜å‚¨åœ¨å†…å­˜ï¼Redisï¼æ•°æ®åº“ä¸­ã€‚

```python
# ç¤ºä¾‹ç»“æ„
conversation_history = [
    {"role": "system",    "content": "ä½ æ˜¯ä¸€ä¸ªå¸®åŠ©ç”¨æˆ·çš„åŠ©æ‰‹ã€‚"},
    {"role": "user",      "content": "æˆ‘æƒ³äº†è§£å¦‚ä½•å‘¼å« LLM æ¥å£å¸¦ä¸Šä¸‹æ–‡ã€‚"},
    {"role": "assistant", "content": "å¥½çš„ï¼Œæˆ‘é©¬ä¸Šå¸®ä½ ã€‚"},
    # â€¦æ¥ä¸‹æ¥ç”¨æˆ·ä¸åŠ©æ‰‹çš„äº¤äº’
]
```

### 2. æ„é€  API è¯·æ±‚æ—¶æºå¸¦å†å²

* å½“ç”¨æˆ·å‘é€æ–°æ¶ˆæ¯æ—¶ï¼Œå…ˆå°†ç”¨æˆ·æ¶ˆæ¯åŠ å…¥ `conversation_history`ã€‚
* ç„¶åï¼Œåœ¨è°ƒç”¨ LLM çš„ API æ—¶ï¼Œå°† `conversation_history`ï¼ˆæˆ–å…¶ä¸€éƒ¨åˆ†ï¼‰ä½œä¸º `messages`ï¼ˆæˆ–ç±»ä¼¼å­—æ®µï¼‰ä¼ å…¥ã€‚
* ä¾‹å¦‚ï¼ˆä¼ªä»£ç ï¼‰ï¼š

```python
api_request = {
    "model": "x-model",
    "messages": conversation_history + [{"role":"user","content":user_new_input}],
    "max_tokens": 500,
    # å…¶ä»–å‚æ•°â€¦
}
response = call_llm_api(api_request)
assistant_reply = response["content"]
# å†æŠŠ assistant_reply åŠ å…¥ conversation_history
conversation_history.append({"role":"assistant","content": assistant_reply})
```

### 3. æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼æˆªæ–­ç­–ç•¥

å› ä¸ºæ¨¡å‹æœ‰çª—å£é™åˆ¶ï¼ˆæ¯”å¦‚æœ€å¤šå¤„ç† N tokensï¼‰ä¸”æˆæœ¬è€ƒè™‘ï¼Œæ‰€ä»¥ä½ éœ€è¦æ§åˆ¶æä¾›ç»™æ¨¡å‹çš„ä¸Šä¸‹æ–‡é‡ã€‚å‡ ç§å¸¸ç”¨ç­–ç•¥ï¼š

* åªä¿ç•™æœ€è¿‘çš„è‹¥å¹²è½®å¯¹è¯ï¼ˆæ¯”å¦‚æœ€è¿‘ 10 æ¡æ¶ˆæ¯æˆ–æœ€è¿‘ 1000 ä¸ª tokenï¼‰
* æˆ–è€…å¯¹å¾ˆæ—§çš„å†…å®¹åšæ‘˜è¦ï¼ˆå°†å†å²å‹ç¼©æˆç®€çŸ­æ€»ç»“ï¼‰ï¼Œç„¶åå†åŠ å…¥æ–°çš„è¯¦ç»†å¯¹è¯ã€‚æ¯”å¦‚ â€œåœ¨å‰é¢ä½ è¯´ä½ æ˜¯ â€¦ï¼Œæˆ‘ä»¬è®¨è®ºäº† â€¦â€
* åœ¨æ¯æ¬¡è°ƒç”¨å‰ï¼ŒåŸºäºå½“å‰ token é¢„ç®—ï¼Œå…ˆä» `conversation_history` å°¾éƒ¨å€’åºç´¯åŠ ç›´åˆ°æ¥è¿‘é¢„ç®—ï¼Œå†æ„é€ è¯·æ±‚ã€‚ç±»ä¼¼ â€œæ»‘åŠ¨çª—å£â€æ–¹å¼ã€‚ ([agenta.ai][2])
* å¦‚æœæ”¯æŒæ›´å¤§ä¸Šä¸‹æ–‡çª—å£çš„æ¨¡å‹ï¼ˆæ¯”å¦‚æŸäº›æ–°æ¨¡å‹æ”¯æŒæ•°åä¸‡ tokens æˆ–è€…ç™¾ä¸‡ tokenï¼‰é‚£ä¹ˆä¹Ÿå¯ä»¥åˆ©ç”¨æ›´å®Œæ•´å†å²ã€‚ ([Google AI for Developers][3])

### 4. è€ƒè™‘â€œç³»ç»Ÿæç¤ºâ€ï¼ˆsystem promptï¼‰å’Œâ€œåŠ©æ‰‹æç¤ºâ€

* é€šå¸¸åœ¨ `conversation_history` çš„å¼€å¤´ï¼Œä¼šæœ‰ä¸€æ¡ â€œsystemâ€ è§’è‰²çš„æ¶ˆæ¯ï¼Œç”¨äºè®¾å®šåŠ©æ‰‹çš„èº«ä»½ã€è¡Œä¸ºè§„èŒƒã€å¯¹è¯èƒŒæ™¯ã€‚
* æ¯”å¦‚ï¼šâ€œä½ æ˜¯ä¸€ä¸ªè‚©éƒ¨æ‹‰ä¼¸æ•™ç»ƒåŠ©æ‰‹â€ æˆ–ä½ ä¸Šæ¬¡æåˆ° â€œè‚©è†€æ‹‰ä¼¸ç»ƒä¹ â€ã€‚
* è¿™ä¸ª system æç¤ºåº”å½“æ¯æ¬¡è°ƒç”¨éƒ½åŒ…æ‹¬ï¼Œä»¥ä¿è¯ä¸Šä¸‹æ–‡â€œè®°å¾—èº«ä»½ï¼æç¤ºâ€ã€‚
* ç„¶åå†åŠ å…¥å†å² user/assistant æ¶ˆæ¯ + æœ€æ–°ç”¨æˆ·è¾“å…¥ã€‚

### 5. å®é™…åœ¨â€œè±†åŒ… APIâ€ä¸­ä½¿ç”¨ï¼ˆå‡å®šæ¥å£ï¼‰

è™½ç„¶æˆ‘æ²¡æœ‰æ‰¾åˆ°â€œè±†åŒ… APIâ€å…·ä½“æ–‡æ¡£ï¼Œä½†ä½ å¯ä»¥æŒ‰ä¸Šé¢æ€è·¯å®ç°ã€‚å…·ä½“æ­¥éª¤ï¼š

* åœ¨åå°å®šä¹‰ä¸€ä¸ªæ¥å£ endpointï¼Œæ¯”å¦‚ `/chat`ï¼Œå®¢æˆ·ç«¯å‘é€ `{session_id, user_message}`ã€‚
* åœ¨åå°æŸ¥æ‰¾æˆ–åˆå§‹åŒ–è¯¥ `session_id` çš„ `conversation_history`ã€‚
* æ›´æ–°å†å²ï¼Œæ„é€  LLM è¯·æ±‚ï¼Œå°†å†å²æ¶ˆæ¯ä¼ å…¥ã€‚
* è°ƒç”¨ LLMï¼Œæ”¶åˆ°åŠ©æ‰‹å›å¤åæ›´æ–°å†å²ã€‚
* è¿”å›åŠ©æ‰‹å›å¤ç»™å®¢æˆ·ç«¯ã€‚
* ç»´æŠ¤å†å²é•¿åº¦ã€è¿›è¡Œæˆªæ–­æˆ–æ‘˜è¦ã€‚

### 6. ç¤ºä¾‹ä»£ç ï¼ˆFastAPI + Pythonï¼‰

```python
from fastapi import FastAPI, Body
from pydantic import BaseModel

# ç®€åŒ–ç¤ºä¾‹
app = FastAPI()
sessions = {}  # { session_id: [messages] }

class ChatRequest(BaseModel):
    session_id: str
    user_message: str

@app.post("/chat")
async def chat(req: ChatRequest):
    hist = sessions.get(req.session_id, [
        {"role":"system","content":"ä½ æ˜¯ä¸€ä¸ªå¸®åŠ©ç”¨æˆ·åšè‚©è†€æ‹‰ä¼¸ç»ƒä¹ çš„åŠ©æ‰‹ã€‚"}
    ])
    hist.append({"role":"user","content": req.user_message})
    # æ§åˆ¶å†å²é•¿åº¦ï¼ˆä¾‹å¦‚ä¿ç•™æœ€è¿‘ 20 æ¡ï¼‰
    if len(hist) > 20:
        hist = hist[-20:]
    # æ„é€  LLM è¯·æ±‚
    api_req = {
        "model": "xxx",
        "messages": hist,
        "max_tokens": 300
    }
    # è°ƒç”¨ LLMï¼ˆä¼ªä»£ç ï¼‰
    api_res = call_llm(api_req)
    assistant_reply = api_res["content"]
    hist.append({"role":"assistant","content": assistant_reply})
    sessions[req.session_id] = hist
    return {"reply": assistant_reply}
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹ä¸æŒ‘æˆ˜

* **Token é™åˆ¶**ï¼šå¦‚æœå†å²å¤ªå¤šã€æ¶ˆæ¯å¤ªé•¿ï¼Œå¯èƒ½è¶…å‡ºæ¨¡å‹çª—å£ï¼Œå¿…é¡»æˆªæ–­æˆ–æ‘˜è¦ã€‚
* **æˆæœ¬ï¼å»¶è¿Ÿ**ï¼šå‘é€å¤§é‡ä¸Šä¸‹æ–‡ä¼šå¢åŠ  token å‘é€ï¼‹æ¥æ”¶ï¼Œå¯¼è‡´æˆæœ¬ä¸Šå‡ã€å“åº”æ…¢ã€‚
* **éšç§ï¼å®‰å…¨**ï¼šå¦‚æœä¸Šä¸‹æ–‡åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œéœ€è¦å°å¿ƒå¤„ç†ï¼ˆåŠ å¯†ã€è„±æ•ï¼‰ã€‚
* **ä¸Šä¸‹æ–‡æ¼‚ç§»**ï¼šå¦‚æœå†å²å¾ˆå¤šï¼Œç”¨æˆ·æ—©å…ˆçš„è¯å¯èƒ½ä¸å½“å‰å¯¹è¯æ— å…³ï¼Œåè€Œå¹²æ‰°æ¨¡å‹ã€‚éœ€è¦ç­–ç•¥å†³å®šå“ªäº›å†å²ä¿ç•™ã€‚
* **çŠ¶æ€æŒä¹…åŒ–**ï¼šå¦‚æœæœ‰å¤§é‡ sessionï¼Œéœ€è¦è€ƒè™‘å†å²å­˜å‚¨ï¼ˆå†…å­˜ï¼Redisï¼æ•°æ®åº“ï¼‰å’Œæ¸…ç†æœºåˆ¶ã€‚
* **ä¸Šä¸‹æ–‡æ‘˜è¦**ï¼šå½“å†å²å¤ªé•¿æ—¶ï¼Œå°†æ—§å†å²è½¬ä¸ºç®€çŸ­æ‘˜è¦æ˜¯æœ‰æ•ˆæ–¹æ¡ˆã€‚æ¯”å¦‚å°†â€œå‰é¢æˆ‘ä»¬è®¨è®ºè¿‡â€¦è¦è®°ä½â€è½¬ä¸ºä¸€å¥è¯ã€‚
* **ç³»ç»Ÿæç¤ºä¸€è‡´æ€§**ï¼šsystem æç¤ºå¦‚æœæ”¹å˜ï¼Œä¼šå½±å“æ¨¡å‹è¡Œä¸ºã€‚åº”ç»Ÿä¸€ç®¡ç†ã€‚

---

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥å¸®ä½ æŸ¥ â€œè±†åŒ… APIâ€ çš„å…·ä½“æ–‡æ¡£ï¼ˆå¦‚æœå…¬å¼€çš„è¯ï¼‰ï¼Œç„¶åç»™å‡º **å¸¦ä¸Šä¸‹æ–‡è°ƒç”¨è¯¥ API çš„ç¤ºä¾‹ä»£ç ï¼ˆé€‚ç”¨äº FastAPIï¼Pythonï¼‰**ã€‚ä½ çœ‹è¦ä¸è¦ï¼Ÿ

[1]: https://pieces.app/blog/ai-context-making-the-most-out-of-your-llm-context-length?utm_source=chatgpt.com "Context length in LLMs: how to make the most out of it"
[2]: https://agenta.ai/blog/top-6-techniques-to-manage-context-length-in-llms?utm_source=chatgpt.com "Top techniques to Manage Context Lengths in LLMs"
[3]: https://ai.google.dev/gemini-api/docs/long-context?utm_source=chatgpt.com "Long context | Gemini API - Google AI for Developers"
